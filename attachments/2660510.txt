City of Stockholm 
International Affairs Unit 
Ragnar Östbergs Plan 1 
SE-105 35 Stockholm 
SWEDEN 
Direct +46 8 5+46 8 29 311 
agata.uhlhorn@stockholm.se 
start.stockholm 
Page 1 (5) 
Feedback on the EU consultation on the Artificial 
Intelligence Act 
The City of Stockholm welcomes the regulation laying down 
harmonised rules on artificial intelligence and amending certain 
union legislative acts. However, certain concerns arise with the 
current proposal for the Artificial Intelligence Act: 
1. There is a need to clearly specify which types of legal 
requirements that are mandatory for the different authorities, 
organisations and companies (etc) concerned. 
2. Who is to define whether or not certain users or systems fall 
under the category of “high risk”? 
3. There is a need to conduct further risk analyses to sort out 
the consequences for those affected by the legislation on 
different levels, such as the public sector. 
4. It should be investigated in further detail which issues 
regarding AI that are suitable for regulation at EU regulation 
level and which other regulation level. 
5. The AI Act should be developed in line with other current 
legislation and legislative proposal in the field of data 
sharing, data reliability and security. 
6. How is “common normative standards” defined? 
7. Many citizens are sceptical of data collection and data 
sharing and see it as an intrusion into their lives – proactive 
information campaigns on how AI works should be planned. 
8. It is unclear whether innovation within the area of cloud 
services will be encouraged. Will the AI Act encourage the 
creation of European cloud services to test AI and AIcomplience? 
1. Which types of legal requirements are mandatory for which 
types of stakeholders? 
In previous consultations, the City of Stockholm has stressed the 
importance that in the development of regulations for AI there is a 
need to clearly specify which types of legal requirements that are 
mandatory for the different authorities, organisations and companies 
(etc) concerned. In this proposal for regulation the requirements are 
City of Stockholm 
International Affairs Unit 
Feedback on EU consultation 
16 June 2021 
Ragnar Östbergs Pl an 1 
105 35 Stockhol m 
Telefon + 46 8 508 29 311 
agata.uhl horn@stockhol m.se 
start.stockhol m 

Sida 2 (5) 
mainly based on providers of AI systems and the City of Stockholm 
finds it challenging to fully understand which role the user and in 
our case the public sector have in this regulation. 
2. Which users or systems fall under the category of “high 
risk”? 
The City of Stockholm uses AI-systems in a number of areas today, 
for example: 
The Education Department at the City of Stockholm uses an 
AI system called Lexplore that maps students' reading using 
eye tracking and artificial intelligence. 
SISAB - The Stockholm School Properties Company uses 
an AI system called SOLIDA. The system controls, 
optimizes and analyses properties in real time using 
algorithms. 
Based on the proposed legislation, does these systems fall under the 
category “high risk”. 
Furthermore, the proposal states: The technical documentation of a 
high-risk AI system shall be drawn up before that system is placed on 
the market or put into service and shall be kept up-to date. 
How will this be followed and by who? How will we as users rely on it 
to be “kept up-to date”. 
3. What will be the consequences for those affected by the 
legislation, such as the public sector? 
Furthermore the City sees that it is overall an extensive and 
complex area and that the regulation is demanding for those who 
fall under the category of “high-risk AI”. 
The proposal states: AI systems used in education or vocational 
training, notably for determining access or assigning persons to 
educational and vocational training institutions or to evaluate persons 
on tests as part of or as a precondition for their education should be 
considered high-risk, since they may determine the educational and 
professional course of a person’s life and therefore affect their ability 
to secure their livelihood. 
The Commission also states: AI systems used in employment, workers 
management and access to self-employment, notably for the 
recruitment and selection of persons, for making decisions on 
promotion and termination and for task allocation, monitoring or 
evaluation of persons in work-related contractual relationships, should 
also be classified as high-risk, since those systems may appreciably 
impact future career prospects and livelihoods of these persons. 

Sida 3 (5) 
The City of Stockholm agrees with the fact that if AI-systems are 
misused it can limit a person’s possibilities to determine their own 
educational needs and in the long run, their ability to secure their 
livelihood. Since the City conducts education it will be affected by 
the proposal concerning educational and vocational training. The 
regulation concerning employment may also affect the City. The 
City of Stockholm urges the Commission to make it more clear how 
the regulation affects the public sector. 
The City sees that there would be an added value in conducting 
further risk analyses to sort out the consequences for those affected 
by the legislation, both on the EU-level, the national level and local 
and regional level; for example how the legislation effects the 
providers as well as the users of AI-systems, when it comes to the 
administrative burden. 
4. AI-regulation on EU level vs other regulation level 
An important part of the AI Act is the high-risk catalogue and the 
requirements for providers and users. The proposal states that these 
parts can be changed through delegated acts over time. Delegated 
acts usually supplement and specify an EU regulation, not 
fundamentally change it. It should therefore be investigated in more 
detail which issues of AI are suitable for regulation at EU regulation 
level and which on other regulation level. 
5. The AI Act needs to be synchronised with EU legislation and 
legislative proposals on data sharing, reliability and security. 
The City also wants to highlight the importance to make sure that 
this legislation is drawn up in accordance with other EUlegislations, for example the General Data Protection 
Regulation (GDPR). At present the AI Act proposal at some points 
appears to be in direct conflict with GDPR regulation. Furthermore, 
if the AI Act is adopted as is, there will be two supervisory bodies, 
the EAIB (European AI Board) and EDPB (European Data 
Protection Board) with overlapping areas of responsibility which 
might lead to misinterpretation concerning regulation that takes 
precedence. For clarification and elaboration see attachment in 
Swedish. Finally, the AI Act-proposal should also be synchronised 
with current legislative proposals on the topic of data sharing, data 
reliability and security. 
An important topic in this context is the use of algorithms and 
deepfakes. Currently there is much fake info is spread online about 
vaccinations. Further, on the topic of data collection it is unclear 
how corporate confidentiality can be/ought to be taken into 
account? Some companies hold very sensitive information and 
should be able to retain the right to trade secrets. 

Sida 4 (5) 
6. How is “common normative standards” defined? 
The proposal states: In order to ensure a consistent and high level 
of protection of public interests as regards health, safety and 
fundamental rights, common normative standards for all high-risk 
AI systems should be established. 
How does the commission define “common normative standards” 
and how will this be followed up? 
7. AI and the citizens 
There is also an ethical aspect of AI. It is important to clarify which 
authority will hold the responsibility to communicate about AI and 
answer the citizens’ questions concerning data collection, which 
algorithms that are behind the AI decisions etc. Many citizens are 
sceptical of data collection and see it as an intrusion into their lives. 
Proactive information campaigns on how AI works should be 
planned. 
8. AI, innovation and European cloud services 
The City also welcomes the initiative on encouraging member states 
to establish artificial intelligence regulatory sandboxes. 
Development and usage of AI brings about new challenges linked to 
new digital technology. It is therefore important to encourage 
innovation and to make it possible to try new ideas. A question that 
arises is – will this also include the area of cloud services? Will the 
AI Act encourage the creation of European cloud service to test AI 
and AI-complience, which currently to a great extent is dominated 
by American solutions? 
AI Act – elaboration in Swedish from a legal perspective 
Otydlighet och eventuell regelkonflikt 
Förslaget ålägger en ”provider” av AI flera skyldigheter, bl. a tillse 
regelefterlevnad, transparenskrav och upprättande av 
dokumentation och instruktioner för ”users”.  Liknande skyldigheter 
åligger enligt dataskyddsförordningen den personuppgiftsansvarige, 
inte personuppgiftsbiträdet som enligt förslaget benämns 
”provider”. Den som upphandlar AI är vanligen 
personuppgiftsansvarig enligt dataskyddsförordningen och har 
därmed en ansvarsskyldighet för de behandlingar av 
personuppgifter som sker i verksamheten. Personuppgiftsansvarig 
är skyldig att endast anlita personuppgiftsbiträden som har en 
tillräcklig säkerhet och garanti, vidare en skyldighet att ålägga 
biträdet instruktioner för behandlingen av personuppgifter för sin 
räkning etcetera. Förslaget å andra sidan ålägger ”user” en 
skyldighet att efterleva den tekniska dokumentationen och de 
instruktioner som en ”provider” tillhandahåller, ”user” ska även 

Sida 5 (5) 
bl. a kontrollera AI-systemets funktion i relation till de givna 
instruktionerna och risker som identifieras ska rapporteras till 
”provider”. 
Sammantaget skiljer sig förslagets skyldigheter – och närmast 
krockar med – de skyldigheter som föreligger enligt 
dataskyddsförordningen. Det finns en risk för att det uppstår en 
osäkerhet och eventuell regelkonflikt i den praktiska tillämpningen 
av de två EU-förordningarna såsom förslaget nu är utformat i sin 
struktur vad gäller skyldigheter för ”provider” och ”user”. Vidare 
finns en risk för att en regelkonflikt uppstår även vid tillämpning av 
EU-regelverk för offentlig upphandling där det måste gå att 
kravställa en leverantör. Det är därför viktigt att förslaget utformas i 
överensstämmelse med övriga EU-regelverk. 
Ett nytt parallellt system för tillsyn 
Parallellt med dataskyddsförordningens tillsynssystem föreslås en ny 
europeisk byrå för AI – European Artificial Intelligence Board 
(EAIB) - vid sidan om EDPB​Europeiska dataskyddsstyrelsen ​  jämte införandet av ett parallellt 
tillsynssystem i medlemsstaterna. Om en aktör bryter mot förslagets 
skyldigheter kommer sannolikt samma agerande leda till en 
överträdelse mot dataskyddsförordningen. Här är det nödvändigt med 
vissa förtydliganden avseende 
 vilken reglering som ska ha företräde i fall av undvikande av 
dubbla och/eller motstridiga tillsynsförfaranden och 
sanktioner, 
 hur de nationella tillsynsmyndigheterna ska förhålla sig till 
varandra, 
 tänkt ansvarsfördelning mellan EDPB och EAIB. 
Förutsägbarhet är en grundpelare inom EU-rätten; det får inte råda 
oklarhet över vilket regelverk som ska tillämpas och när och vilka 
konsekvenserna skulle bli vid en eventuell överträdelse av ett 
regelverk. 
Förslagets legitimitet 
Förslagets kärndelar är bland annat högriskkatalogen och krav på 
skyldigheter för respektive aktörer. I förslaget anförs att dessa delar 
ska kunna ändras genom delegerade akter över tid. Det är sannolikt 
inte rättsligt möjligt att genom delegerade akter - EUkommissionens genomförandebeslut - ändra en EU-förordning. 
Delegerade akter brukar komplettera och precisera en EU-reglering, 
inte ändra den i grunden. Det bör utredas närmare vilka frågor 
avseende AI som lämpar sig för reglering på EU-förordningsnivå 
respektive annan regleringsnivå. 