Response to the European Commission Draft 
Artificial Intelligence Act 
By: 
Norwegian Open AI Lab, www.ntnu.no/ailab 
NTNU Digital, www.ntnu.edu/digital 
Background 
On April 21st, The European Commission released its proposal for the first ever legal 
framework on AI. The proposal addresses the risks of AI and aims to position Europe to 
play a leading role globally. 
The Norwegian Ministry of Local Government and Modernization has invited Norwegian 
actors in the AI field to comment on the proposal. This document presents the view of the 
Norwegian Open AI Lab, and is also supported by NTNU Digital. 
About The Norwegian Open AI Lab (NAIL): NAIL is a center for research, innovation and 
education within AI, hosted by NTNU. NAIL is a partnership organization, and our current 
partners in industry, business and the public sector are DNB, DNV, Equinor, Kongsberg, 
Telenor, SINTEF, TrønderEnergi, The Norwegian Computing Center, The Norwegian 
School of Economics, Trondheim Municipality, DeepInsight, Sticos and Zeabuz. 
About NTNU Digital: NTNU Digital is NTNU’s strategic initiative to increase the 
understanding, use and development of digital technology as a tool to solve complex 
issues across research disciplines. 
Key recommendations 
In response to the draft Artificial Intelligence Act, the Norwegian Open AI Lab, makes the 
following key recommendations to the European Commission: 
1. Clearer descriptions are needed for how this regulation will impact products or 
services governed by already existing regulations. 
2. Specifically, the area of autonomous systems is not dealt with in the proposed 
regulation. This is a missed opportunity with respect to defining a set of common 
regulatory principles across applications of technology for autonomous systems. 

3. Businesses will not be able to act on the regulation before harmonized international 
standards exist. Top priority must therefore be given to developing such standards 
in parallel with the development of the regulation itself. 
Trustworthy AI as the norm 
We support the ambition set out in the proposed legislative framework, that AI should be 
a tool for people and a force for good in society, with the ultimate goal to increase human 
well-being. We agree that a legal framework for trustworthy AI is a necessity in order to 
develop an AI ecosystem of trust in Europe. A lack of trust from citizens and unclear legal 
conditions for companies could slow down the development and uptake of AI 
technologies, and hence reduce the competitiveness of Europe. 
Disparate regulatory responses by national authorities would risk a fragmentation of the 
internal market. Hence such regulation clearly needs harmonization at the European 
level. Regulation is needed to ensure that AI systems, products, and services deployed 
in Europe comply with European norms and values. We therefore welcome the draft 
regulation. 
The regulatory landscape 
As the technology progresses further, AI will play an important role in an ever-increasing 
number of systems, products, and services. The draft Artificial Intelligence Act aims to put 
down fundamental principles to govern such use. However, we find it challenging to 
understand the connection between the proposed regulation and already existing policy 
provisions, specifically with respect to the use of AI in products and services that are 
governed by already existing regulations such as for cars, marine equipment, etc. 
The draft Artificial Intelligence Act also needs to be seen in conjunction with other relevant 
and recent regulations. In particular, emphasis must be given to harmonizing the Artificial 
Intelligence Act and the recently proposed Data Governance Act as well as the General 
Data Protection Regulation. 
Companies that are developing or integrating AI in systems, products, or services rely on 
harmonized standards as a means of verifying that their offerings meet relevant 
regulations and directives. It is therefore critical for continued innovation that harmonized 
standards are developed with the maximum priority and minimum delay from the release 
of the new Artificial Intelligence Act. 

Definitions / delimitations 
How AI is defined will determine whether a specific product or service falls under the 
regulation, alternatively whether this is open for interpretation. A clear and concise 
definition that leaves few grey areas is therefore of critical importance. The approach 
taken is to base the definition on the techniques and methods being used, rather than 
basing it on the features of the product or service. We believe this is a good approach 
that leaves less ambiguity than many of the alternatives. 
The proposed legal framework is meant to be future proof in its fundamental choices. 
However, this appears to be an overly optimistic view in the light of the rapid 
developments in the field. With respect to the approach taken to define AI, the 
consequence is that frequent updates to Annex I will be needed as the field progresses 
and new techniques are developed. 
The risk-based approach 
The fact that the draft regulation has a risk-based approach, allows for different levels of 
intervention for different AI applications, based on the associated risk. We welcome this 
approach. Moreover, we appreciate that the draft regulation bans certain use cases of AI 
that are not aligned with fundamental and shared values in Europe. The number of risk 
categories and the orientation of each category seem appropriate. 
The high-risk category includes AI applications with potential to bring societal benefits, 
economic growth and enhanced innovation and global competitiveness. A balanced 
regulation will increase the level of trust by citizens in such products and services, and it 
will reduce uncertainty and risk for companies. 
The regulation identifies two main categories of high-risk AI systems; firstly, those that 
use AI systems as safety components of products subject to third party conformity 
assessment, according to already existing regulations; secondly, AI application areas with 
implications for the fundamental rights of citizens, in which a set of eight application areas 
are listed. For seven of these, the regulation mandates a self-assessment scheme for the 
ex-ante conformity assessment. The latter of the eight application areas, remote biometric 
identification systems, shall be subject to third party conformity assessment. 
It is expected that safety components based on AI technology will play an important role 
in a wide range of products in the future. We find the draft regulation vague in its 

description of how it will be integrated into existing sectoral safety legislation. Most 
notably, the topic of autonomous systems is not dealt with in this proposal. Autonomous 
systems will play an integral role in many different products, such as cars, marine vessels 
(surface and sub-surface), and aviation. By neglecting this topic, we risk that use of 
autonomous systems in different product categories will not be regulated according to a 
set of common criteria and procedures. 
We consider the balance between requirements for self-assessment and third-party 
assessment to be reasonable. The regulation lists seven areas with requirements that 
high-risk AI systems must meet. Best practices for the development of AI technologies 
include all these areas, and we therefore find that the burden put on the developers and 
technology providers by this regulation is not unreasonable. The key challenge is however 
that harmonized standards do not yet exist for all areas. Three of these areas stand out 
as particularly challenging and in need of new standards. 
Data and data governance: statements such as “data sets shall be relevant, 
representative, free of errors and complete” need interpretation and clarification. 
Human oversight: statements such that the human oversight operator shall “fully 
understand the capacities and limitations of the high-risk AI system” seem unrealistic for 
highly sophisticated and complex applications in specialized areas, and therefore needs 
interpretation and clarification. 
Accuracy, robustness and cybersecurity: this area covers complex requirements, 
including issues such as bias in continuous learning systems, data poisoning and 
adversarial data. Again, interpretation and clarification are needed through harmonized 
standards. 
Implications for innovation 
The code of conduct as described by the draft regulation in large parts follows best 
practices for the development of AI systems. As such, this regulation therefore to a 
reasonable degree avoids putting extra burdens on the companies developing and 
integrating AI systems in products and services. To the degree that this regulation 
reduces the timeline before relevant harmonized standards become available, one could 
argue that the regulation will indeed stimulate innovation. The new harmonized standards 

will specify procedures and methods needed to fulfill the regulation, and we believe that 
these procedures will prove useful to the companies. 
It is encouraging to see regulatory sandboxes as part of the EC proposal, as the industry 
has been advocating this for many years. The UK and Norway among others have started 
to gain experience with this, and we support this instrument in order to stimulate 
innovation also in complex and challenging areas. 
We support the principle that providers of minimal risk AI systems will not be forced to 
adhere to the codes of conduct but can do this on a voluntary basis. We believe that being 
able to document internal developer practices in this field in line with the code of conduct 
in many cases will be a competitive advantage. 
Next steps 
We believe that engagement and broad dialogue will be critical in the months and years 
to come. More nuanced legal definitions are needed, to create even more legal certainty 
within such a fast-moving domain as AI. In that, it is critical to hear from industry, civil 
society and academia. We support attempts of the Commission to engage a broader 
community. 
Specifically, it will be important to convince businesses and politicians, both in Europe 
and globally, that the AI regulatory framework does not intend to slow down innovation in 
Europe. Instead, the framework represents an opportunity to create a framework for 
trustworthy AI practices that could be adopted outside of Europe as well. For that, a 
pragmatic, knowledge-driven and supportive approach is needed, among industry and 
policy makers - in the form of sharing best practices. 
It is encouraging to see EC´s ambition to create a joint AI, Data and Robotics Partnership 
and seek wider and more active industry involvement therein. The partnership could be 
instrumental not only for setting the research and innovation agenda for AI in Europe, but 
also in setting priorities for technology testing and fostering good sandboxing practices. 
No ethical AI is possible without having knowledge and financial muscles to develop and 
deploy AI technology in the first place. We need to accelerate private and public 
investments into AI uptake across Europe. Moreover, we need to discuss how we can 

attract investors who believe in Europe's ability to do breakthrough AI research and 
innovations, and who can scale the AI business. We have high-quality AI research in 
Europe, and European research environments are well positioned to make new 
breakthroughs. However, our challenge in Europe is to transfer research into production 
at a fast rate and cater for new, global market needs. Additionally, we are struggling to 
attract and retain top-notch talents in Europe and create a vibrant and scalable startup 
and SME ecosystems. We hope to see that the Commission gives this challenge high 
priority going forward. 
We applaud the Commission’s suggestion to increase investments into AI, including the 
revision of a Coordinated Plan and the planned investment of 1 billion EUR per year into 
AI Research and Innovation through the Digital Europe and Horizon Europe programmes. 
It will be crucial to involve businesses in these efforts. The plans to attract 20 billion EUR 
investments into AI per year is ambitious. For this investment to be spent efficiently, 
industrial priorities for Europe should be decided on by the Member States. Europe should 
accelerate the uptake of AI in already strong digital, global industries (such as energy, 
heavy machinery, chemicals) and boost the uptake of AI in the public sector. Green and 
Sustainable AI will also open new growth opportunities. 