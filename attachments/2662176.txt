Finans Danmark | Amaliegade 7 | 1256 København K | www.finansdanmark.dk
Position paper 
The interplay between protection and 
further use of artificial intelligence 
Position 
Finance Denmark supports regulation of AI. It is important to provide a regulation 
that protects the customer, through which trust in AI can be build. Much of what 
the financial sector does, is fundamentally based on trust. Therefore, it is im-
portant that AI-solution now and in the future can be trusted through a sound 
and appropriate regulatory framework on AI. 
The proposal from the European Commission distinguishes between high and low 
risk. Finance Denmark recommends that a risk-based approach with several lev-
els will be used instead. 
We support that the future supervision of the financial sectors use of artificial intel-
ligence is placed with the regulatory authorities that currently has the supervisory 
oversight of the financial sector 
Finance Denmark proposes that it will be possible to apply the same regulatory 
risk-based approach for artificial intelligence as the approach used in connec-
tion to fintech. 
Higher focus on the interplay between protecting the European citizens and the 
further use of artificial intelligence 
The European Commission presented on the 21st of April 2021 its proposal for fu-
ture harmonized regulation on artificial intelligence – Proposal for a regulation of 
the European parliament and of the council laying down harmonized rules on ar-
tificial intelligence (Artificial intelligence act) and amending certain union legisla-
tive acts. 
Finance Denmark considers that it is important to have a clear and coherent Eu-
ropean regulation on artificial intelligence and we therefore welcome the Com-
mission’s proposal. 
Finance Denmark assess that there can be a wide variety of opportunities in the 
use of artificial intelligence. For example, artificial intelligence enables Europe to 
increase the prosperity of its citizens and can accelerate/boost the growth of 
businesses - and thereby include both economic and social benefits. 

Artificial intelligence in the financial sector will contribute to improve the cus-
tomer experience with smarter more convenient and safer ways to access, 
spend, save and invest. AI will further increases cybersecurity, consumer protec-
tion and improves the risk management by streamlining and optimizing business 
processes. Furthermore, it will support the fight against economic crimes includ-
ing combatting money laundering. 
It is important for both businesses and consumers that there is a harmonized, co-
herent and robust regulation of artificial intelligence and the use hereof. On one 
hand AI-regulation must secure and provide a framework that will support the 
development and further application of artificial intelligence in businesses. On 
the other hand, adequate and effective regulation must ensure that the citizens 
and consumers can safely use and interact with services and solutions that are 
based on artificial intelligence. 
For the general provisions, we have the following general considerations on the 
proposed regulation of artificial intelligence: 
It is imperative to maintain a high level of customer protection in the legisla-
tion. This will ensure that customers have the confidence and trust to use arti-
ficial intelligence. 
The proposal from the European Commission distinguishes between high and 
low risk. Finance Denmark recommends that a risk-based approach with sev-
eral levels will be used instead. A risk-based approach with only two levels is 
likely to reduce the use of artificial intelligence by both large and established 
companies as SME’s and start-ups. We believe that a more gradual setup, 
will encourage companies to apply AI-solution gradually and swiftly. Such a 
gradual approach will keep customer assured and the level of trust high as 
well as increasing the overall application of AI across all sectors. 
It is important to ensure a level playing field for all industries and geogra-
phies. This is crucial if you want to ensure an increased and appropriate use 
of artificial intelligence across industries. 
It is worth mentioning that artificial intelligence is still a technology under de-
velopment. In connection to this, it is worth mentioning that it must be ex-
pected that there will be an ongoing need to reassess which artificial intelli-
gences that are high risk, and which are not. If an ongoing adjustment is not 
established, the regulation will probably over time be distorted in relation to 
the purpose and desire to secure, protect the consumers and innovate Euro-
pean businesses. 

The wish in the proposal for businesses to voluntarily submit their AI solutions to 
the AI-regulation, will perhaps not have the desired effect. This is likely due to 
the binary distinction between high and low risk. It is Finance Denmark's as-
sessment that a more differentiated and risk-based approach as the one 
mentioned above will make it more likely that providers of AI-solution will vol-
untarily comply with the new regulation of artificial intelligence. 
Furthermore, Finance Denmark supports the implementation of financial AI-
solutions also must comply with current legislation on GDPR and consumer 
protection legislation. 
For the special provisions we have the following comments. 
In the stated proposal the supervision of the financial sector, will be placed with 
the existing financial supervisory authorities. For that we have following com-
ments: 
We support that the future supervision of the financial sectors use of artificial 
intelligence is placed with the regulatory authorities that currently has the su-
pervisory oversight of the financial sector. 
We believe it will be appropriate to ensure further coherency with existing fi-
nancial regulation. The regulation regarding development and use of AI-so-
lution should apply a risk-based approach. This will make it possible for the fi-
nancial supervisory authorities to deviate from the narrow high risk and low 
risk approach in the proposal. We believe that a more risk-based approach 
will provide better protection and assurance for the consumers as well as 
support innovation and the use of AI. 
Finance Denmark proposes that it will be possible to apply the same regula-
tory risk-based approach for artificial intelligence as the approach used in 
connection to fintech. 
We support that financial companies that are regulated under Capital Re-
quirements Directives (CRD) also shall apply the elements described in para-
graphs 1to 8 in the proposed article 9 (Risk management system) in their risk 
management procedures described in Article 74 of the CRD. Again, it is our 
believe that for this to have the indented effect and support the adaption of 
AI, minimize the negative hazards by AI and help promote trust, a more risk-
based approach will be appropriate. The present binary high-risk / low-risk 
approach will impose unnecessary barriers to implementing new AI-solution 
that e.g., is intended to support human decisions. 

The proposal and general regulation do not clearly distinguish between artifi-
cial intelligence used to support human decisions and when the artificial in-
telligence works autonomously. Therefore, Finance Denmark suggest apply-
ing a risk-based approach that should lead to lighter regulatory requirements 
for artificial intelligences that are used to support human decisions. Whereas 
autonomous artificial intelligences should be regulated in more detail and 
thereby adding a proportionality consideration into the regulatory setup. 
For example: If a specific AI-system is used to autonomously decide whether 
a consumer should be granted credit or not - we agree that this should be 
classified as high-risk. But if the AI-systems only work as a guideline and will be 
followed by a human assessment, we suggest that a risk-based proportional-
ity is added to the narrow and binary high and low risk approach in the pro-
posal. 
We strongly suggest that expert systems are exempt from the very broad AI 
definition in annex I. The very nature of expert systems makes its contradict-
ing to include them in this regulation, because they have no elements that 
makes them in any way ‘intelligent’. An expert system will always render de-
terministic results whereas AI systems will render probabilistic results. 
As an alternative to a broad exemption of expert systems from the AI defini-
tion, we suggest that a narrower AI definition will be applied with regard to 
future AI regulation of the financial sector where expert systems are not in-
cluded. We suggest that an AI definition for the financial sector will be based 
on the current work and experience that e.g. Danish and German FSA have 
done on AI. This will ensure that the general regulations of the financial sector 
and the future AI regulation will work well together. 
An exemption will also support a more risk-based approach in regard to the 
financial sector which will ensure greater coherency with existing regulation 
as stated above. Today most banks use expert system to help support the in-
dividual credit decisions. By supplementing such expert systems with simple 
statistical features does not make them probabilistic AI systems. If more statis-
tical and probabilistic elements are added, then the expert systems will 
eventually become an AI-system. To ensure that such gradual development 
is regulated in a coherent way, a risk-based approach to AI-regulation is 
beneficial. If a risk-based approach is not adopted with regard to the finan-
cial sector we fear that the proposed high-risk low / low risk setup will create 

a regulatory mismatch between this proposal and existing regulation in the 
financial sector. 
The annex to the proposal specifically states: 
AI systems intended to be used to evaluate the creditworthi-
ness of natural persons or establish their credit score, with the ex-
ception of AI systems put into service by small scale providers for 
their own use 
The proposal presents a somewhat unclear and vague argument for this exemp-
tion: “Considering the very limited scale of the impact and the available alterna-
tives on the market”. This undocumented speculation leads to the conclusion 
that: “, it is appropriate to exempt AI systems for the purpose of creditworthiness 
assessment and credit scoring when put into service by small-scale providers for 
their own use”. 
This will most likely lead to an unlevel playing field and harm general trust in AI. An 
ill-conceived AI, that is used by a small-scale provider is potential equally harmful 
towards the individual consumer as a large-scale provider. An unchecked AI 
based creditworthiness assessment will undermine trust in AI solutions in general 
and should be avoided. 
It is also unclear what is meant by ‘their own use’. Does it mean internal use or as 
support to help make a human decision or something else? Again, the risk to-
wards the customer is not any different whether ‘their own use’ is done in the 
context of a small or large provider. 
To ensure a coherent and risk-based approach, we recommend that this exemp-
tion is removed from the regulation, because it will most likely be counterproduc-
tive to the overall goals of this regulation of establishing trust and it will also result 
in an unlevel playing field. On this basis we strongly recommend that any future 
regulation of AI within the financial sector will use a similar risk-based approach 
and be in correspondence to the existing risk-based regulatory setup used to-
wards the financial sector. And here it seems obvious and natural to adapt the 
same risk-based approach as is presently used towards fintech as mentioned 
above. 