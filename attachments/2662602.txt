Schriftliche Stellungnahme von Prof. Dr. Patrick Glauner 
Für das am 06.05.2021 stattfindende gemeinsame Fachgespräch der Ausschüsse für 
die Angelegenheiten der Europäischen Union des Deutschen Bundestages und der 
französischen Assemblée nationale 
Zur Politik der EU im Bereich der Künstlichen Intelligenz (KI) und insbesondere dem 
Verordnungsvorschlag der Europäischen Kommission zu KI (COM(2021) 206 final) 
Zusammenfassung 
Durch den am 21.04.2021 von der Europäischen Kommission veröffentlichten 
Verordnungsvorschlag soll innerhalb der EU ein einheitlicher Rechtsrahmen für 
Künstliche Intelligenz (KI) geschaffen werden. 
Die darin enthaltene sehr breite Definition von „KI“ klassifiziert nahezu jede 
bestehende und zukünftige Software als „KI“ und würde dann von diesem 
Regelwerk umfasst werden. 
Es gibt jedoch aufgrund von bestehenden Regulierungen – abgesehen von möglicherweise einigen wenigen neuartigen Anwendungsfällen – keinen KI-spezifischen 
Regulierungsbedarf. 
Durch den Verordnungsvorschlag besteht die Gefahr einer Überregulierung, die in 
der EU insbesondere den Einsatz oder die Entwicklung von KI-Anwendungen in 
sicherheitskritischen 
Anwendungsbereichen 
nahezu 
unmöglich 
machen 
würde. Hierdurch würden auch voraussichtlich chinesische und US-amerikanische 
Konzerne in ihrer Technologieführerschaft weiter gestärkt. 
Beruflicher Hintergrund des Verfassers 
Als Hochschullehrer bin ich an der TH Deggendorf schwerpunktmäßig in der Lehre und 
Forschung zu KI tätig. Zudem berate ich Unternehmen beim Einsatz von KI. Diese Tätigkeit 
umfasst die Definition und Umsetzung von KI-Strategien, die Implementierung von KIAnwendungen, deren Betrieb sowie Schulungen. 
Ausführungen im Einzelnen 
1. Zu breite Definition von KI 
KI hat das Ziel, menschliches Entscheidungsverhalten zu automatisieren und gilt daher auch 
als die nächste Phase der industriellen Revolution. Es gibt aktuell weder in der Wissenschaft 
noch der Praxis eine exakte und allgemein anerkannte Definition von KI aufgrund der 
Deutscher Bundestag 
Ausschuss für die Angelegenheiten der 
Europäischen Union 
Platz der Republik 1 
11011 Berlin 
Ihre Nachricht vom 
Telefon-Durchwahl 
E-Mail 
Unser Zeichen 
Ort, Datum 
26.04.2021 
Tel.: +49 991 3615-453 
patrick.glauner@th-deg.de 
Deggendorf, 
02.05.2021 
Prof. Dr. Patrick Glauner • Technische Hochschule Deggendorf 
Dieter-Görlitz-Platz 1 • 94469 Deggendorf 

Schnittmengen mit anderen Gebieten, wie z.B. der Statistik und Signalverarbeitung. Diese 
Problematik erschwert grundsätzlich jegliche Art von KI-Regulierung. 
Der Verordnungsvorschlag enthält in Article 3 (Definitions) mit Verweis auf Annex I eine 
eigene Definition von KI: Diese umfasst jede Software​Angemerkt sei, dass KI grundsätzlich auch durch rein hardwarebasierte Ansätze ohne Software implementiert werden 
kann. Der Verordnungsvorschlag lässt dies außer Acht und würde auf diesem Wege implementierte KIs grundsätzlich 
nicht regulieren. 
2 Viele gängige KI-Verfahren können auch dem Fachgebiet der Signalverarbeitung zugeordnet werden. Es gab in der 
Geschichte 
der 
Signalverarbeitung 
jedoch 
keine 
entsprechend 
breiten 
anwendungsfallunabhängigen 
Regulierungsversuche, da diese nicht praktikabel wären. ​ , die Methoden des maschinellen 
Lernens oder logikbasierte Verfahren nutzt. Sie schließt jedoch auch jede Software ein, die 
statistische Verfahren oder Such- und Optimierungsverfahren einsetzt. Hierdurch wird nahezu 
jede bestehende und zukünftige Software ohne KI-Bezug als „KI“ klassifiziert. Ein Beispiel 
hierfür ist jede Software, die den Mittelwert von Zahlen berechnet und somit ein „statistisches 
Verfahren“ anwendet. 
Da nahezu jede Software von diesem Regelwerk umfasst wird, würden somit für jedes Unternehmen unvorhersehbare Risiken entstehen, sobald es Software einsetzt oder entwickelt. 
2. Kein KI-spezifischer Regulierungsbedarf 
Bestehende Regulierungen, Gesetze, Standards, Normen, etc. von Technologien sind in den 
meisten Fällen vertikal aufgebaut und betrachten dabei allgemein Systeme, die bestimmte 
sicherheitskritische Anwendungsfälle adressieren, wie z.B. im Flugverkehr, im Straßenverkehr 
oder der Betrieb von Atomkraftwerken. Der genauen Implementierung dieser Systeme durch 
Hardware, Software oder einer Kombination daraus wird darin oft wenig bis keine Beachtung 
geschenkt. 
KI-Lösungen sind meist ein kleiner Teil von größeren Software-/Hardwaresystemen. Der 
Verordnungsvorschlag versucht diesen Anteil horizontal - und somit anwendungsfallunabhängig - zu regulieren2. Dieser Ansatz erscheint aufgrund der insgesamt meist 
unkritischen KI-Anwendungsfällen als nicht praktikabel. Es ist davon auszugehen, dass eine 
zusätzliche horizontale Regulierung zu unklaren Zuständigkeiten und Kompetenzstreitigkeiten 
führen würde. Zusätzliche Regulierungen sollten daher nur neuartige Anwendungsfälle 
adressieren, die von bestehenden Regulierungen noch nicht erfasst werden. 
Der KI Bundesverband spricht sich dafür aus, bestehende anwendungsfallspezifische 
Regulierungen anzuwenden und diese bei Bedarf KI-spezifisch anzupassen. ​https://ki-verband.de/wp-content/uploads/2021/03/Final_Regulierung_compressed-1-1.pdf ​  Der Bitkom ist 
ebenfalls der Ansicht, dass selbst eine allgemeinere horizontale Regulierung von 
algorithmischen Systemen nicht praktikabel sei. ​https://www.bitkom.org/sites/default/files/2020-04/20200402_kurzfassung-bitkom-stellungnahme-zumabschlussbericht-der-dek.pdf ​  
3. Fehlende Abgrenzung zu bestehenden Regulierungen 
Die in dem Verordnungsvorschlag in Article 5 verbotenen KI-Anwendungsbereiche sind sehr 
weit gefasst und führen aufgrund des entsprechend weiten Interpretationsspielraums​Beispielsweise könnte schon der Betrieb einer Suchmaschine auf einer potentiell nicht repräsentativen Datenbasis 
durch Article 5 (a) aufgrund der möglichen Auswirkungen der Suchergebnisse verboten sein. ​  zu 
Unsicherheiten für alle Beteiligten. Deutlich zielgerichteter wäre die Definition von konkret 
verbotenen Anwendungsfällen. Dabei sollte auch geprüft werden, ob diese überhaupt explizit 
verboten werden müssten oder ob dies schon heute durch andere Gesetze, wie z.B. dem 
Strafgesetzbuch oder der Datenschutz-Grundverordnung (DSGVO), der Fall ist. Neue Verbote 
zudem 
entsprechenden 
Anwendungsfälle 
im 
Allgemeinen 
und 
ohne 

Bezug zu KI adressieren, da sie (in Zukunft) ggf. auch ohne den expliziten Einsatz von KIMethoden implementiert werden könnten. 
Die Definition von konkreten Anwendungsfällen ohne expliziten Bezug zu KI wäre aus den 
gleichen Gründen daher auch in Article 6 (Classification rules for high-risk AI systems) für 
eine präzisere Definition von „Hochrisikoanwendungen“ hilfreich. ​https://www.politico.eu/article/6-key-battles-europes-ai-law-artificial-intelligence-act/ ​  Es ist zudem aus dem 
Verordnungsvorschlag unklar, was die Europäische Kommission konkret unter „sicheren“ 
Anwendungen versteht. Darüber hinaus ist offen, wie die „Sicherheit“ in einzelnen 
Anwendungsfällen überhaupt hergestellt werden könnte, insbesondere da viele Methoden des 
maschinellen Lernens den Faktor „Unsicherheit“ fest in ihrer Funktionsweise integriert haben. 
Auch droht durch den Verordnungsvorschlag in Verbindung mit bestehenden Regulierungen 
die Gefahr von widersprüchlichen und doppelten Anforderungen, u.a. bei der automatisierten 
Kreditvergabe. ​https://amp2.handelsblatt.com/politik/international/kuenstliche-intelligenz-neue-eu-regeln-fuer-ki-koennten-fuereuropa-zum-nachteil-werden-sorge-ueber-ausbleibende-investitionen/27113210.html ​  
4. Unerfüllbare Anforderungen an „Hochrisikoanwendungen“​Ich möchte mich insbesondere bei Tobias Manthey von der EvoTegra GmbH für die umfangreichen Diskussionen 
zum Thema „Hochrisikoanwendungen“ während der Verfassung dieser Stellungnahme bedanken. ​  
Neben der in Article 6 sehr breit gefassten Definition von „Hochrisikoanwendungen“ sieht der 
Verordnungsvorschlag u.a. in Article 11 (Technical documentation) entsprechende Dokumentationspflichten, in Article 60 (EU database for stand-alone high-risk AI systems) 
Registrierungspflichten, sowie in Article 62 (Reporting of serious incidents and of 
malfunctioning) Meldepflichten vor. Diese Anforderungen an die Entwicklung oder den Einsatz 
von KI in sicherheitskritischen Anwendungsbereichen sind vergleichbar mit dem Betrieb von 
Atomkraftwerken oder der Entwicklung von Flugzeugen. Sie erscheinen daher als 
innovationshemmend und unverhältnismäßig. 
Zur Umsetzung der in Article 64 (Access to data and documentation) beschriebenen Verfahren 
müsste 
Europäische 
Kommission 
praktisch 
EU-weite 
KI-Kompetenz 
aller 
Unternehmen, Hochschulen und Expertinnen und Experten in den entsprechenden Behörden 
bündeln und Hunderte Milliarden Euro in eine eigene Infrastruktur investieren. Die 
Anforderungen an die in Article 53 (AI regulatory sandboxes) beschriebenen Sandboxtests 
erfordern, dass das gesamte aus Daten und KI bestehende geistige Eigentum mit den 
entsprechenden Behörden geteilt werden müsste. Dies erscheint als unverhältnismäßig und 
nicht realisierbar. Zudem bestehen offene Fragen zur Haftung, falls durch Sandboxtests Dritte 
Zugriff auf das geistige Eigentum erhalten sollten. 
Aus diesen Gründen würde der Verordnungsvorschlag die Entwicklung oder den Einsatz von 
entsprechenden sicherheitskritischen KI-Anwendungen, wie z.B. jegliche sicherheitskritischen 
Assistenzsysteme in Fahrzeugen, in der Europäischen Union nahezu unmöglich machen. 
Bemerkenswert ist zudem, dass der finale Verordnungsvorschlag im Vergleich zu den 
vorherigen Entwürfen mit Hinblick auf den Einsatz von KI in sozialen Netzwerken deutlich 
entschärft wurde. Darin werden soziale Netzwerke nun gar nicht mehr konkret adressiert, 
obwohl gerade hier eine realistische Gefahr für die Beeinflussung durch KI liegt. ​https://www.cnbc.com/2020/09/19/2020-presidential-election-facebook-and-information-manipulation.html ​  

5. Überregulierung würde chinesische und US-amerikanische Konzerne stärken 
Ein Ziel der im Jahr 2016 verabschiedeten DSGVO war es, die Macht von US-amerikanischen 
Cloud-Anbietern zu begrenzen und europäische Unternehmen zu stärken. Mittlerweile hat sich 
jedoch gezeigt, dass genau das Gegenteil eingetreten ist. ​https://www.bloomberg.com/opinion/articles/2018-11-14/facebook-and-google-aren-t-hurt-by-gdpr-but-smallerfirms-are ​  Insbesondere die großen USamerikanischen Cloud-Anbieter verfügen über die personellen und finanziellen Ressourcen zur 
Implementierung von DSGVO-konformen Diensten. Zudem verfügen sie über die finanziellen 
Ressourcen zur Begleichung eventueller Strafzahlungen bzw. zur Vermeidung dieser durch 
das Führen von komplexen Gerichtsverfahren. 
Der Verordnungsvorschlag würde daher dazu führen, dass europäische Unternehmen durch 
eine Überregulierung im internationalen Wettbewerb zukünftig keine konkurrenzfähige 
Stellung einnehmen könnten. Chinesische und US-amerikanische Anbieter von KI-Lösungen 
würden durch diese Regulierung gestärkt werden. Dadurch könnten insbesondere chinesische 
Unternehmen mittelfristig europäische Unternehmen in jeder Branche vom Markt verdrängen 
bzw. diese übernehmen. ​Kai-Fu Lee, „AI Superpowers: China, Silicon Valley, and the New World Order“, Houghton Mifflin Harcourt, 2018. ​  
Empfehlungen 
Die Europäische Kommission sollte die Mehrwerte von KI für die Bürgerinnen und 
Bürger – insbesondere aus Sicht der zu erwartenden weiteren Wohlstands- und 
Lebensqualitätssteigerung – in den Mittelpunkt ihrer Arbeit stellen. Dabei sollte sie von 
einer Überregulierung von KI absehen. 
Durch 
eine 
Hightech 
Agenda 
Europa 
europaweit 
breite 
KI-
Qualifizierungsmaßnahmen geschaffen werden. Dadurch würden die Bürgerinnen 
und Bürger viel mehr zu Gestaltern der digitalen Transformation, als von ihr gestaltet 
zu 
werden. 
Zudem 
Transferprojekte 
zwischen 
Hochschulen 
und 
Industriepartnern zielgerichteter finanziert werden. Auch sollte eine europäische KISpitzenforschungsinstitution entsprechend der Europäischen Organisation für 
Kernforschung (CERN) gegründet werden. ​https://sciencebusiness.net/news/call-cern-ai-parliament-hears-warnings-risk-killing-sector-over-regulation ​  
Die Hightech Agenda Bayern​https://www.bayern.de/politik/hightech-agenda/ ​  kann dafür als positives Vorbild dienen. Hierdurch 
entstehen aktuell eine Vielzahl von KI-Maßnahmen zur Stärkung der bayernweiten 
Wettbewerbsfähigkeit, wie beispielsweise: 
KI-Studiengänge und -Vorlesungsangebote. ​https://idw-online.de/de/news765811 ​  
Gesellschaftliche Projekte, wie z.B. DeinHaus 4.0​https://deinhaus4-0.de/ ​  zum längeren und 
gesünderen Leben zu Hause. 
Transferprojekte zwischen Hochschulen und Startups, wie z.B. zwischen der TH 
Deggendorf und der EVOMECS GmbH zur KI-basierten Produktionsplanung. ​https://www.evomecs.com/wp-content/uploads/2020/10/131020-Presse_Final_GER.pdf ​  
KI-Transferzentren im ländlichen Raum, u.a. das KI-Zentrum in der Denkwelt 
Oberpfalz der LUCE Stiftung. ​https://www.luce-stiftung.de/kooperationsvertrag-zwischen-oth-amberg-weiden-und-der-luce-stiftung/ ​  
Gerne stehe ich für weitergehende Fragen und Diskussionen zur Verfügung. 
gez. Prof. Dr. Patrick Glauner 
Professor für Künstliche Intelligenz 
Fakultät Angewandte Informatik 