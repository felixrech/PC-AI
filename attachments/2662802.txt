FIM position on the Artificial intelligence draft Regulation 
Auteur : 
Roxana Turcanu 
Date de publication : 
21/07/2021 
rturcanu@fimeca.org - + 33 (0)1 47 17 64 87 
As a preamble, one has to acknowledge that the implementation of software techniques and approaches commonly 
referred to as "Artificial Intelligence" is not a novelty, as self-driving machinery is already placed on the market and 
put into service especially in the industrial and agricultural sectors. 
These advanced techniques also contribute to improve the reliability of components, to implement predictive monitoring and maintenance, to increase the lifespan of machinery, to optimise energy efficiency and to adapt production 
to customer demand. 
The deployment of these techniques represents a cornerstone for the competitiveness of the European Union, and 
it is imperative to foster innovation in this sector. 
Context and challenges 
In the context of the Artificial intelligence draft Regulation, FIM supports the risk-based approach. 
Nevertheless, it appears that this text has been developed without considering that many regulated products incorporating AI as a safety function, notably machinery subject to the provisions of Directive 2006/42/EC, are currently 
used in several sectors. Currently, the AI is considered in the framework of risk analysis, thus allowing manufacturers 
to take appropriate protection measures. Therefore, the articulation between this draft Regulation and the revision 
of Directive 2006/42/EC raises questions. 
Furthermore, the IA draft Regulation establishes obligations, particularly in terms of risk management and conformity assessment, which are already covered by the Machinery Directive, and which go well beyond what the Machinery 
Directive requires, notably concerning Chapters II and III of Title III. Today, the methodology adopted, for example 
by the Machinery Directive, is to carry out a risk analysis, to determine the applicable Health and Safety Requirements 
and to take the appropriate safety measures. In this draft Regulation, the provisions of Chapters II and III must be 
applied in an absolute manner. 
Finally, we make ours the title of the book written by Siri's co-creator, the Franco-American engineer Luc Julia: "Artificial intelligence does not exist". 
While this draft text seems to address legitimate concerns about the use of AI software, prohibiting certain uses, it 
is not at all adapted to the use in industrial products, especially if the industrial products are already regulated by a 
New Approach Regulation. 
This act will have a disproportionate impact on the companies’ competitiveness and will limit the European Union's 
capacity for innovation in this area. 
In this context, FIM would like to make comments and to contribute to the improvement of the proposal. 

2/4 
Scope (article 2) 
As a reminder, the manufacturer of a machine must carry out a risk assessment, according to the general principles 
and safety integration principles (paragraph 1.1.2 of Annex I of the Machinery Directive) and determine which essential requirements are applicable. Subsequently, he can use technical references, specifically harmonised standards, in order to implement solutions complying with the state of the art. The cornerstone of the New Approach is 
to ensure technology neutrality, i.e. the legislator is seeking results without imposing the means. 
Artificial intelligence is a technical tool among others, allowing to improve the functioning of a machinery and to 
make available new functionalities to the user. As a technology, it does not intrinsically create a new hazard. 
Considering these elements and those presented in the introduction, we strongly believe that AI systems integrated 
in products already in the scope of the New Approach regulation and used in the workplace should be excluded from 
this Regulation’s scope. 
Definitions (article 3) 
AI Definition 
FIM draws attention to the fact that, despite European and international past and present work, no given definition 
of artificial intelligence has reached a consensus, due mainly to the fact that there is no objective criterion to distinguish the concept of artificial intelligence from a conventional algorithm. 
We also note a gap between the definition given in the "Ethics Guidelines for Trustworthy AI" and the one adopted 
in this draft Regulation. 
Finally, the definition of artificial intelligence (Article 3.1) is too broad and includes software applications already 
widely used in the industry. This is the case, for example, for logic-based approaches. 
Substantial modification definition 
Furthermore, the introduction of substantial modification concept in the Artificial intelligence draft Regulation is a 
source of legal insecurity, as it is in the draft revision of the Machinery Directive (please see FIM position on this 
matter). 
In this context, we propose the following amendment: 
“Substantial modification’ means a change to the AI system following its placing on the market or putting 
into service, not foreseen by the provider, which may affect the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or and result in a modification to the intended 
purpose for which the AI system has been assessed;” 
Requirements and obligations of Chapters II et III of Title III 
The different provisions of Articles 8 to 15 seem to be disproportionate to the objective of the draft Regulation. 
Moreover, the risks these provisions address have already been taken into account by the essential requirements of 
the various regulations listed in Annex II, Section A, in particular by the Directive 2006/42/EC. Only, the legal logic 
adopted by these regulations is different from the one in the AI draft: they allow manufacturers to implement agile 
and proportionate solutions to achieve health and safety general objective. 
Article 9 introduces the issue of the risk management system, which consists of a continuous iterative process run 
throughout the life cycle, thus requiring regular systematic updating. 
This requirement is contrary to the current provisions of the NLF. In the case of a machinery incorporating a "high 
risk" AI system, the New Legislative Framework states that it must remain safe throughout its life cycle. While it is 
likely that machineries may continue to learn (supervised or unsupervised learning), after they have been put into 
service, this functionality can only be the result of a deliberate intention by the manufacturer, for example to improve 
the performance of the machine. In this context, the manufacturer must, by design, control the learning capability, 

3/4 
to ensure an adequate level of safety throughout the life cycle of the machine. This requirement is covered by the 
current provisions of the Machinery Directive and other New Approach texts. 
The extent of requirements imposed on data is a crucial matter, especially with regards to supervised learning (article 
10). At the same time, some requirements are not suitable for industrial use, particularly those concerning "possible 
biases" and the notion of "free of error", the latter cannot reasonably constitute an absolute criterion. 
The provisions relating to the technical file (Article 11) and user information (Article 13) are already in the scope of 
New Approach texts and therefore presently implemented for such systems, in a way that is proportionate to the 
objective sought by the legislator. 
We also question the feasibility of the record-keeping sought in Article 12. The storage of large amounts of data 
relating to the use of an AI system and their exploitation in the framework described in Article 61 represents a significant burden for companies, while the benefit seems to be limited. Additionally, how will market surveillance authorities be able to analyse and interpret records containing large amounts of information? 
The provisions of Article 13 on transparency are already laid out by the New Approach regulations in a proportionate 
way. Likewise, in an industrial context, the AI system is not intended to be used "on" people (Article 13.3.b.iv). 
Article 14 on human oversight remains the most problematic in the context of industrial or agricultural use. Inarguably, the main AI use cases in these sectors concern driverless machines operating in factories or in open fields. This 
article imposes the presence of an operator, whereas in the framework of the Machinery Directive the risk analysis 
is the key element that allows the manufacturer to determine whether human oversight is required or not and if it 
is, under what operational conditions it should be implemented. 
The provisions laid down in Article 15 (accuracy, robustness, and cybersecurity) are already covered by the New 
Approach texts and therefore already implemented for such systems, moreover in a proportionate manner regarding 
the objective sought by the legislator. 
Article 17 requires the implementation of a quality management system, on top of the voluntary provisions of the 
well-known and applied quality management systems standard (ISO 9001). 
Article 23 requires the transfer of data to the market surveillance authorities upon reasoned request. We question 
the ability of these authorities to interpret records containing hundreds of thousands of pieces of information (see 
also the commentary on Article 12). 
Article 29 sets out obligations for AI systems users. In our sector, these obligations would concern essentially work 
equipment, the use of which is already regulated by Directive 2009/104, based on Article 153 TFEU. According to the 
Blue Guide (article 3.6 End-user) “Union harmonisation legislation does not create obligations for the end-users of 
the products in their scope”. 
FIM requires that these obligations do not apply to regulated products (see section A, Annex II) incorporating AI as a 
safety function. 
Common specifications (article 41) 
The possibility for the European Commission to adopt common specifications by means of implementing acts seems 
impractical in terms of technical expertise. This possibility is also raised in the context of the revision of the Machinery 
Directive. 
In addition, this provision contravenes the New Legislative Framework, which put forwards the reference to voluntary harmonised standards. 
FIM proposes to delete article 41. 

4/4 
Conformity assessment for integrated “high risk” AI systems (article 43) 
The link between the draft IA Regulation and other NLF legislation should be made to avoid double conformity assessments. The obligations of the manufacturer of a regulated product (in relation to section A of Annex II) which 
incorporates an AI which has already undergone a conformity assessment should be clarified. 
Les industries mécaniques, premier employeur industriel de France, conçoivent des pièces, composants et sous-ensembles et équipements pour 
tous les secteurs de l’économie : 
Pièces mécaniques issues d’opération de fonderie, forge, usinage, formage, décolletage, traitement de surface, etc. 
Composants et sous-ensembles intégrés dans les produits des clients 
Équipements de production (machines, robots, etc.) et équipements mécaniques (pour la santé, l’agriculture, les TP, le bâtiment, 
la restauration, la lutte contre l’incendie, l’approvisionnement en eau, la production d’énergie, la mesure, …) 
Produits de grande consommation (arts de la table, outillage, ...) 