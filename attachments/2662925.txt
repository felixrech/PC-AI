The European Tech Alliance welcomes the
European Commission’s proposed AI Act as a
good balance between supporting muchneeded AI innovation in Europe and having
safeguards in place to ensure high safety
standards and public trust in AI. We
welcome the EU’s leadership in creating an
AI regulatory framework while supporting
Europe’s global competitiveness in that field.
For EU businesses, many of whom operate
cross-border, it is crucial to have a single set
of EU rules on AI rather than a fragmented
country-by-country approach. 
With this in mind, we set out some key points
that we believe are important for Council
and Parliament to take onboard during
discussions on the AI Regulation.
Context
AI is a key technology used across areas as
diverse as health, mobility and e-commerce.
Within the EUTA there is a diverse and
widespread use of AI technology. We use it to
make 
our 
companies 
more 
efficient 
and
productive while constantly improving the range
of services that our customers can access. It is
also crucial to our success in competing with
other businesses around the globe. AI is key to
creating skilled jobs and driving innovation in
Europe as EUTA Members and other EU tech
businesses implement and scale the technology. 
As outlined in our previous statement on highlevel principles of AI, we very much support and
welcome a differentiated approach to AI
regulation and believe that risk is the right
metric to define the scope of new AI rules.
A focus on regulating high-risk AI applications is
the right way forward to ensure a balance
between supporting AI innovation in Europe and
ensuring the right safeguards are in place for AI
uses that create more risks to society. It is
important to maintain this narrow focus. Here
below we include several points regarding the
scope of the proposal which we believe would
benefit from further clarity and legal certainty.
Kristin Skogen Lund
President of the EUTA
Kristin Skogen Lund
Magdelena Piech
Chair of the EUTA
Magdalena Piech
June 2021
Foreword
 The European Tech Alliance
Welcomes the Artificial
Intelligence Act 

Definitions
Some key definitions of the draft Artificial
Intelligence Act should be clarified: The AI
definition set out in the proposal is too broad
and would include a vast amount of systems
that may not always be considered AI per se.
We therefore encourage the EU co-legislators
to adopt the AI definition proposed by the
High-Level 
Expert 
Group 
on 
Artificial
Intelligence. Similarly, the process to assess
whether some AI systems should be considered
high risk is only vaguely defined in Annex 3,
which would have a negative impact on
product planning decisions. The definition of a
“safety component” (Art. 3(14) is also a good
example of this lack of clarity, as the definition
refers to ambiguous concepts which are not
further 
defined 
(e.g. 
“safety 
function”).
Similarly, the definition used for “manipulative,
exploitative and subliminal techniques” in
relation to prohibited AI systems and the exact
definition of a “bias” should be made explicit
to avoid legal uncertainty.
Ensure a Level Playing Field
AI is paramount to the EU competitiveness and
the future AI regulation should ensure a level
playing field between EU and third country
developers: It is important to note that the
proposal lays down rules for placing an AI
product onto the market, putting the product
into service and the use of AI systems within
the EU. The training of AI, however, is not part
of the scope under Art. 1(a). Under the current
proposal, it will be possible for third country
developers to train their AI models in third
countries with lower AI regulations, which may
turn into a competitive advantage.
Meanwhile, as AI developers, though we
welcome 
possibility 
to 
conduct
conformity assessments internally, we
would also welcome reassurances that
the risk assessment procedure will not be
too 
burdensome. 
We 
suggest 
that
providers of AI systems should only be
obliged to register high risk AI systems on
the proposed EU data base, if they
conclude they cannot mitigate risks and
ensure compliance after conducting an
internal conformity assessment. 
As EU companies develop robust AI
models to keep them competitive on the
market, having to wait for official
approval may generate the need for
continuous 
official 
certification.
Innovation 
would 
be 
hampered 
if
regulatory authorities could control AI
systems before placing them on the
market, as it may create “a bottleneck”
and 
significantly 
slow 
down 
the
development of new AI models. The
authorities may conduct external audits
to all of the documentation provided by
the internal controlling entity.

Avoid a Fragmented Approach
The digital Single Market is crucial for EUTA
members to scale-up and be competitive at
a global level. We therefore stress the need
to avoid a fragmented approach across
Europe: As per the enforcement powers, we
note the Commission proposes that national
competent authorities should conduct checks
and assessments on an ex-post basis. As
many of our business models can be
regulated by various market authorities
when we operate across markets, it will be
essential 
to 
clarify 
which 
surveillance
authority will be granted AI oversight over a
specific sector. Moreover, penalties should
be imposed based on a clear catalog of
prerequisites, based on specific enumerated
infringements. 
Increasing 
business 
risks
around AI development in a disproportionate
way may have a stifling result on AI
development in the EU, because authorities
would be able to act arbitrarily, without any
specific administrative imperative. 
Regulating Low-Risk AI
Codes of Conduct for regulating low-risk AI
applications 
should 
be 
right 
way
forward: The EUTA is particularly pleased to
see the role that Codes of Conduct will play
in this future regulation. Several EUTA
members are already developing their own
internal codes and as the EUTA we stand
ready and eager to work together with the
European Institutions to develop these codes
together.
Final say
The 
publication 
of 
proposed 
AI
Regulation comes at a pivotal moment for
Europe 
and 
will 
have 
far-reaching
implications and long-lasting effects. We
will continue to provide use-cases and
examples of AI applications in order to
contribute to the ongoing policy debate and
look forward to the clarification of key
concepts and definitions to promote legal
certainty to businesses and end-users alike.