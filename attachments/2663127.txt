Artificial intelligence and cities 
The Covid-19 pandemic has disrupted our societies beyond precedent. The global health crisis has 
enormous economic and social repercussions. It has also highlighted the urgency of securing a 
people-centred digital transformation in Europe, which is essential to ensure social and economic 
resilience in our cities. European digital strategies must fully support the mainstreaming of 
digitalisation as part of rights-based public service delivery. 
We recognise the crucial role of AI technologies to respond to global public health emergencies. 
At the same time, human rights and European fundamental values must be fully protected. The 
next EU regulatory framework on trustworthy AI must specifically address the use of AI in public 
health emergency prediction and management making sure AI is used without undermining 
ethics and fundamental rights.  
More generally, artificial intelligence is an enabler of change for local governments. AI is already 
transforming the governance of the city and society. Public administrations can increase 
1. AI needs data. A huge amount of data produced and collected in cities, crucial for local 
governments to improve public services and policies, is currently gathered and owned 
by the private sector. A single market for data needs to benefit all ecosystem players, 
including local governments. We call for legislative action to ensure access and use of 
business to government (B2G) data sharing in the proposed Data Act planned for 2021. 
2. Liability and accountability in AI are key to guaranteeing people’s safety. AI safety and 
reliability tests are burdensome; local public authorities do not have the expertise or 
the budget to carry them out. A central EU body or agency should develop the necessary 
verification and validation procedures, and guarantee security and public safety. 
3. Some AI uses can be considered high-risk. More detailed and clear descriptions of the 
possible high-risk uses are necessary to clearly understand when a local public 
administration is affected. We propose establishing a task force composed by AI experts 
and local public administration experts to better define the different possible high-risk 
uses. 
4. AI could have a disruptive effect on the future of the job market and skills development 
in cities. ESF+ and the Youth Guarantee funding should focus more on digital literacy 
training, skills development and gender equality. 
5. Local governments are crucial to fostering an ecosystem of excellence and trust in AI in 
Europe. The EU must work with local governments in the development of the future 
regulatory framework for a trustworthy AI, taking into account the principles defined by 
the Cities for Digital Rights coalition. 
People-centred Artificial 
Intelligence (AI) in cities 
March 2020 

efficiency and productivity while reducing costs through automation of processes and tasks. City 
governments can use algorithms and machine learning applications to predict service demand 
and anticipate urban problems, improve decision making and the delivery of more and 
innovative public services. 
As AI is becoming more advanced and more accessible, city authorities are increasingly 
experimenting and piloting AI, in many cases in combination with other tools such as IoT, 5G or 
Big Data technology, leveraging their potential while understanding new patterns and trends. 
As with the first smart city projects​Becoming cities of the future, lessons learned from experimenting smart cities, October 2016, https://bit.ly/30Hy7Rj ​ , cities use the results and lessons from AI experimentation 
to develop action plans and strategies, often in collaboration with national governments and 
with the support of local and regional stakeholders. 
However, AI adoption in cities is a long and costly process. Good data collection, processing, 
management and opening is expensive and requires specific, high-level competences as well as 
new governance approaches. A broader uptake of AI technology locally requires intensive 
financial investment from the national and EU level to ensure adequate technological and skills 
development in city administrations. 
Opportunities and challenges for cities 
AI is a powerful means to fully transform Europe’s cities into sustainable, inclusive and smart 
places for people to live. ​EUROCITIES statement ‘Smart cities in the age of the digital revolution’, March 2019, https://bit.ly/38khQoB ​  AI development also helps cities to reach the sustainability goals of 
the Green Deal​EUROCITIES statement on the Green Deal (to be finalised), March 2020, https://bit.ly/3aNHkNg ​  especially in sectors such as air quality and mobility. Local authorities use AI 
to leverage IoT applications and to predict the level of pollution in cities. City governments can 
get valuable information by analysing social media data on tourists’ behaviour and to adapt 
cultural policies and investments to needs. Cities use machine learning to predict parking space 
availability to then efficiently redirect drivers into a free area. Through AI chatbots, 
governments can communicate faster with citizens and stakeholders increasing their sense of 
participation. 
While AI adoption is increasing in cities, challenges connected to it are too. Disruption in the 
labour market and skills gap, safety and liability, and digital rights protection are the most 
important ones for cities. 
Disruption in the labour market and skills gap 
The rapid and exponential technological progress in AI will have a disruptive effect on the job 
market. While it is still difficult to predict to which extend AI and robotics will affect 
unemployment rate, polarisation of jobs, income inequalities or discrimination in the labour 
market, the risks seem high. AI, powered by machine learning, automates tasks that might cause 
displacement or even replacement of workers, polarisation of job demand between high-skilled 
and low-skilled jobs, and worsen the status of already fragile groups of people, such as the 
digitally excluded, long-term unemployed and low-skilled people. There is a strong need in 
cities for skills development including long-life learning programmes, training for low-skilled 
people and early education on digital skills - also oriented to engage more young women into 
technology. ​EUROCITIES report on equal opportunities and access to the labour market, December 2018, https://bit.ly/2wrt8tL ​  
Safety and liability 
AI applications can hide bias or amplify existing bias. Machine learning, powered by data, has 
no consciousness, reflects the human prejudices and opinions of the developers, and repeats 
and perpetuates data which, if flawed or incorrect, can lead to misinterpretations and errors. 
When AI is used, for example, for urban mobility (e.g. autonomous cars) or environmental (e.g. 
air pollution or water security) purposes, data bias might lead to higher risks for people’s 

safety. ​EUROCITIES statement on Integrating transport automation in the urban system, February 2019, https://bit.ly/3atmlyN ​  AI systems and algorithms must undergo rigorous testing to check their reliability and 
safety, meaning time, the right expertise and costs. Liability issues are also a major concern 
for cities. If a driverless bus runs over a pedestrian, who is responsible? There are many parties 
involved in an AI system (data provider, designer, manufacturer, programmer, developer, user 
and AI system itself), liability is difficult to establish when something goes wrong and where 
there are many factors to be taken into consideration. 
Digital rights 
Fundamental human rights might be put at risk in an AI age. AI systems can impair freedom of 
expression, privacy and data protection, equality and fairness. Local governments are actively 
committed to protecting, promoting and monitoring citizens’ human rights in the digital sphere. 
Through the Cities for Digital Rights​Cities for Digital Rights https://citiesfordigitalrights.org/ ​  coalition, supported by EUROCITIES, over 50 cities all over 
the world are working to provide trustworthy and secure digital services and infrastructures for 
the common good. From apps that gamify participation in local consultations to video-based 
solutions that promote community interaction, cities are developing services to decrease 
inequalities, discrimination and help reach traditionally excluded communities. Local 
governments are implementing mobility plans and actions in cooperation with local stakeholders 
to secure people’s privacy while obtaining crucial real-time data visualisation through traffic 
cameras.  
Guiding AI principles for Europe 
Despite the differences in the level of AI experiments and deployment across Europe, local 
governments share the same values and principles when it comes to using AI. 
− People-focused AI: People are at the centre of AI deployment in cities. AI should be used to 
facilitate access and deliver better services to citizens - not to track, control or direct people’s 
behaviour. AI systems should serve people, and solutions should be based on EU societal and 
ethical values. 
− Collaborative intelligence for successful AI deployment in cities: AI must complement and 
augment human capabilities, not replace them. 
− Data is the engine of AI: The quantity, quality and transparency of used data is a key success 
factor for AI adoption. High quality annotated open data should be more available for use by all 
actors. Those using the data have the responsibility to ensure its integrity, authenticity, 
consistency and accuracy. A description of the data on which an algorithm is trained should be 
published. 
− Safety and security: AI must serve and protect people; systems should be accurate and perform 
reliably. Security and privacy should be integrated into systems from the design phase. 
− Accountability and transparency: As the impact of AI on people’s safety can be high, strong 
accountability and transparency measures and mechanisms should be ensured. Oversight 
measures covering responsibility and liability need to be put in place. 
Facilitate access and use of private data 
AI thrives on data. Full access, share and use of data by all ecosystem actors is a prerequisite for 
AI development and implementation. A growing amount of data is generated every day in cities 

by people and machines, but its use and re-use is not fully exploited . ​Data, People, Cities – EUROCITIES citizen data principles in action, November 2019, https://bit.ly/3afmF3Y ​  We welcome the 
Commission proposal to improve access to data establishing common European data spaces that 
will facilitate data being used and shared between different players, also cross-border, as well as 
data quality, interoperability and standards within and across sectors. We strongly believe in 
strenghtening this effort through initiatives that focus on semantic interoperability by shared 
definitions, both technical and multilingual. Ensuring GDPR compliance, we will monitor the 
governance process and decisions on which data will be used and in which situations. We will also 
monitor the standardisation of data formats, protocols and registry that could help promote 
exchange of data and knowledge. However, a huge amount of data is currently gathered and 
owned by the private sector. The use and management of that data is crucial for public authorities 
to improve public services and policies including urban planning, mobility and housing while 
ensuring democratic control over data and mitigating the negative societal impact of AI. Access 
and use of business to government (B2G) data needs specific regulation. We therefore call for 
action to be taken on B2G data sharing in the proposed Data Act planned for 2021.  
Accountability and transparency measures 
AI systems and algorithms can hide bias which might lead to high risks for people’s safety. Safety 
and reliability tests of AI systems are burdensome; local public authorities do not have the 
expertise or the budget to carry them out. A central EU body or agency should develop the 
necessary verification and validation procedures, and guarantee security and public safety. 
Liability and accountability in AI are key to guaranteeing people’s safety. Tangible measures 
must be applied to close the accountability gap such as: 
full access to the algorithm code by the competent authorities whenever needed for 
inspection or verification purposes 
obligations to report which algorithms are used 
a framework for algorithmic auditing that supports AI system development end-to-end 
fostering an open source code philosophy 
Scope of a future EU regulatory framework 
We agree with the Commission’s opinion on applying the high-risk approach and to use the 
cumulative criteria of the ‘sector’ where AI applications are employed as well as the intended 
‘use’ of AI within each sector. More detailed and clear description of the possible uses that are 
considered high-risk is essential to clearly understand when a local public administration is 
affected by a specific use. Considering the multitude of possible uses of AI in several sectors of 
responsibility for public authorities and the complexity of the classification exercise, we 
recommend a task force composed of experts on AI and public administration experts, also at 
local level, to better define the different possible high-risk uses. 
Funding for skills development 
Local governments need support in managing the digital transition and to tackle the possible 
disruptive effects of emerging technologies in the labour market. City governments are key 
players in supporting the creation of new jobs as well as the development of skills and 
knowledge; they are the right level to facilitate the dialogue between all actors involved, 
including national and regional governments, educational institutions and the private sector. 
Digital skills development must be enhanced in city administrations, but local governments face 
strong competition from global technological companies in terms of attracting employees with 
the right digital skills. We welcome the Commission’s strong focus on skills development as part 
of its digital strategy including the update of the EU Skills Agenda, the dedicated funding in the 

proposed Digital Europe Programme to advanced digital skills and the update of the Digital 
Education Action Plan to increase education quality through AI. However, cities should also be 
able to access and use ESF+ and the Youth Guarantee funding that focus more on digital literacy 
training and skills development to tackle disruption in the labour market and skills gap or 
mismatch. This should specifically include women empowerment measures to combat gender 
imbalance in STEM. 
Building an ecosystem of excellence and trust together 
Local governments are crucial to fostering an ecosystem of excellence and trust in AI in Europe. 
With increasing urban populations and access to talent and skills, universities, companies and 
infrastructures, city authorities can facilitate research and innovation activities and processes, 
and create the right conditions to boost AI deployment, including by SMEs. Acting as open 
participation and collaboration platforms, using and making data and information available, city 
authorities enable crowd-creation, foster experimentation, share technological expertise and 
co-develop ideas and solutions. 
Local governments are key to building confidence and trust in AI. Through experimentation and 
early adoption of AI, city governments identify possible safety and fundamental rights risks, and 
propose trustworthy solutions. As the level closest to citizens, local authorities engage with 
citizens, understand their fears and concerns and develop together possible solutions. The EU 
must work with local governments in the development of a future regulatory framework for a 
trustworthy AI that takes into account the principles defined by the Cities for Digital Rights 
coalition​Cities for Digital Rights https://citiesfordigitalrights.org/ ​  and that supports cities to uptake and upscale AI in Europe. 