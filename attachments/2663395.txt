www.efpia.eu  1 
Summary 
Artificial Intelligence (AI) powered solutions have the potential to enhance the healthcare ecosystem. 
EFPIA’s vision is to maximise the potential of using AI to develop novel therapies and approaches to 
identify, treat and care for patients more efficiently, while preserving patient safety and privacy. 
EFPIA inputs into ongoing policy debates suggesting recommendations on AI to ensure that they foster 
innovation while guaranteeing high healthcare standards and patient safety. This position paper 
contains key areas for consideration by legislators and regulators as they are developing a legislative 
framework on AI.  
EFPIA fully embraces the benefits which AI powered solutions could bring to the healthcare ecosystem 
and its potential to positively impact the lives of patients and support healthcare professionals in 
delivering care. EFPIA supports adaptation of existing frameworks for the acceptability in decision 
making and adoption of AI technologies to provide a path through which AI can be developed, 
adopted and used in healthcare systems. The innovative biopharmaceutical industry recognises the 
current challenges faced by European health systems and aims to work with partners in achieving 
sustainable value-based and outcome-focused healthcare by leveraging opportunities provided by the 
increasing use of AI technologies. 
EFPIA recommends the following aspects to be taken on board in future AI policy development: 
Rules on AI should be adequate, appropriate, clear and consistent, fostering a harmonised 
approach across the EU. 
AI literacy and competence building is an enabler. 
Access to high-quality data is critical to AI deployment. 
Data Governance is fundamental. 
Transparency should be defined in a way that it allows for sufficient interpretability or 
explainability of the AI and underlying data sets. 
Intellectual Property protection should be effective and predictable. 
Leadership and coordination are needed. 
The EU has an opportunity to leverage its capabilities in healthcare by accelerating the development 
of an AI ecosystem through inclusivity, capacity and trust. EFPIA wishes to underline the importance 
of this agenda to the pharmaceutical industry and its commitment to contribute to its uptake and 
successful adoption. 
EFPIA Position Paper on Artificial Intelligence 
Author: Digital Health WG Date: December 2020  Version: FINAL 

www.efpia.eu  2 
EFPIA Position and Recommendations on AI 
AI has the potential to make a significant difference to healthcare. A broad range of techniques can be 
used to create AI solutions to carry out or augment healthcare tasks that have until now been 
completed by humans or have not been possible previously. AI can bring significant opportunities for 
keeping people healthy, improving care, saving lives and saving money for healthcare systems. It can 
equip healthcare professionals (HCPs) with new tools to gain detailed data analyses delivered through 
the generation of novel scientific insights and allow them to dedicate more time to irreplaceable 
human interactions. AI will also provide an automation of manual tasks to aid efficiency and 
standardization. The boost in efficiency and efficacy strongly depends on the availability of data to 
train AI models and the adoption of AI in the healthcare sector. With appropriate support, patients will 
benefit from an increase in evidence-based care, higher quality interactions with healthcare 
professionals and more personalized care plans. Patients will be empowered to play an active role in 
managing their health and wellbeing that can save time and money. AI platforms also hold the 
potential to design optimal drug combinations that are effective and based on real experimental 
data rather than mechanistic assumptions. ​Mid-Term Review on the implementation of the Digital Single Market Strategy - A Connected Digital 
Single Market for All. SWD (2017) 155 final. ​  AI platforms can also perform predictive modelling using 
data mining and probability to forecast or estimate more granular, specific scenarios or outcomes, this 
can be used to predict the benefits in combining specific drugs (combination therapies). 
EFPIA believes there is a need for a common definition of AI in healthcare. There are many definitions 
of Artificial Intelligence (AI) with no general accepted definition. This position paper recognizes AI as it 
is described in the documents of the AI High-Level Expert Group (HLEG)​https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai ​  and considers ‘AI as a 
problem-solving software and/or hardware used by humans to search for solutions by analysing the 
environment and taking actions – with some degree of autonomy’. Specifically, we use the term AI 
primarily to refer to ‘computational modelling, such as statistical analyses, neural networks, data 
science, natural language processing and machine learning (including deep learning) all tools used by 
humans in furtherance to medicine development, diagnostic development, and patient care’. This 
understanding is different from the colloquial, all-purpose nature of the term “artificial intelligence” 
that is used in general parlance. Most notably, our definition is not focused on so-called “artificial 
general intelligence,” which is a different category of AI relating to self-aware, intelligent machines. 
The development of artificial general intelligence generally remains in the future and is not 
representative of the current use of AI by most companies and other healthcare organisations. 
AI systems designed for use in the healthcare space need to be established through evidencable 
training, testing, and development that can demonstrate safe and efficacious outcomes with 
prospective validation. In regards to autonomous AI, the expectation around understanding decision 
making rationale should be consistent with what is currently required in the development of 
pharmaceutical drugs, biologics, medical devices, and other therapeutics. 
Importantly, patients and citizens should be central to the feedback loop and be empowered in the 
context of AI and digital technologies to build trust with patients and citizens and adjust to the needs 
of the users. AI systems should promote fairness, inclusion and avoid bias as well as providing 
transparency and enabling accountability. To support this setup there is a need to assess AI systems 

www.efpia.eu  3 
to determine the appropriate level of human involvement in AI-augmented decision-making to ensure 
that appropriate oversight is embedded into business processes.  
The aspiration to leverage AI technology for the benefit of patients cannot be considered without all 
the value-adding steps executed by different healthcare partners throughout the value chain. In 
particular, the innovative pharma industry uses AI for discovering and developing novel therapies, 
personalised medicine (including biomarker development), improving diagnostics (through 
advanced machine learning for imaging), business optimisation, and engaging with and empowering 
patients and healthcare professionals. 
AI applications are being considered across the pharma value chain:  
EFPIA supports a sector-specific approach including a systematic assessment on which guidelines or 
regulations exist already and identify gaps or overlaps. The innovative biopharmaceutical sector has 
considerable experience in defining good practice guidelines and implementing regulations to 
contribute to the development of an AI ecosystem in Europe. EFPIA offers to facilitate or participate in 
a series of discussions with pharmaceutical/healthcare/medical technology sector to formulate a 
forward-looking strategy to improve key aspects of drug discovery, patient care and healthcare 
delivery that could be enhanced with the use of AI. 

www.efpia.eu  4 
EFPIA believes that the following principles and recommendations should guide the designing of an AI 
legislative framework: 
1. Rules on AI should be adequate, appropriate, clear and consistent, fostering harmonised 
approach across the EU 
• Rules on AI must be simple and clear in how and when to apply them, sufficient in their scope 
to regulate current and future potential uses without restricting innovation, nonoverlapping/duplicative, align with global standards and ensure fair and consistent 
implementation by stakeholders to keep a level playing field for all operators. They are critical 
in building trustworthiness as AI used for health decision-making requires an appropriate 
oversight to facilitate responsible AI. Acknowledging that AI will present new legal challenges, 
we support a flexible regulatory framework that is effective whilst not being excessively 
prescriptive that it impedes innovation or affects negatively EU’s competitiveness and 
position on the global stage. Given the speed of change in technological capabilities like AI, 
new approaches to existing guidance/regulations are needed to ensure that they remain 
robust as technology advances e.g. systems languages, total product lifecycle. Unclear 
regulation could create inconsistency in interpretation across the value chain e.g. divergent 
national interpretation of GDPR, and create confusion impeding wider application of AI. It 
will be important that the framework for AI use in healthcare is advanced globally across 
jurisdictions e.g. EU, US, Japan etc. to ensure similar frameworks are adopted. 
• EFPIA supports adapting regulations rather than creating new rules, providing clarification 
and guidelines, and exploring other mechanisms such as self-regulation. While it is essential 
to address any safety concerns, an unbalanced policy could lead to restriction of AI outside 
of its validated use and consequently leave patient benefits unexplored. 
• Continues engagement with the broad stakeholder base in policy development would inform 
outcomes proactively (e.g. use of regulatory sandboxes for testing, consortium-led data 
collaboratives to inform IT standards and open source protocols) and ensure the 
development of an aligned EU AI ecosystem (e.g. based on International Medical Device 
Regulators Forum principles and guidelines) that is attractive to global innovators and is 
supportive of future advancements.  
• EFPIA recognises the need for global regulatory alignment as part of a global approach and 
embrace existing legislation such as Medical Devices Regulation (MDR)​https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32017R0745 ​ /In vitro Diagnostic 
Medical Devices Regulation (IVDR). ​https://eur-lex.europa.eu/eli/reg/2017/746/oj ​  EFPIA supports Commission’s approach to regulate AI 
based on risk, acknowledging CE marking system for high risk applications in healthcare 
which is already addressed by MDR/IVDR. 
• There are many stakeholders involved in providing healthcare to citizens and increasingly 
these will be interconnected as an ecosystem, sometimes with AI solutions intertwined as a 
fundamental supporting tool and often instead of a human medical professional. Healthcare 
decisions can be significant and there is sometimes the need to clarify liability for decisions 
made. For the system to trust and rely on AI solutions embedded in the healthcare ecosystem 
there will need to have a clear guidance on liability and explicit transparency to patients in 
the role of AI in their treatment. 

www.efpia.eu  5 
2. AI literacy and competence building is an enabler 
• EFPIA views the skills agenda as being critical when it comes to AI in healthcare. EFPIA 
supports partnerships between the public and private sectors, bringing together leadership 
and commitment from organisations to ensure coordination of research and innovation in 
AI. EFPIA members recognise through their accelerator and innovation hub initiatives that 
SMEs and academia are key components of innovation in AI, and that SMEs require both 
access to finance and support in the adoption of AI. Therefore, coordination of research 
centres of excellence and leadership from a lighthouse centre of research, innovation and 
expertise is critical to establishing European leadership in AI. 
• It is important that healthcare professionals have the right skills to understand and utilise AI 
solutions and to have ability to exercise oversight in line with their mandate. There should 
be an educational focus on use of AI-based solutions for example in healthcare workforce’s 
curricula and complementary courses as part of continuous professional development. 
Similarly, a focus on AI literacy for the broader society and skills by patient communities 
would also be warranted. EFPIA calls for investments e.g. as part of EU4Health 2021-2027 
programme, in reskilling and lifelong learning opportunities which are required to 
overcome social and cultural challenges affecting stakeholders in healthcare.  
3. Access to high-quality data is critical to AI deployment 
• In order to assure high quality AI solutions and to safeguard the EU’s competitiveness in the 
international AI marketplace, the easy yet compliant access to a significant amount of highquality, representative data will be indispensable. This would further help to reduce bias, 
discrimination and ensure highest levels of safety and robustness of AI solutions in 
healthcare. Patients and citizens should be empowered through feedback mechanisms to 
help address bias and other potential concerns. EFPIA supports initiatives which can provide 
for increased and appropriate access to high-quality health data, e.g. through the proposed 
EU Health Data Space. In particular, we encourage the Commission to identify obstacles that 
would prevent an adequate use and deployment of AI in Europe through optimal data 
sharing between stakeholders in a data-agile economy and to explore appropriate 
standards, tools or frameworks to incentivize data sharing​https://eur-lex.europa.eu/legal-content/EN/TXT/?qid=1593073685620&uri=CELEX%3A52020DC0066, p. 13 ​  such as for example Findata. ​https://www.findata.fi/en/about-us/what-is-findata/ ​   
4. Data Governance is core 
• GDPR is aimed at standardising and strengthening the protection of personal data, including 
the rights of individuals to be better informed about how their data are used. It also sets out 
clear responsibilities and obligations on healthcare professionals and companies using such 
data, with stringent penalties for infringements. 
• GDPR requirements and concepts, local and institutional regulations, as well as ethical 
oversight, may require further clarification if they are to support innovation in AI. 
Furthermore, it will be important to address the fragmented application of the GDPR and 
other legislation bearing on scientific research across the EU. It has to be ensured that data 
are managed and analysed within a secure and ethical governance framework. ​https://www.hma.eu/fileadmin/dateien/HMA_joint/00-_About_HMA/03-Working_Groups/Big_Data/Final__Priority_Recommendations_of_the_HMA-EMA_joint_Big_Data_Task_Force.pdf ​  Human 
involvement in AI-augmented decision making ensures that appropriate oversight is 
embedded into business processes.  

www.efpia.eu  6 
5. Transparency 
• The pharmaceutical industry has already embedded transparency in various aspects of its 
business. AI diagnostic tools and other patient-facing tools should be transparent around 
their function/training to some degree (or otherwise be independently tested for 
robustness), different approach should be applied in case of proprietary internal R&D tools, 
since the insights from those will be validated in conventional ways, e.g. animal studies 
and/or clinical trials. 
• Where transparency is more difficult, such as Artificial Neural Networks, transparency will 
need to be better defined in this context. EFPIA recommends defining levels of transparency 
that allow sufficient interpretability or explainability of the AI and underlying data sets, 
including auditing mechanisms which are key to establish an environment of trust. Control 
and retention of both the data sets used to train the model, and the code used to create the 
model would aid in transparency. It is also important that transparency requirements are 
carefully balanced to still allow sufficient incentivisation of the investments needed to 
stimulate the generation of the necessary data sets and AI solutions. 
6. Intellectual Property (IP) protection on AI should be effective and predictable 
• Effective and predictable IP protection, including patents, is fundamental to 
advancing biopharmaceutical 
innovation, 
including with 
AI. 
Intellectual 
property 
protections, including patents, provide incentives that drive and sustain those substantial 
investments in crucial prevention, treatments and cures, so they can be available to the 
patients who need them. Importantly, patents also promote the sharing of knowledge 
through the disclosure requirements of the patent system.  
• EFPIA encourages the Commission to consider the many different types and sources of data 
that exist in today’s complex technological environment and consideration of how data 
evolves over time. For example, while readily available data from public sources may not 
need or benefit from a system of incentives, other types of data that can only be generated 
through investment and great effort would not exist without incentive systems. 
7. Leadership and coordination 
• The private sector can explore the innovative uses of AI-based systems and inform the public 
data debate by demonstrating the value creation for the healthcare system, supporting its 
sustainability as well as the value creation to the European economy. The public sector will 
need to ensure that the right framework for engagement, the skills and infrastructure are 
present to leverage this and can bring significant human capital thanks to the education 
systems, workforce based on the skills agenda and capabilities through its investment in 
infrastructure. 
• The European Commission must ensure this ecosystem is well-coordinated and the impact 
of the Coordinated Plan on AI with Member States is greater than the sum of its parts. 
EFPIA welcomes the establishment of experts groups such as a High-Level Expert Group on 
artificial intelligence and calls for further development of guidelines fostering 
complementarity and synergies between national and EU level. The Coordinated Plan needs 
to demonstrate acceleration, clarity of ambition to attract private investment particularly 
from an international perspective, the right infrastructure and skills to make it attractive to 
develop an EU AI ecosystem, enabling the adoption of AI by the public sector, securing access 
and use of data, the right enablers and incentives for private investment. The Commission 

www.efpia.eu  7 
need to ensure efficiencies are realised, clarity of guidelines and establish mechanisms for 
quick decision-making. 
To conclude 
EFPIA encourages further elaboration of EU plans on the development of a true centre of excellence 
for AI in healthcare, including policies on data and digital literacy within the healthcare sector and the 
general population, state supported investment programs, attractive “equal” partnerships between 
public healthcare systems and industry, testbeds for novel AI approaches and validation of AI systems 
and outcomes. 
EFPIA asks the Commission to adapt existing frameworks for the acceptability in decision making and 
adoption of AI technologies to provide a path through which AI can be developed, adopted and 
implemented in healthcare systems. We would seek a greater clarity and guidelines that enable 
innovation, adoption and acceptance of AI technologies. 
EFPIA wishes to underline the importance of all key stakeholders being engaged in this initiative at the 
highest level and encourages early agreement on a multi-stakeholder platform to drive the proposal 
forward in a way that fosters cooperation amongst national competent authorities, avoids 
fragmentation and develops Member States AI capabilities. 