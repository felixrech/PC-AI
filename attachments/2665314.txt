Norwegian Position Paper on the European Commission’s Proposal for a 
Regulation of the European Parliament and of the Council Laying Down 
Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and 
Amending Certain Union Legislative Acts (COM(2021) 206) 
1 INTRODUCTION 
Norway is one of the most digitalised countries in the world, and Norwegian citizens and 
businesses rely to a large extent on data and digital services in their daily lives. Many 
Norwegian businesses use AI as part of their operations, for instance in the oil and gas 
industry, the maritime sector and in aquaculture. There are also a number of projects and 
initiatives based on AI in the Norwegian public sector. 
The Norwegian National AI strategy states that AI developed and used in Norway should 
be built on ethical principles and respect human rights and democracy. Research, 
development and use of AI in Norway should promote responsible and trustworthy AI and 
safeguard the integrity and privacy of the individual. 
The Norwegian government therefore welcomes the European Commission's proposal for 
a new Artificial Intelligence Act. The proposal appears to be well thought out and provides 
a balanced approach, and will contribute to putting Europe in a leading position when it 
comes to the development and use of trustworthy and reliable AI. 
2 DEFINITION OF AI 
Norway has a tradition for making laws and regulations as technology neutral as possible 
so that they can be applied even when new technologies and digitalisation change our 
society and the way we live. We therefore support the Commission's take on the 
definition of AI. We support the use of a broad definition, and the possibility for adapting 
the list of techniques and approaches, as AI is an area where the technology develops at 
a fast pace. 
3 RISK-BASED APPROACH 
As a rule, the Norwegian government seeks to avoid regulating specific technologies, and 
will rather regulate unwanted use. Regulating technology – in particular technology that is 
still in an early phase – can have unintended consequences on developments, disrupt 
markets and reduce the potential for innovation. 
We therefore support the risk-based approach the Commission has proposed, where the 
majority of current AI applications will fall into categories that do not place undue 
demands on businesses. We appreciate the aim of balancing regulation with flexibility, 
and not imposing a higher than necessary burden on those providing or using artificial 
intelligence systems with limited or no risks. We recognise the challenge involved in 
striking the balance between innovation and regulation. The risk-based approach is a 
useful way to address this. 

Side 2 
We agree that under such a risk-based approach, most applications should fall outside of 
the scope of the regulation. 
4 PROHIBITED AI PRACTICES 
The Norwegian government supports the Commission's proposal for AI practices that 
shall be prohibited. However, we have a concern regarding the Article 5 – 1 (a) stating 
that an AI system that deploys subliminal techniques is prohibited if it is likely to cause 
physical or psychological harm. In our opinion, such manipulative practices are often 
used in cases that cause financial harm to people, which may in turn lead to 
psychological harm. We would propose that the prohibition of AI systems that deploy 
subliminal techniques is expanded to also include financial harm. 
Regarding Article 5 – 1 (c) the Norwegian Government supports the suggestion of 
prohibiting AI systems for evaluation or classification of the worthiness of natural persons 
where such use of AI-systems may lead to unjustified or disproportionate treatment of 
individuals. However, it should be carefully considered whether the terms 'unjustified or 
disproportionate' will provide sufficient safeguards against unwanted use of this type of 
AI-systems. The Norwegian government is concerned that this, in some cases, could 
allow for exclusion of individuals from the use of certain fundamental services that should 
be available to all, for instance health and care services. 
5 HIGH RISK AI SYSTEMS 
The Norwegian Government supports the overall approach to high risk AI systems in the 
Commission's proposal. We support the proposal for an EU database for high-risk AI 
systems. 
Determining borderline cases 
The term 'high risk system' is defined in article 6 with reference to lists in Annexes II and 
III. The Commission will be empowered to adopt delegated acts to update these lists. 
Deciding whether a system qualifies as a high-risk AI-system may require difficult 
considerations. It is our view that it may be necessary to adopt a procedure to determine 
borderline cases. We propose that such a procedure could be modelled after Article 4 in 
Regulation 2017/745 on medical devices. In addition, in order to ensure the best possible 
end user protection, we propose to include in the regulation that: 'In cases of doubt, 
where, taking into account all its characteristics, an "AI system" may be considered a 
"high-risk AI system" the provisions of Title III, Chapter 2 of the Regulation apply'. Such 
provisions have been used in other EU regulations. 
Autonomous shipping 
Norway is at the forefront in the development of autonomous vessels and hosts a number 
of test sites. We recognise that safety systems for the navigation of such vessels are 
included in 'High-risk AI systems' through the inclusion of Directive 2014/90/EU in the list 
in Annex II. However, we see a growing activity around AI based systems intended for 
decision support to increase safety in harbours and fairways. This includes AI systems for 

Side 3 
the safe handling of an increased amount of goods in harbours. We therefore propose 
that AI systems for autonomous shipping are added to Annex III – 2 (a), where systems 
for the management and operation of road traffic are already listed. 
A need for harmonised standards 
The regulation's Title III, chapter 2, lists seven areas with requirements that high-risk AI 
systems must meet. Best practices for the development of AI technologies include all 
these areas, and we therefore find that the burden put on the developers and technology 
providers by this regulation is not unreasonable. The key challenge is that harmonized 
standards do not yet exist for all areas. The Norwegian government welcomes the 
development of harmonised standards, and Norway would like to be included in any work 
on such standards or common specifications initiated by the Commission. The Norwegian 
government already supports the work on international AI standards by supporting 
Standard Norway's participation in this work. 
Data and data quality 
There is a need for further clarification of statements such as 'data sets shall be relevant, 
representative, free of errors and complete'. Bearing in mind that data are contextsensitive, we believe that ensuring that data are fully 'free of errors' and 'complete' is an 
impossible task. The deciding factor should be whether the errors are of such a nature 
and scope that the dataset in question should be precluded from model development. 
Considering the high penalties for non-compliance with this article in particular, we would 
suggest a softer wording on this point. Although data for training, validation and testing 
should be free of errors and complete to the greatest extent possible, it should not be an 
absolute requirement. 
We also consider data quality to be dependent on context: What may be sufficient data 
quality in one context, may not be good enough in another. Such differences in context 
can occur also within the scope of high-risk AI. Hence, in art. 10 (3) reference could be 
made to the purpose of the processing in order to clarify that relevance, necessity and 
accuracy must be assessed in relation to the purpose of the processing, similar to how 
this is done in the GDPR art. 5 (1) c and d. 
Transparency in administration of justice and democratic processes 
When using AI-systems to assist a judicial authority in researching and interpreting facts 
and the law, and in applying the law to a concrete set of facts (Annex III – 8 (a)), it is 
particularly important that people are provided with a possibility to examine and review 
the decisions made by the judicial authority. There is some concern that the proposed 
draft does not provide sufficient transparency in the functioning of such AI-systems, which 
in turn could make it difficult to examine and understand the decisions made by the 
authority. We therefore recommend that it is considered whether it is necessary to 
propose additional transparency requirements for AI-systems used in this capacity. 
Third party conformity assessment 
The proposal for regulating high-risk AI systems relies to a large extent on selfassessment. It should be considered whether there is a need for third party conformity 

Side 4 
assessments for high-risk AI-systems before they go on the market also in the cases 
where they are not part of a product required through other regulation to undergo such an 
assessment. 
6 THE AI ACT IN RELATION TO OTHER LEGAL FRAMEWORKS 
To ensure the success of the European AI coordinated plan, the European AI regulation 
needs to be comprehensive and the connections to other relevant regulations easy to 
understand. Care should be taken to ensure consistent use of terms throughout the 
regulation, and to use precise terms that are not open to interpretation. 
In particular, emphasis must be put on harmonising the Artificial Intelligence Act and the 
recently proposed Data Governance Act as well as the General Data Protection 
Regulation (GDPR). From the proposal it can be difficult to understand the relationship 
between the AI Act and existing regulations regarding the use of AI in products and 
services. 
Relation to GDPR 
The development and use of AI rely heavily on data, including personal data. In 
consequence, the Commission’s proposal has considerable data protection implications 
and significant overlap with the existing data protection framework, in particular the 
GDPR and the Law Enforcement Directive (LED). We recommend clarifying in Article 1 of 
the AI Act that the Union’s legislation for the protection of personal data, in particular the 
GDPR and the LED, shall apply to any processing of personal data falling within the 
scope of the AI Act. 
We also recommend that concepts and definitions are harmonised between the AI Act 
and the GDPR to the greatest extent possible, to avoid confusion. A consistent use of 
terms and definitions will make it easier to apply these two regulations in parallel. In 
particular, attention should be paid to the GDPR art. 22 on automated individual decisionmaking and to art. 15 (1) h regarding the data subject's rights to information about the 
logic involved in automated decision-making. 
Consumer protection and workers' rights 
Consumer protection is an important part of ensuring trustworthy AI in Europe. The AI Act 
should be part of a broader review of relevant EU rules (e.g. product liability and product 
safety rules and consumer law) to put in place a comprehensive legal framework that 
guarantees a strong set of rights for consumers. 
It is important that consumer protection remains strong also for AI-systems or products 
that include such systems. It should be considered whether existing redress mechanisms 
that exist under EU law are sufficiently adapted to the challenges of AI, such as 
transparency, safety and accountability. 

Side 5 
It is a strength of Norwegian working life that employees have a great deal of influence 
over their own professional practice, working day and conditions. This applies to both the 
individual employee and not least the employees' union representatives and 
organisations. 
Norwegian regulation in the area of workers' rights ensures workers' and their 
organisations' influence when it comes to the introduction of new technologies in the 
workplace. 
Article 29 in the AI Act states that users' obligations to use high risk AI systems in 
accordance with the instructions of use are 'without prejudice to other user obligations 
under Union law or national law'. This means that existing EU and national regulations for 
both consumers and workers apply to high risk AI systems. We would like to underline 
the importance of the new AI regulation not overriding existing and well-functioning 
regulation in these areas. We recommend clarifying in Article 1 of the AI Act that Union 
legislation or national law shall apply in all areas that are not explicitly covered by the 
regulation, such as consumer rights and workers' rights. 
7 CONSEQUENCES FOR SMEs 
Complex regulations may pose an undue burden to SMEs (Small and Medium 
Enterprises). Even when their applications fall outside the scope of the regulation, fear of 
non-compliance and the possibility of large fines, means that they often will 'err on the 
side of caution' and drop potential projects. This may seriously stifle innovation in the field 
of AI and favour large international companies that have the legal and financial muscles 
to ensure compliance and provide all necessary documentation. 
SMEs would greatly benefit from more clarity, simpler language and clearer links to other 
regulations such as the GDPR. It should be easy for SMEs to navigate the regulation and 
understand what parts apply to them and their projects. It is also important that support 
mechanisms such as standards, guidelines and checklists, regulatory sandboxes and 
European Digital Innovation Hubs (EDIHs) are in place before the regulation comes into 
effect. 
8 REGULATORY SANDBOXES 
It is encouraging to see regulatory sandboxes as part of the EU proposal. The Norwegian 
government established a regulatory sandbox for AI and personal data protection at the 
Data Protection Authority in 2020. The goal is to promote the development of innovative 
artificial intelligence solutions that are both ethical and responsible. We support 
regulatory sandboxes as an instrument to stimulate innovation in areas that are complex 
and challenging. We believe that innovation and data protection can be promoted through 
a sandbox, especially for SMEs with limited resources. 
From the wording of Article 53, it is not quite clear what a regulatory sandbox will 
encompass. The question arises whether the proposed regulatory sandbox includes an IT 
infrastructure in each member state, with some additional legal grounds for further 

Side 6 
processing, or whether it merely organizes access to regulatory expertise and guidance. 
In our experience, requiring the authority to provide IT infrastructure will be raising the 
threshold for establishing sandboxes, due to the technical expertise and costs that this 
would entail. 
Article 53, section 3 states that the sandbox does not affect supervisory and corrective 
powers. This is a useful clarification. However, we also see a need for some guidance on 
how competent authorities can strike a good balance between being a supervisory 
authority on the one hand and giving detailed guidance through a sandbox on the other. 
We propose that the AI Act specifies that participation in a sandbox does not constitute a 
stamp of approval, and that the organization/controller is still accountable for its 
processing of personal data. 
Article 53, section 6 describes that the modalities and conditions of the operation of the 
sandboxes shall be set out in implementing acts. It is important that specific guidelines be 
produced in order to ensure some consistence and help in the establishment and 
operation of sandboxes. However, binding implementing acts could limit each Member 
State’s ability to customise the sandbox according to local needs. 
It is our experience so far that operating a sandbox is resource intensive, and it is to be 
expected that only a small number of businesses would get the opportunity to participate. 
It shall be noted that participating in the sandbox could constitute a competitive 
advantage for participants that are able to further process data for new purposes, as 
reflected in Article 54. Therefore, the opportunity for further processing, as set out in 
Article 54, would require careful consideration of how to select participants to the 
sandbox in order to ensure fair competition. 
9 GOVERNANCE STRUCTURE AND AI BOARD 
The Norwegian government foresees to designate a national supervisory authority, in 
accordance with the proposal. Norway, as an EEA member state, should be represented 
in the European Artificial Intelligence Board (EAIB) to be established in accordance with 
title VI, chapter I of the proposal, equivalent to our participation in the European Data 
Protection Board. This will be essential to ensure consistent application of the AIregulation across the internal market. 
The Proposal foresees to give a predominant role to the Commission, with the EAIB in an 
advisory role. This contrasts with the need for a European AI body independent from any 
political influence. We would recommend giving more autonomy to the EAIB. This will 
give the Board a better possibility to ensure the consistent application of the regulation 
across the single market. We note that no power is conferred to the Board regarding the 
enforcement of the proposed regulation. Yet, considering the spread of AI systems 
across the single market and the likelihood of cross-border cases, there is a crucial need 
for a harmonized enforcement and a proper allocation of competence between national 
supervisory authorities. We therefore recommend that the cooperation mechanisms 
between national supervisory authorities be specified in the forthcoming regulation. 