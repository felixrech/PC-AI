Feedback provided by AstraZeneca: 
Artificial intelligence – ethical and legal requirements 
Introduction 
AstraZeneca welcomes the proposed Regulation laying down harmonised rules artificial intelligence 
(Artificial Intelligence Act​Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial 
Intelligence Act) and amending certain Union legislative acts ‐ https://ec.europa.eu/info/law/better‐regulation/ ​ ) and believes that harmonised EU rules on AI can pre‐empt a possible 
fragmentation of the single market and foster the safe and responsible development, use, and uptake 
of AI in the European Union. It. Below we provide initial feedback on the draft Act insofar as it is 
relevant for our business activities in biomedicine, pharmaceuticals, and healthcare. 
Tightening the definition of ‘AI’ and ‘Systems’ to exclude legacy activities 
The language used to define AI in the draft legislation is very broad and includes all statistical 
computations and analyses. Like many of its peers in the biomedical, pharmaceutical, and healthcare 
sector, AstraZeneca is a science‐ and data‐driven business. AstraZeneca has routinely used the 
scientific method, statistical analyses, and computational methods for decades. Applications include 
biological discovery science, the enabling of clinical trials, interventional research, drug product 
approval, and post‐marketing activities. The currently proposed inclusive definition of AI would 
encompass a large portion of the daily work of many biomedical and pharmaceutical companies. 
These activities were historically neither thought of or classed as ‘AI’ nor identified as conferring 
additional risks (often to the contrary). 
As the draft AI Act will be following the normal legislative procedure, due consideration should be 
given to the potential cost of implementation for the private sector. In a recent report about How 
Much Will the Artificial Intelligence Act Cost Europe?[1], the Center for Data Innovation stressed that 
“the [AI Act] will cost the European economy €31 billion over the next five years and reduce AI 
investments by almost 20 percent. It is of paramount importance to define AI in a way that enables 
regulatory control where truly required for AI systems. 
We would therefore appreciate further dialogue on a definition of AI that does not capture legacy 
activities and takes into consideration existing requirements in the field of diagnostics and medical 
products. Similarly, further guidance on the definition of a ‘system’ would be beneficial to data‐driven 
industries to understand what activities are in and out of scope for this regulation.  
AstraZeneca’s AI applications 
AstraZeneca invests in, develops, and uses AI technology. Examples of use cases include: 
AI systems put into service for own use: Many of our internal systems do indeed include machine 
learning, language processing, and decision assistance and automation using AI. The developers 
of our AI solutions are often also the end‐users. Outputs of such AI systems might for example 
support patient stratification into clinical trials, or predictive algorithms to help design smarter 
trials. 
Upstream use cases, where sector‐specific processes or regulations mitigate risk: This may for 
example include an AI modelling tool that predicts compound safety and efficacy prior to adding 
the compound to the company portfolio. This unvalidated compound still goes through safety 

exercises, clinical trials, in‐depth analyses, and restrictions based on safety concerns, and 
regulatory approval. The potential risk generated by the use of an AI modelling tool is managed 
by the drug development process. Similarly, uses of AI tools in Operations is effectively mitigated 
through existing regulations such as Good Manufacturing Practices. 
Medical software products developed using or containing AI:  In addition to manufacturing 
medicinal products, AstraZeneca is also a legal manufacturer of medical devices. We are 
increasingly exploring the potential benefits of the use of AI and machine learning technologies 
to enhance the medical device development process and indeed as a core component of the 
medical device itself. We have developed quality management systems for medical device design, 
development, and manufacturing and have recently endeavoured to supplement these systems 
with good machine learning practices. We, and our partners, follow IVDR MDR regulation for any 
devices supporting our medicines on market. 
AI systems that support patient stratification e.g. diagnostics 
Facial Recognition for employee and site security 
Determining AI risk categories 
The Commission proposal rightly highlights that the use of artificial intelligence can provide key 
competitive advantages to companies and support socially and environmentally beneficial outcomes 
in the healthcare sector. AstraZeneca wholeheartedly supports the premise of the proposal that in 
the health sector where public health is paramount, AI supporting human decisions must be reliable 
and accurate. 
The proposal lays down a risk methodology to define “high‐risk” AI systems that pose significant risks 
to the health and safety or fundamental rights of persons. The European Council has called for a clear 
determination of those AI applications that should be considered high‐risk. AstraZeneca supports this 
approach, as it ensures legal certainty and facilitates innovation and continued investments in AI 
technologies. We also strongly encourage a proportionate application of all relevant requirements 
proposed in the Act. 
Our reading of the proposed Article 6 in conjunction with Annex II and Annex III of the draft Artificial 
Intelligence Act suggests a limited amount of AstraZeneca’s current applications of AI would be 
categorised as high‐risk, including the following: 
Software as a medical device; 
AI systems acting as or supporting diagnostics (e.g. that support patient stratification); and 
AI systems used in facial recognition for employee and site, and information security. 
Codes of Conduct 
The draft Artificial Intelligence Act provides a framework for the creation of codes of conduct that 
encourages providers of non‐high‐risk AI systems to apply voluntarily the mandatory requirements 
for high‐risk AI systems. 

AstraZeneca develops and uses AI technology in line with its 
Principles for Ethical Data and AI (see Annex) as well as its Code 
of Ethics and Ethics & Transparency Commitment under its 
Sustainability Ambition. 
AstraZeneca is furthermore committed to review its voluntary 
Principles for Ethical Data & AI against relevant requirements 
incorporated in the final Artificial Intelligence Act (gap analysis) 
and to promote the development of a sectorial Code of 
Conduct to this effect. 

Annex 
AstraZeneca Principles for Ethical Data and AI 
Explainable and Transparent 
We are open about the use, strengths and limitations of our data and AI systems. 
We explain to people if they are interacting with an AI system and whether interactions 
are recorded. 
We are able to explain when and how AI is used to aid a decision that impacts humans. 
We will ensure appropriate levels of explainability and transparency in line with our legal 
obligations. 
We will ensure our assumptions are clear, we will ensure algorithms are 
appropriately documented, decisions are explainable as needed, and processes are 
in place to deal with unanticipated impacts. 
We can demonstrate our data sources, and how models are trained and maintained. 
We have the ability to explain processes, data and algorithms when required to do so 
while protecting our intellectual property. 
We are transparent about the use of AI to build trust and credibility in all our endeavours. 
*Explainable refers to the ability of humans to understand the results of a solution generated by 
Artificial Intelligence  
Fair 
We endeavour to use robust, inclusive datasets in our Data and AI systems. 
We seek to ensure our use of AI is sensitive to social, socio‐geographic and socio‐ 
economic issues, and protect against discrimination or negative bias to the best of our 
ability. 
We will continually adapt and improve our AI systems and training methods to drive 
inclusiveness. 
We treat people and communities fairly and equitably in the design, process, and 
outcome distribution of our AI systems. 
We are aware of the limits of our AI systems. We strive to apply their outputs in the right 
context and in a non‐discriminatory fashion. 
We monitor our AI systems to maintain fairness throughout their lifecycle. 
We acknowledge all data sources and human effort in our Data and AI Systems, while 
protecting our intellectual property. 
Accountable 
We apply governance proportional to the impact and risk of our Data and AI Systems. 
We diligently assess risk against opportunities to act consistently with our company 
values. 
We take accountability of our use of Data and AI Systems throughout their life cycle, 
so their use is appropriate and monitored over time. 
We anticipate and mitigate the impact of potential unfavourable consequences of AI 
through testing, governance, and procedures. 

We are accountable for our findings and the recommendations from AI systems. We 
govern AI‐supported decisions appropriately. 
We recognise and address unforeseen consequences resulting from our AI usage 
appropriately, and ensure that lessons are learned. 
Human‐Centric and Socially Beneficial 
Where Data and AI is involved, humans oversee the system and are accountable for 
driving clear, expected benefits to people and society. 
We apply AI to contribute to a sustainable workforce, business, and planet, to help make 
AstraZeneca a Great Place to Work, and accelerate our contribution to society. 
We involve people at appropriate times to responsibly deploy AI where decisions carry a 
material impact. We harness the capabilities of AI to accelerate the development and 
delivery of the right life‐changing medicines to the right patients with the right 
commercial potential. 
We employ human‐led governance over our AI systems. We respect human dignity and 
autonomy and strive to reflect this in our AI systems. 
We drive prudent and sustainable energy consumption when using Data and AI 
systems. 
We recognise that protecting the environment is an integral part of ensuring AI systems 
are socially beneficial. We aim to reduce the energy consumption of our AI systems in 
line with our Ambition Zero Carbon. 
Private and Secure 
We respect privacy and control, and act in a manner compatible with intended data 
use. 
We respect privacy and the rights of all stakeholders, and will act in accordance with 
relevant laws and regulations. 
We assign appropriate protective measures to keep all information held or generated by 
AstraZeneca’s AI systems secure. 
We employ Data and AI systems that are designed to be secure. 
We strive to protect our AI systems against information breaches and unintended 
applications, with mitigation processes in place. We manage our AI systems through their 
life cycle, including information used and generated. 
We review third party AI providers’ data protection standards to seek alignment, 
and comply with applicable law.  
+++ENDS+++ 