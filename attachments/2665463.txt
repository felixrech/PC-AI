- 1 - 
Berlin, August 5, 2021 
Association of German Chambers of Commerce and Industry 
(Deutscher Industrie- und Handelskammertag, DIHK) 
On the EU Commission’s proposal for a European Law on Artificial Intelligence​Proposal for a Regulation of the European Parliament and of the Council laying down harmonised rules on Artificial Intelligence (Artificial Intelligence Act) and amending certain Union legislative acts”, COM(2021) 206 final, of 21 
April 2021, see: eur-lex.europa.eu/resource.html?uri=cellar:e0649735-a372-11eb-958501aa75ed71a1.0019.02/DOC_1&format=PDF). ​   
This statement is based on the economic policy and European policy positions of the Association of 
German Chambers of Commerce and Industry (DIHK) and has been drawn up by a cross-industry 
working group on “AI Regulation”. The working group is composed of members of various DIHK Expert Committees, as well as desk officers from the Chambers of Commerce and Industry (CCIs). 
The comments received from CCIs and committee members up to the time of the submission of the 
statement have been taken into consideration. If the DIHK receives further relevant comments that 
have not yet been taken into account in this statement, the DIHK will supplement this statement accordingly. 
A. The most important Aspects in Brief 
Artificial intelligence (AI) is considered to be one of the key technologies of digitalisation and a driver 
of economic growth. In order to ensure that the course is set for the successful development and 
application of AI, the DIHK advocates the improvement of the AI framework conditions at both state 
and federal level, as well as at EU level. For SMEs in particular, it is important that security and confidence are strengthened with respect to the use of AI technologies. A European legal framework 
can make an important contribution to this. The key here is to find the right balance between safe AI 
systems and innovation-friendly framework conditions. The legal provisions must not impose unnecessary barriers to the further development of AI, but instead should have the effect of promoting innovation. The key demands: the creation of legal certainty through a definition of the term "AI system" that is not only differentiated, but also as clear as possible. Here, the actual specific risk posed 
by these systems should be taken into consideration for the risk qualification. Obligations are to be 
designed in a pragmatic manner so that the bureaucratic burden for companies is kept as small as 

- 2 - 
possible. Furthermore, coherence with requirements from existing European regulations is to be ensured, thereby making sustainable use of the advantages of a single European market and 
strengthening global competitiveness. 
B. Relevance for the German Economy 
AI as a technology is crucial for the future competitiveness of German companies. The field of application of AI extends across almost all branches of the economy and business areas. The economic 
potentials that can be opened up by AI in the German economy are just as many and varied as the 
AI systems and the applications that can be implemented with these processes: data analysis and 
pattern recognition, the processing and generation of language, human-machine interaction, robotics or the recognition of images and objects. This relates not only to the optimisation of processes 
and products – there is also enormous potential in new business models and services that are 
based on AI technology or supported by AI systems. 
The fact that German companies are increasingly addressing the topic of AI is also shown by the 
results of the DIHK Digitalisation Survey 2021​DIHK e.V., 2021. Digitalisation with Challenges – The Chamber of Commerce and Industry Survey on Digitalisation. Evaluation of a company survey from 1 November to 4 December 2020. ​ : 27 percent of the companies surveyed are planning 
to use AI within the next three years. Nevertheless, many SMEs are still exercising restraint with regard to the current use of AI systems: currently, only about eleven per cent of the companies surveyed use AI technology. 
The reasons for the reticence to introduce digital technologies such as AI are many and varied. In 
addition to the high costs, a lack of time resources, an insufficient database or a lack of skills among 
executives and employees, many companies also report that they have security concerns and that 
there is a high degree of legal uncertainty (cf. DIHK Digitalisation Survey 2021). The new technological possibilities and framework conditions in the field of AI raise new legal questions. Among other 
things, these relate to how to deal with risks, the tolerance of mistakes or questions of liability. This 
is inhibiting the acceptance and therefore the success of the technology. Overall, a good one in four 
companies consider the lack of acceptance of new technologies to be an obstacle to innovation (cf. 
DIHK Innovation Report 2020 ​DIHK e.V., 2020. Time for Innovation – DIHK Innovation Report 2020. Evaluation of a Company Survey from 10 
February to 23 April 2020. ​ ). 
It is therefore important to create legal certainty and strengthen confidence in technologies such as 
AI for the benefit of the economy. How its use develops further, the level of acceptance and the future success of the technology will depend on this. Ultimately, however, this relates not only to the 
acceptance of the technology, but also the business models and products of the companies that are 
based on it. A clearly defined European legal framework can foster not only reliability, but also 
transparency, security and data protection. This makes an important contribution to strengthening a 
feeling of trust between providers and users. 
The new legal framework must not lead to over-regulation and thereby become an obstacle to innovation for the development and application of AI in Europe. The international competitiveness of 

- 3 - 
Germany’s key industries and globally active companies, as well as the needs of small and medium-sized enterprises, must be taken into consideration to a sufficient extent in this process. It is 
important to bring about a legal framework that makes it possible for the technology to develop 
within the EU and increases a feeling of trust between providers and users. This requires an approach that is open to new technologies and impartial and which finds a balance between opportunities and risks. Special priority should be given here to ensuring legal certainty for businesses. 
As the topic of AI is highly relevant for the entire German economy and the broad field of application, the DIHK takes the following position on selected business-related aspects of the Draft Law on 
Artificial Intelligence (hereafter referred to as AI Regulation): 
C. In Detail 
A Legally Certain and Future-Proof Definition of AI 
An appropriate definition of the term AI is fundamental for future legislation, as it specifies the field 
of application of the regulations. The resulting impacts for companies should be given special consideration here. A common understanding of AI throughout Europe is important for the development 
of the technology in the EU. Businesses require clear and understandable criteria that make AI accessible as a technology and enable them to quickly and easily determine the degree to which they 
are affected and deal with the regulations. It is equally important to draw up the definition in such a 
way that it is also suitable over the long term and therefore ensures planning certainty. 
The EU Commission bases its Draft AI Law on a very broad understanding of what is to be considered an artificial intelligence system (hereafter “AI system”) within the meaning of the Regulation. 
Article 3 of AI Regulation contains – with reference to Annex I – a definition of AI, according to 
which it is “software that is developed with one or more of the techniques and approaches listed in 
Annex I and can, for a given set of human-defined objectives, generate outputs such as content, 
predictions, recommendations, or decisions influencing the environments they interact with”. Undoubtedly, almost every application is suitable for this and also destined to have an influence on its 
environment. There is no delimitation in this respect according to Art. 3 AI Regulation. The techniques and concepts listed in Annex I are therefore the decisive factors here. These are also very 
broad, with the inclusion of machine learning, logic-based approaches, statistical approaches or 
search and optimisation methods. 
This should not be fundamentally assessed as negative, as broad regulation can strengthen confidence in the technology. However, this approach must not lead to significant additional costs, especially for small and medium-sized businesses, which inhibit the development and use of the technology. It should also be taken into account that many companies are already providers or users of 
such software systems. In these applications, the degree of autonomy of the AI is mostly still very 
small. 
4a) Machine learning approaches, including supervised, unsupervised and reinforcement learning, using a wide variety 
of methods including deep learning; 
b) Logic- and knowledge-based concepts, including knowledge representation, inductive (logical) programming, 
knowledge bases, inference and deduction engines, (symbolic) reasoning and expert systems; 
c) Statistical approaches, Bayesian estimation, search and optimization methods.

- 4 - 
The definition of AI should definitely be made more specific and differentiated so that it reflects the 
wide range of possible AI applications and the significant technological differences in the complexity 
of the underlying algorithms. The unfiltered inclusion of all systems that include techniques such as 
machine learning, logic-based concepts and, in particular, statistical approaches, search and optimisation methods clearly goes too far. This also applies against the background of the impact of AI 
Regulation on other EU requirements, such as those from the Machinery Regulation. The degree of 
independence of the system or decision-making autonomy appears to be suitable as a guideline 
and yardstick. Similarly, risk-relevant properties such as the training and learning ability of systems 
should be included. For example, a distinction has to be made between AI that is no longer changing and a solution that is constantly evolving in customer use. 
This distinction even at the level of the field of application is urgently required, as it is disproportionate to demand extensive testing and compliance obligations even for low-threshold, dependent applications. In order for the EU to be able to establish a pioneering role in the field of AI, companies 
that are already using or developing AI today must be protected accordingly and be given incentives 
to continue to focus on it in the future. 
We therefore advocate a differentiated definition of AI that is suitable for practical application over 
the long term and which finds a benchmark that enables a clear distinction to be made between the 
different stages of technological development. 
Further Development of Risk Classes 
The risk-based approach selected by the EU Commission is to be supported as a matter of principle. A distinction is made between AI systems that represent an “unacceptable risk”, a “high risk” 
and a “low” or “minimal risk”. This differentiation enables a proportionate regulatory intervention to 
be implemented where this is meaningful in safety-relevant areas. However, the yardstick for this 
should only be the specific risks that arise from the intended use of the AI systems themselves. This 
is important from a company’s point of view, as the transfer of all general risks to the individual application will lead to a more reticent approach to the technology. 
Consideration of the risk areas and their sometimes high demands on AI systems makes this clear. 
The obligations that are associated with the development and operation of high-risk AI in particular 
must also be justified in individual cases. For this purpose, it is not only the criticality of the field of 
application, but also the degree of development and the associated autonomy or decision-making 
autonomy of the AI system that also has to be taken into consideration. In this way it is possible to 
minimise the additional burden without failing to take account of any risks. 
This should be taken into account to the extent that the high-risk areas listed in Annex III are not 
subject to a general suspicion of being hazardous. The consequence of such a deterrent effect that 
emanates from such a suspicion, particularly in sectors such as education, human resources or services, is that AI might be disproportionately restricted in its development. Against this background, a 
comparison of existing practice, EU objectives and possible risks has to be carried out. It needs to 
be determined to what extent leeway for innovative companies, for example in the dual use of data 
or the application of AI in non-critical areas, is unjustifiably restricted here. 

- 5 - 
A further major challenge lies in the speed of development of the systems and the rapid expansion 
of the fields of application. The Commission reserves the right to extend the list of high-risk applications in Annex III of AI Regulation, as well as the contents of most of the other Annexes. On the one 
hand, it is important that the regulatory framework is open to further developments in order to do 
justice to the development dynamics in the area of AI and the resulting requirements. On the other 
hand, any dynamic expansion of the systems listed in the Annex and of the basic definitions of 
terms for these systems means a high degree of legal uncertainty for companies. In order for businesses to be able to anticipate possible expansions as early as possible, an assessment of the risk 
should be carried out on the basis of transparently communicated criteria. These criteria should be 
very clearly and narrowly defined and future-proof. A regular evaluation and, if necessary, revision 
of the Annexes of AI Regulation could, for example, make it easier for companies to draw up their 
plans and adapt to the latest technology that is available. 
Avoiding Double Burdens 
With its approach of horizontal, cross-sectoral legislation, the Commission’s draft introduces regulations for almost all economic sectors. This makes it all the more important to establish coherence 
with provisions that already exist. 
Many manufacturers are concerned that in the future they will have to submit evidence to several 
notified bodies confirming that they have fulfilled documentation or transparency obligations for one 
and the same product. This is to be feared, for example, in the case of embedded, AI-based software systems that are used as control systems for machines and are an inseparable part of these 
machines. Unclear responsibilities, disputes concerning competence, duplicate documentation obligations and multiple conformity procedures should therefore be avoided as a matter of urgency. It is 
important to make use of the know-how that already exists in the field of AI in specific sectors and 
involve the relevant bodies. 
For this reason – in order to avert the danger of dual or over-regulation – particularly high priority 
should be given to taking up and integrating existing structures. In numerous sectors, products and 
systems already require a risk-based conformity assessment, which also cover systems with AI. In 
this respect, the further specification or supplementary clarification of these provisions would be sufficient. This will keep unnecessary administrative burdens that result from any new provisions to a 
minimum. 
The medical technology sector is a good example of this: here, EU Regulations 2017/745 (MDR) 
and 2017/746 (IVDR) already regulate the marketability and monitoring of medical software. New 
procedures and specifications resulting from the planned AI Regulation could therefore lead to duplicate legislation and an overall inconsistent legal framework, with contradictory assessments for 
AI-supported medical devices, which would be associated with considerable legal uncertainties and 
additional expenditure for companies. This would not only weaken the international competitiveness 
of the industry, but could also result in delayed market access for digital innovations. 
Further burdens are also to be feared in the interplay between AI Regulation and the draft of the 
Machinery Regulation. According to the current drafts, it is to be feared that a large number of machine products would be classified as high-risk, which would trigger a new conformity assessment 
procedure with the mandatory involvement of a notified body. In order to avoid this, as well as the 

- 6 - 
technological backward step that might be feared as a result, the differentiated consideration and 
definition of AI that has been explained above is urgently required. 
Furthermore, with respect to the introduction of the conformity assessment procedure, it should be 
ensured that the state and private bodies involved in this process are equipped with sufficient capacities in order to avoid delays and the resulting costs incurred by companies as a result. 
Supporting Transparency – Protecting Business Secrets 
AI that is trustworthy and transparent is to be supported as a matter of principle. Everyone who interacts with AI and is potentially exposed to its influence has a legitimate interest in being able to 
recognise this. It should be emphasised that, for this purpose, the provisions of the GDPR apply 
without restriction to data that is involved in the use of AI. 
Measures that are also appropriate for achieving broader acceptance and a greater degree of confidence on the part of the user should be supported. One such measure could for example be the visible identification of applications that contain AI systems. Furthermore, a standardised exit option 
could be offered. 
Transparency should be subject to a clear boundary where sensitive and possibly competition-relevant business secrets are involved. Algorithms, extensive and high-quality data sets and therefore 
AI systems in general are highly complex, difficult to develop and already represent an intellectual 
property asset worth protecting for companies today. The business models of many companies are 
based on an algorithm that forms the individual added value compared to the competitors. These 
unique selling points must not be undermined by transparency regulations imposed at the expense 
of businesses. 
Data Requirements difficult to Implement in Practice 
Data serves as the basis for most AI systems in business. In this respect, a high quality of the data, 
as well as its continual optimisation, is essential. However, the requirements for the data quality, as 
well as its documentation and traceability as laid down in the Regulation, must be questioned, especially with a view to practicality. The consequences in international competition also have to be 
taken into account here. 
One fundamental problem first of all is the lack of a database, which affects many SMEs in particular. Small and medium-sized enterprises in particular have to overcome hurdles with regard to the 
availability of data, which is a significant basic pre-requisite for the use of AI. Due to the smaller size 
of the company, the data potential is smaller per se in SMEs than in large companies. Furthermore, 
the level of digital maturity is lower on average than in large companies. For many AI methods, however, it is crucial to train the AI systems with plenty of high-quality data. For this purpose it is necessary that the legal and infrastructural pre-conditions for the generation and collection of corporate 
data be created. 
Moreover, not every company can or would like to develop AI systems itself. This is why “AI service 
providers” (“AI as a Service”) are a crucial factor here: they develop AI solutions that can either be 
used “off the shelf” in a wide range of industries or adapted to specific companies. This means that 
the companies often have no insight into the technology or algorithm. Since these AI systems are 
often based on particularly large amounts of data and the use of highly complex models, it is difficult 

- 7 - 
for users in practice to sufficiently satisfy all of the standardised requirements for the data used contained in Article 10 of AI Regulation. Furthermore, specific AI and data analysis skills are required to 
show compliance with the requirements of Article 10. This is where many smaller companies reach 
their limits. It is therefore important to provide for pragmatic legislation that takes this circumstance 
into account and maps the responsibility of the providers and customers of so-called AI as a Service. The regulation should therefore explicitly allow companies to have their compliance with the 
requirements of Article 10 confirmed by the corresponding AI service provider in the form of a corresponding Declaration of Conformity or label. Only in this way can companies rely on the legally secure use of such services and will invest in them. 
Keeping Bureaucracy to a Minimum 
AI legislation should avoid creating complex rules for the companies concerned. It should be taken 
into account that especially for start-ups and SMEs, the high bureaucratic burden can result in enormous financial burden that affect them to a disproportionately greater extent. 
Already today, there are clear differences in the use of the technology, depending on the size of the 
company: while approximately one third of large companies with more than 1,000 employees make 
use of AI, only about one in ten small companies with fewer than ten employees do so (cf. DIHK 
Digitalisation Survey 2021). This problem could be further exacerbated by the regulatory framework, 
as the effort and costs involved have to be weighed against the benefits from its use. Excessive 
costs resulting from regulatory requirements might lead to the application of AI being inhibited instead of strengthened. 
Small and medium-sized enterprises must therefore also be put in a position where they are able to 
implement the legislation. They require extensive guidance in order to be able to find their way 
around the risk classes, as well as support with the setting-up of the required compliance, risk and 
quality management system. To this end, the EU Commission should press ahead with the provision of appropriate “Guidance Documents”. This support is essential for the development and establishment of new AI systems, as it is a necessary pre-requisite for the conformity assessment and 
market approval – in exactly the same way as the quality of the application itself and its safety. In 
this sense, the adaptation or further development of products should dispense with ever new conformity assessment procedures in order to keep the administrative burden as low as possible. 
Promoting and Protecting Innovations  
In order to belong to the creators and winners of the future, the regulatory framework must be open 
to innovation and enable a high-performing and internationally competitive European economy. 
Most companies are not entering the era of AI from scratch. Above all, they require innovationfriendly legislation that enables AI systems to be further developed in the ever-shorter innovation 
cycles of the digital economy. 
The testing of and experimenting with AI technologies should be made easier. The regulatory sandboxes proposed by the Commission are a helpful way to try out innovations in the interaction with 
legislation in a practical way and to further develop the regulatory framework in an evidence-based 
way. The opportunities offered by the regulatory sandboxes should be taken advantage of to the full 

- 8 - 
and adjacent areas of law taken into account in the process. In addition, access for companies 
should be designed to be low-threshold and with as little bureaucracy as possible. When AI is being 
tested, it is particularly important to integrate AI-human interaction into the test phase. This plays a 
crucial role in the training of the algorithms and the functionality of the AI. 
SMEs Require Support 
The CCI organisation with its Germany-wide, European and international network consisting of 79 
Chambers of Commerce and Industry throughout Germany, as well as the German Chambers of 
Commerce in European countries, can make an important contribution to the implementation of the 
AI legislation. SMEs need detailed guidance and advice on practical implementation. Through the 
global network of CCA, the Association of German Chambers of Commerce and Industry (DIHK) 
can also support German companies across borders. 
D. Contact Persons with Contact Details 
Alena Kühlein Steffen von Eicke 
Digital Economy, Infrastructure, Regional Policy Director Digital Single Market, EU Transport Policy, 
Head of Digital Economy Division Econonic Regional Policy 
Deutscher Industrie- und Handelskammertag e. V. Deutscher Industrie- und Handelskammertag e. V. 
Breite Strasse 29 | 10178 Berlin Avenue des Arts 19 A-D / 1000 Brüssel / Belgien 
Telephone: +49 30 20308-2107 Telephone: + 32 2286-1639 | Mobile: +49 151 11313099 
Kuehlein.Alena@dihk.de |  http://www.dihk.de  vonEicke.steffen@dihk.de | www.dihk.de 
E. Description of the DIHK 
Who we are: 
The 79 Chambers of Commerce and Industry (IHKs) have joined forces under the umbrella of the 
Association of German Chambers of Commerce and Industry (DIHK). Our common target: the best 
conditions for successful economic activity. 
At the federal and European level, the DIHK represents the interests of the entire commercial sector 
vis-à-vis politicians, administration and the public. 
After all, several million companies from the trade, manufacturing industry and service sectors are 
legal members of a CCI – from kiosk owners to Dax corporations. In this way, the DIHK and CCIs 
are a platform for the many and varied concerns of companies. We bundle these in a written procedure on a legal basis into common positions of the business community and thereby contribute to 
the opinion-forming process on economic policy. 
Moreover, the DIHK coordinates the network of the 140 German Chambers of Commerce Abroad, 
delegations and representative offices of the German economy in 92 countries. 
It is enrolled in the European Commission’s Register of Interest Representatives (No. 
22400601191-42). 