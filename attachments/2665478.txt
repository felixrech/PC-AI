Standard Chartered Bank 
1 Basinghall Avenue 
London EC2V 5DD 
sc.com 
DG for Communications Networks, Content and Technology 
European Commission 
1049 Bruxelles 
Belgium 
02 August 2021 
(submitted online) 
Dear Mr Viola 
Standard Chartered’s comments on the proposed Regulation on Artificial Intelligence 
(2021/0106) 
Standard Chartered welcomes the European Commission publishing the above consultation 
which seeks to achieve a coordinated European approach on the human and ethical 
implications of Artificial Intelligence (AI). 
We believe that harmonised rules which aim to both (i) protect EU citizens and (ii) enhance 
the take up of AI across the EU will be beneficial to the EU economy and EU companies. 
Standard Chartered offers a range of banking services in 59 markets. We are increasingly 
using automated, data-driven methods, to enhance both our internal processes and our 
client facing activities. We deploy such methods for activities such as customer engagement; 
customer onboarding; AML and fraud detection; management reporting and talent 
acquisition. 
The existence of extensive regulatory requirements within the financial services sector, 
contribute to ensuring the safety and soundness of firms, financial markets, and consumers. 
Therefore, the Financial Services sector is particularly well placed to respond to challenges 
that AI use may pose and already have in place a number of tools to manage risks in relation 
to AI use. At Standard Chartered, we have developed our Responsible AI Standards which 
are benchmarked against existing AI regulatory standards including the MAS FEAT 
Principles and the HKMA High Level Principles of AI. Our internal Standards enforce 
principles such as accountability, explainability, fairness, transparency and auditability, and 
we have comprehensive governance which oversees our use of AI. 
We believe AI requires an adaptative regulatory structure which can respond to the 
technology as it evolves. Therefore, a policy approach based on outcomes rather than 
focusing on a particular technology or application of a technology would seem appropriate. 
We would like to make the following specific comments, for your consideration. 
Definition of AI: Article 3 defines an “AI system” according to the techniques that it 
uses. This definition at face value – which includes “statistical approaches” - would 

result in even a simple linear regression model meeting this definition and having to 
be subject to the requirements within the Regulation. This seems disproportionately 
burdensome for the level of risk posed by such techniques. We suggest greater 
articulation and nuance in relation to this definition which would result in a more riskbased, proportionate regulatory scope. We believe the OECD or the Commission’s 
High Level Expert Group (HLEG) definition of AI which is more abstract and does not 
depend on the techniques used to define AI, offers an alternative approach. This 
definition could be enhanced with reference to (i) non-deterministic behaviour and 
(ii) a lack of direct visibility into causation of outcomes. It is this latter aspect that 
introduces risk and the element which we believe warrants particular attention and 
potentially standalone regulation.  
In the absence of a comprehensive amendment to the proposed definition within the 
Regulation, we suggest the text would read clearer if “high-risk AI systems” were 
systematically replaced by the term “high-risk uses (of AI systems)”. We believe this 
is better suited to refer to what is covered by Annex 3 – a set of intended uses. 
Likewise, the terms “unacceptable-risk AI systems”; “low-risk AI systems” and 
“minimal-risk AI systems” could be replaced with “unacceptable-risk AI uses (of AI 
systems); “low-risk AI uses (of AI systems)”; and “minimal-risk AI uses (of AI 
systems)”. 
Extraterritorial application: We appreciate that an extra-territorial approach is 
intended and that the AI Regulation as proposed will apply to (i) providers placing on 
the market or putting into service AI systems in the EU; (ii) users of AI systems 
located in the EU; and (iii) providers and users of AI systems that are located outside 
the EU, where the output is used in the EU. We would welcome clarity on how 
scenarios such as (i) hosting an AI application on a Cloud Service Provider in the 
EU, but using it outside the EU without impacting EU customers, or (ii) buying an AI 
product developed in the EU but using it solely with non-EU clients, is captured by 
the proposed Regulation. We suggest that the definition of “user” and “putting into 
service” could be sharpened to clarify the expectations in such a scenario, or if such 
scenarios are meant to be outside of scope, an exemption to that effect be explicitly 
included.  
Potential regulatory duplication: We observe that AI is largely reshaping the 
delivery of existing services. AI is used as a tool to support human judgement, rather 
than replace it. To that end, certain activities within scope of the Regulation, such as 
retail credit decisioning, are already subject to extensive obligations. We would urge 
that the use of AI itself to support – and arguably, enhance and mature - such 
activities are not subject to obligations which are duplicative of existing requirements. 
Rules relating to consumer protection, client communications, third party riskmanagement and model risk management for example, already exist to ensure that 
firms’ use of AI is not to the detriment of regulators’ objectives. 
We urge the Commission to consider whether compliance with existing regulatory 
requirements should be deemed compliance with the requirements under the 
Proposed Regulation, or at least such existing requirements should be recognised 

as a solid foundation from which only supplemental obligations might be required. In 
the absence of this, there may be a risk that regulators assess Financial Services 
firms against different, but similar, sets of standards. 
There is a further risk of duplication between various participants along a supply 
chain. Based on current definitions, it is not fully clear when a given player would be 
a “user” as opposed to a “provider”. This could create confusion, particularly in 
relation to notification obligations. It is also important to ensure that these definitions 
are appropriately calibrated to ensure that regulatory loopholes are avoided and that 
the right incentives are in place for all parties involved. Regulated entities in particular 
should not be unduly disincentivised from using third party technologies. 
Data Governance: We note that Article 10(3) proposes that data used for AI 
purposes is “free from errors”. We do not believe it is realistic to expect data to not 
contain any errors, and such an unattainable standard may have a detrimental 
impact on innovation. We strongly believe that this should be replaced with a 
requirement for firms to take appropriate steps to identify the risk of errors and 
mitigate as appropriate. This is particularly important given the heaviest fines are for 
non-compliance with the data governance requirements.  
International collaboration and engagement: We appreciate the Commission’s 
endeavours in pioneering a legally binding regulation on AI. We urge the Commission 
to continue to partake in the development of international standards and principles 
on the use of AI with international bodies. This is particularly important given the 
extra-territorial application of the proposed Regulation.  
In particular, we suggest the Commission should look to international best practice, 
for example the Monetary Authority of Singapore’s Veritas Consortium, which brings 
together industry practitioners with the primary financial services regulator to develop 
practical, proportionate and implementable Standards. 
We would be very pleased to discuss our views in further detail. 
Yours Sincerely 
Pier Luigi Culazzo 
Group Chief Data Officer 