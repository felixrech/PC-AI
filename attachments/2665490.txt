Johnson & Johnson’s 
contribution to the public consultation on 
the Artificial Intelligence Act proposal 
6 August 2021 
AI Act: an opportunity to build trust and foster innovation 
Johnson & Johnson welcomes the opportunity to build a trustworthy and innovative ecosystem for 
artificial intelligence (AI), where the AI Act (AIA) plays a critical role in combination with the existing 
regulatory framework. The AIA should have a clear scope and framework, facilitating its 
implementation and avoiding complexity, in order to build trust between citizens, developers, 
deployers and users and create a favourable environment which fosters innovation. The 
international implications of this regulation and cross-border regulatory cooperation are important 
to ensure EU citizens and businesses have access to beneficial AI solutions. 
The AIA includes in its objectives addressing health-related AI systems, and aims to support parties 
in effectively managing risks and unlocking the potential benefits of using AI in healthcare. We 
support the current approach of focusing on healthcare applications that are covered under the 
Medical Devices Regulation (MDR) and In-Vitro Diagnostics Regulation (IVDR), such as Software as 
Medical Device (SaMD). 
An efficient, harmonized and consistent regulatory framework working in conjunction with 
existing legislation on medical technologies and privacy 
This proposal is joining a very robust regulatory framework which already addresses potential risks 
emerging from the development and use of AI in medical technologies. The interplay of the new 
regulation with regulations such as the General Data Protection Regulation (GDPR), MDR and IVDR 
needs to be further clarified. 
Medical devices, including many aspects related to medical software, are comprehensively and 
clearly regulated under the EU MDR/IVDR, which pursue similar objectives as the AIA, i.e., ensuring a 
high level of protection of human health and avoiding a harmful impact on the health and safety of 
persons, and they already take into account the use of AI systems operating as “components of 
products”. In order to achieve legal certainty, we believe that those requirements (e.g., conformity 
assessment, database registration, Notified Bodies, etc.) already specified under the sectoral 
legislation, i.e., MDR/IVDR, should supersede AIA provisions. Nevertheless, the AIA may help fill 
any potential gaps by giving a framework upon which the Medical Devices Coordination Group 
(MDCG) could develop further guidance for AI in medical technologies. 
The scope of the regulation needs a clear definition of AI. As written, it could cover any software or 
statistical approach, leading to a lack of certainty regarding which products are within the scope of 
which obligations. 
Taking into account the GDPR experience will be fundamental for a successful development of this 
regulation, as we observed how important objectives and well-intended architecture led to 
fragmented interpretation and inconsistent implementation across Member States. The role and 
flexibility given to Member States should not lead to divergence but rather to ensuring a more 
cohesive and harmonized interpretation, implementation and enforcement of the legislation. For 

instance, we believe the deployment and outcomes of the regulatory sandboxes should also be 
aligned and leveraged at the EU level through the appropriate mechanisms (AI Board, MDCG) to 
avoid fragmentation across countries. Clarifying the role of the European Artificial Intelligence Board 
and empowering it compared to National Boards within the aligned regulations will help ensure 
consistent interpretation and implementation of the AIA. Sufficient expert and public oversight will 
be necessary, while protecting its independence to ensure and preserve public trust. Per the 
European Commission Proposal, Member States should be encouraged to set up a basic framework 
around complex liability cases such as injuries/accidents where it is challenging to track specific 
human decisions due to the gradually increasing autonomy of the AI technology. 
The requirements in this regulation will demand considerable effort and implementation time by 
regulators and all relevant stakeholders, including multiple industries. Therefore, based on the 
experience of key pieces of the New Legislative Framework such as MDR/IVDR and the Machinery 
Directive, 24 months would not be enough for such implementation period and we urge 
consideration of a minimum of 36 months for implementation. 
Finally, we also welcome the development of voluntary codes of conduct for low-risk applications 
where aspects such as transparency, explainability, human oversight, and monitoring could benefit 
from relevant guidance. ​For example, ALTAI (European Commission’s High-Level Expert Group’s Assessment List on Trustworthy 
Artificial Intelligence), OECD Principles on AI, and the WHO Guidance on “Ethics and governance of artificial 
intelligence for health” ​  
Striving for strong alignment with MDR/IVDR 
Aligning the risk levels in the AIA proposal with those under MDR and IVDR will be fundamental to 
ensure legal certainty. While the AIA does not imply a change in classification under MDR/IVDR, the 
denotation of AI systems as high-risk should not mislead or alter the original classification under 
MDR/IVDR. There are also other important elements which require clarification or specification to 
avoid a misalignment or duplication with MDR/IVDR. We advocate for: 
Alignment of submissions, assessments and CE markings, particularly after the recent 
application of MDR/IVDR which establishes a rigorous framework on medical technologies. 
Alignment of changes in AI systems and requirements for new submissions with existing 
guidance for SaMD and internationally with other regulatory agencies, such as the United 
States Food and Drug Administration (FDA). 
Consistent definitions with MDR/IVDR. The definitions of safety and quality under 
MDR/IVDR take precedence, as they are intrinsically linked to the intended purpose and use. 
Definitions like “provider” (vs “manufacturer”) or “serious incident” are also inconsistent 
with those under MDR/IVDR. The obligations for manufacturers and importers should also 
be clearly distinguished. 
Clarify the role of Notified Bodies regarding designation for AI competencies; time to 
designation and capacity; roles and responsibilities in conformity assessment; and 
implications for medical devices certified by them. 
EUDAMED should be used as the database for medical devices and in vitro diagnostic 
devices, without additional requirements. Unique Device Identification - device identifier 
(UDI-DI) (as required under MDR and IVDR) should be used as the system of traceability for 
issuing entities. Furthermore, the post market surveillance of these devices should be 
reported via EUDAMED, avoiding the addition of new reporting pathways or burden. 

AIA requirements: need for further guidance and legal certainty 
Many aspects of the legislation, such as the requirements for good testing practices (Article 9), data 
governance (Article 10), technical solutions on cybersecurity (Article 15), criteria for nonconfidentiality (Article 33), will require further details addressed in guidance developed by relevant 
regulatory bodies, such as the Medical Devices Coordination Group. This regulatory guidance will 
need cross-stakeholder input throughout and actual use cases and examples to bring more clarity 
and applicability to the guidance. For instance, data requirements seem to be developed for 
supervised models but unfit for unsupervised ones. Further clarity is also needed on how the 
statistical properties around bias shall be integrated, measured and monitored, how full 
transparency can be ensured, and which testing and security controls are to be implemented to 
address bias. 
The roles and responsibilities along the AI value chain, including citizens, developers, 
manufacturers, deployers and users, must be clearly defined. The regulation can help ensure safety 
as a continuum by appropriately addressing the lifecycle management of AI systems, from 
development to deployment and use. However, the regulation does not specify proportionate and 
clear obligations for 3rd party providers, which would be needed in order to avoid placing 
unreasonable burden or unattainable obligations on AI providers. 
Data Governance as core element to AI development 
The establishment of clear standards of collection, storage, and handling of data will enable data to 
be shared, combined and used for the purposes of using AI applications safely for innovation. A 
balance between the AIA requirement to use representative and relevant data for training and 
validation and the implications of GDPR for access to such data is essential to ensure robust and 
representative AI solutions. 
Implicit links exist between privacy-by-design and security-by-design under the GDPR, and risk 
management under the MDR/IVDR. The AI Act adds a new layer of regulation, which will make 
designing and deploying AI systems even more complex. A clear, transparent and efficient process 
for ensuring consistency and alignment across the overlapping remits of the MDR/IVDR, the AI Act, 
and GDPR requirements could position Europe in a leading role in fostering AI innovation. 
We welcome the proposal to address bias (Article 10 (5)) by providing a legal basis under GDPR 
which would allow processing of certain types of personal data in high-risk applications. However, 
additional guidance will be needed on acceptable bias. ​Again see ALTAI (European Commission’s High-Level Expert Group’s Assessment List on Trustworthy 
Artificial Intelligence), OECD Principles on AI, and the WHO Guidance on “Ethics and governance of artificial 
intelligence for health” ​  