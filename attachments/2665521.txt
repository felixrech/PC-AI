Feedback on the Artificial Intelligence Act  
The Center for Data Innovation (Transparency Register #: 367682319221-26) is pleased to respond 
to the European Commission’s public consultation on the Artificial Intelligence Act (AIA). ​“Artificial intelligence – ethical and legal requirements,” European Commission, n.d., 
https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethicaland-legal-requirements_en. ​  We agree 
with the Commission’s position that artificial intelligence (AI) technologies should be subject to a 
well-designed regulatory framework. This framework should encourage the responsible adoption and 
use of the technology to benefit society, provide guardrails that address potential harms, and foster 
growth and innovation in the European digital economy. AI represents a new frontier of digital 
technology whose impact on the economy and society will be transformative in the next decades. It is 
of central importance that the EU creates conditions where citizens can take advantage of the 
incredible range of opportunities AI represents for new sources of growth, productivity, and scientific 
progress that will make Europe richer, healthier, and safer. 
OVERVIEW OF THE CENTER FOR DATA INNOVATION’S POSITION ON THE 
ARTIFICIAL INTELLIGENCE ACT 
The AIA is too broad in its attempt to regulate an entire stack of technologies and applications at 
such an early stage in the development of AI. The added cost for the development and deployment of 
AI imposed by the many regulatory obligations in the Act will impose an expensive burden on the 
European digital ecosystem. In particular, the AIA, along with other regulatory barriers to market 
entry and growth, will make it difficult for European digital entrepreneurs to set up new businesses, 
grow them, and in the process create jobs, technological progress, and wealth. In 2000, the Lisbon 
Strategy set out to make Europe “the most competitive and dynamic knowledge-based economy in 
the world.” The EU has not achieved this goal, and the proposed top-down regulatory framework for 
AI development and use will once again create difficult conditions for new businesses to enter a 
revolutionary digital market, resulting in more missed opportunities for growth in Europe. 
The AIA sets up an overarching regulatory framework for the widest possible range of AI algorithms. 
This approach is a flawed way to regulate a general-purpose technology like AI, which is more akin to 
the wheel, electricity, or the internal combustion engine, rather than specific technologies like 
automotive vehicles, airplanes, or the Haber process for ammonia production. AI involves a 
constantly evolving set of tools, methodologies, algorithmic frameworks—in other words, it is not an 
explicit device or engineering process, but rather an information-technological approach that will end 

up embedded in many different social and commercial products and services, and thus is not easily 
amenable to singular regulation. It is impossible to predict the future impact of AI today and attempts 
to impose broad a priori rules on the technology will most likely create deadweight losses, 
opportunity costs, second-order effects, and other kinds of deleterious impacts on the rate and reach 
of digital progress in Europe. 
The Center for Data Innovation recommends a regulatory approach for AI based on the idea of 
algorithmic accountability: the principle that an algorithmic system should employ a variety of 
controls to ensure the operator (the party responsible for deploying the algorithm) can verify it acts in 
accordance with its intentions, as well as identify and rectify harmful outcomes. Adopting this 
framework would both promote the vast benefits of algorithmic decision-making and minimize 
harmful outcomes. ​For more, see Joshua New and Daniel Castro, “How Policymakers Can Foster Algorithmic Accountability,” May 21, 
2018, https://www2.datainnovation.org/2018-algorithmic-accountability.pdf. ​  This regulatory approach focuses on evidence-based action against documented 
harms, rather than an ex ante approach that tries to foresee how a new technological stack is used. 
Algorithmic legislation should focus on the idea that the operators of such tools can demonstrate 
they had controls to ensure the system was acting as intended. This approach allows for the 
regulatory framework to change over time as market forces, social norms, new technologies, and 
other factors shape the use of algorithms in society. 
Beyond suggesting a different overall approach to regulating AI, we have the following concrete 
recommendations on how to improve the AIA. 
EXPAND AI REGULATORY SANDBOXES 
One of the costliest negative externalities the AIA creates is the reduction in the opportunities for AI 
development and use in Europe. Because the AIA applies horizontally, it dampens the prospects of 
European startups and small and medium enterprises (SMEs) developing and using AI. The AIA’s 
regulatory sandbox provision is a sandbox in name only: It promises close regulatory oversight 
without any meaningful concessions in return. A sandbox should allow companies to experiment with 
new technologies free from some or all of an existing regulatory framework, while regulators monitor 
the impact. The sandbox acts as a two-way street: if regulators see that suspending certain rules or 
requirements does not lead to adverse outcomes, they conclude that these rules are redundant. A 
better approach for the AIA’s sandbox would thus be to lift certain legal or regulatory requirements in 
exchange for closer supervision of outcomes by regulators. This would allow businesses to creatively 
experiment with new AI systems and see what impact various requirements have or do not have in 
the real world. 

To improve the AIA, the sandbox should: 
1. Create a full exemption of the law’s requirements for new businesses that can demonstrate 
they are closely monitoring and reporting on the safety and reliability of their systems. 
2. Make it easy and straightforward for new businesses to join the sandbox and ensure new 
businesses working on AI have a legal right to participate in a sandbox where the AIA does 
not apply. 
3. Exempt participating businesses from complying with the AIA until they have demonstrated 
the viability of their product and have begun to scale. 
A major expansion of the sandbox provision is necessary to avoid making the EU a graveyard for 
domestic AI development where only mature AI companies go to sell their wares once they have 
scaled elsewhere. In addition, the AI regulator should apply learnings from sandbox participants into 
the law. For example, they should drop certain provisions if they turn out to be unnecessary or 
replaceable with more efficient alternatives that do not adversely affect consumer rights and safety. 
RELAX PROBLEMATIC TECHNICAL REQUIREMENTS 
On multiple occasions, the Commission stressed that the purpose of the Act is not to regulate the 
technology of AI itself, but its use, depending on the level of risk it creates. However, several 
requirements for high-risk AI systems are specific technological regulations. The following obligations 
are problematic, as they are at odds with the technical realities faced by AI developers: 
1. “Training, validation and testing data sets shall be relevant, representative, free of errors and 
complete.” Most useful and relevant data sets would not meet such a high bar. While data 
quality is important, especially in unsupervised learning, many AI systems are designed to 
turn messy and noisy data into useful outputs. This requirement introduces an unattainably 
high bar for many types of AI systems and rules out an entire class of useful AI tools in 
Europe for the future. 
2. “For high-risk AI systems, the requirements of high quality data, [...] traceability, [and] 
transparency [...] are strictly necessary.” Requiring “traceability” and “transparency” as 
strictly necessary is problematic as these are contentious terms subject to varying 
interpretations. Under a strict reading, this clause introduces a legal requirement for 
explainable AI in Europe. Many researchers are already working on interpretable AI. However, 
several AI methodologies are, by their very nature, explainable only at higher levels of 
abstraction. This does not inherently reduce their usefulness. Indeed, plenty of human 
decisions are themselves untraceable. It is unreasonable to expect all AI systems to be 
traceable, as risks to fundamental rights can be mitigated through other tools (e.g., the right 
to appeal a given decision). 

CLARIFY AND REMOVE UNNECESSARY AND BURDENSOME COMPLIANCE REQUIREMENTS 
The legislation creates an immense compliance burden for developers and users of high-risk AI 
systems. Europe’s SMEs (which make up 99 percent of all businesses in Europe) stand to benefit 
from adopting and implementing AI tools to improve their ability to plan, decide, and manage 
resources, including human capital, and thus increase their productivity and raise wages. However, 
SMEs will be deterred from adopting AI tools by the enormous workload the AIA creates for them 
which will force many businesses to shift resources from investment to compliance. It is therefore of 
great importance that the AIA maintains the current self-assessment procedure and declaration of 
conformity, as mandating third-party compliance verification would be prohibitively expensive for 
most small businesses. The EU needs to incentivize the increased use of AI by European companies, 
as this will have important spillover effects for economic growth, productivity, and wages. 
To reduce some of the AIA’s burden, the proposal should be modified as follows: 
1. Adjust the overly prescriptive requirement for humans to “fully understand” an AI system, 
and instead require operators to “understand the principles governing the AI system and 
verify it acts in accordance with their intentions.” 
2. Remove “inference and deductive engines” and “statistical approaches” from Annex I, as 
these are vague terms and are likely to encompass a huge range of software systems which 
it is unreasonable to categorize as constituting AI. 
3. Clarify and align the terms “placing on the market”, “making available on the market,” 
“putting into service,” and “developed with a view to placing it on the market,” to avoid 
confusion. 
4. Include a statutory commitment to liaise and align new standards with efforts from 
recognized international standard-setting bodies such as IEEE or from allied nations such as 
NIST, as well as seek input on these standards from industry voices, to ensure harmonized 
standards are created with a view to setting up an AI governance framework that extends 
beyond the EU and has an international dimension, especially in terms of compatibility with 
other like-minded democracies. 
FINAL COMMENTS 
The many calls by civil society to further expand the bans on various AI tools must be resisted. The 
Commission is to be lauded for its balanced approach now how to regulate the use of biometric 
recognition tools by public authorities. Banning such tools outright represents an assault on 
European citizens’ rights to live safe and secure lives, especially given that the AIA takes such care to 
ensure that privacy rights are respected by AI. 

As a regulatory guiding principle, the Commission should bear in mind that the right to privacy coexists along other fundamental rights for European citizens, rights to economic opportunity, to 
security, and to progress. The EU should not sacrifice the prospects for dramatic, foundational 
improvements to technology and society in the coming decades because of a fear of new digital 
tools. AI is arguably the most important human advancement since electricity. The European Union 
should ensure that it helps the peoples of Europe take advantage of this powerful new technology, to 
use it innovatively and help it generate growth. Businesses and societies that want to participate in 
this next wave of technological change need to be incentivized to do so, not hamstrung with a new 
set of costly and cumbersome regulations.  