Onfido’s response to the European Commission’s proposal on a 
regulatory framework for Artificial Intelligence 
About Onfido 
Onfido is the global remote identity verification provider that partners with 1,600 
organisations worldwide, including many EU fintechs such as Adyen, Bunq, Getaround, Nickel, 
Revolut, Wise and Monese. Our leading biometric and AI technology enables clients to prove 
that their customers are who they claim to be, enabling them to comply with regulatory 
obligations including AML and KYC requirements in the EU. We use a hybrid model that 
combines machine learning with human expert oversight, which delivers best-in-class speed, 
consistency and accuracy. 
Started just nine years ago, we have scaled rapidly, and now employ over 100 people across 
the EU and more than 4500 worldwide, with offices in Paris, Lisbon, London and Berlin as well 
as the US, Singapore and India. We are continuing to invest and grow our EU presence to 
meet increasing customer demand in both the fintech space and other verticals. 
We are thought leaders in AI bias, ethics, fraud, security and privacy. We were winners of the 
2020 CogX Award for “Best Innovation in Algorithmic Bias Mitigation” and “Outstanding 
Leader in Accessibility” and were “Highly Commended” in the SC Europe Awards 2020 for 
“Best Use of Machine Learning”. ​https://onfido.com/resources/blog/onfido-wins-best-innovation-in-algorithmic-bias-mitigation-outstanding-leader-inaccessibility-at-cogx-2020 ​  We work with Interpol to develop leading practice in fraud 
prevention and publish a widely-acclaimed annual Fraud Report considering the state of the 
market. ​https://onfido.com/landing/fraud-report-2020/ ​  Onfido is a founding member of the Better Identity Coalition in the US and a member 
of the FIDO alliance dedicated to best-in-class global authentication standards. 
Onfido embraces the opportunity to share our expertise and experience to help develop 
regulatory reforms to foster innovation, accessibility and financial inclusion for all across 
national borders. We would be delighted to expand further on any of the detail below. 
European Commission proposal laying down harmonised rules on AI 
In its proposal from April this year, the European Commission sets out new rules that seek to 
increase trust in AI, with the main objective to guarantee the safety and fundamental rights 
of EU citizens while improving AI technology in the EU. The Commission proposal states that 
addressing the opacity, complexity, bias, unpredictability and partially autonomous 
behaviour of AI, as well as the necessary compatibility of AI with fundamental rights and 

enforcement of legal rules are key priorities. Onfido supports the introduction of a clear and 
proportionate legal framework around the use of AI. Fostering trust among citizens and 
certainty for businesses is critical. 
The risk-based approach proposed by the European Commission rightfully recognises the 
need to balance the protection of fundamental rights with the need to foster innovation in 
AI, which is crucial to ensuring the EU remains competitive in the global AI space. 
Definitions and consistency 
However, we are concerned that currently there is a lack of clarity on key terms and 
definitions within the proposals and a lack of consistency across other documents. It is vital 
that going forward all stakeholders have the same understanding of these terms and the 
scope of definitions used. 
In particular there needs to be a clear understanding of the risks and human rights 
implications of different AI systems with reference to the definitions used. The February 2020 
White Paper makes reference to “Remote biometric identification” and defines this as “when 
the identities of multiple persons are established with the help of biometric identifiers 
(fingerprints, facial image, iris, vascular patterns, etc.) at a distance, in a public space and in a 
continuous or ongoing manner by checking them against data stored in a database.”​https://ec.europa.eu/info/sites/default/files/commission-white-paper-artificial-intelligencefeb2020_en.pdf (footnote 52, p18). ​  
The White Paper seeks to make a distinction between such identification systems and 
“authentication”. It describes the latter as “a security process that relies on the unique 
biological characteristics of an individual to verify they are who they say they are”. ​https://ec.europa.eu/info/sites/default/files/commission-white-paper-artificial-intelligencefeb2020_en.pdf (footnote 52, p18) ​  It also 
suggests that “Authentication (or verification) [..] is often referred to as one-to-one matching. 
It enables the comparison of two biometric templates, usually assumed to belong to the same 
individual. Two biometric templates are compared to determine if the person shown on the 
two images is the same person.”​https://ec.europa.eu/info/sites/default/files/commission-white-paper-artificial-intelligencefeb2020_en.pdf (footnote 56, p21) ​  
Yet in the AI proposal, a “remote biometric identification system” is defined differently, and 
“authentication” is not defined at all. We would urge the Commission to take the time to 
ensure consistency of definitions and terminology. If not, there is a risk that AI solutions and 
services posing a relatively low level of risk are nonetheless captured by definitions deeming 
them to be high risk or even prohibited. This would undermine the risk-based approach and 
the credibility of the proposals. 

We consider that the definition of “remote biometric identification” used in the White Paper 
is appropriate and should be carried through to the AI proposals. 
Measures to encourage innovation 
It is vital that the AI Act is balanced in terms of protecting users and encouraging trust on the 
one hand, and promoting innovation and investment on the other. To that end we consider 
that it should promote the use of industry-driven standards which are flexible and outcomesbased. 
Even in high-risk areas, we need to ensure that we are not shutting down innovation and we 
are promoting responsible use of AI. To that end we strongly support the encouragement of 
sandboxes as a means to experiment in a safe environment, and this needs to be more than 
just a token gesture. It needs to be part of a wider push to stimulate dynamic innovative firms 
and encourage investors to back them. As well as setting rules we see the Regulation as 
creating the potential to unlock new services which are hugely beneficial to users and 
business. We would urge that this opportunity is not lost or diluted and would strongly 
welcome the opportunity to outline our thoughts on this. 