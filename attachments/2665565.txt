1 / 10 
Consultation to the European Commission’s AI 
Regulation Proposal 
Nokia’s submission 
6 August 2021 

2 / 10 
Contents 
1 
Introduction .......................................................................................................................... 3 
2 
Remarks on the Commission’s approach .......................................................................... 3 
3 
The scope of the proposed regulation ............................................................................. 3 
4 
Assessing Applicability ......................................................................................................... 4 
Achieving trustworthiness ................................................................................................... 4 
Transparency ........................................................................................................................ 5 
4.2.1 
Data and Data Governance ................................................................................................. 5 
4.2.2 
Source Code Disclosure ....................................................................................................... 6 
Human Oversight Requirements ........................................................................................ 6 
5 
Measures Supporting Innovation ....................................................................................... 7 
6 
Standardization efforts ....................................................................................................... 8 
7 
Competitiveness of European Union Innovators ............................................................. 9 
8 
Enforcement ......................................................................................................................... 10 
9 
Closing remarks .................................................................................................................... 10 

3 / 10 
1 
Introduction 
Nokia congratulates the European Commission on the impressive accomplishment of proposing 
on 21 April 2021 what effectively constitutes the first regulation on Artificial Intelligence in the 
world. 
The proposal is clearly based on a significant amount of research, information rounds and 
consultations of numerous stakeholders. We regard it as a courageous first take on a topic that 
is highly debated by a wide variety of specialists. 
Nokia is honored to have been given the opportunity to contribute to the debate through its 
participation in the High-Level Expert Group. We are equally keen to continue to play a part in 
clarifying the legal and regulatory regime applicable to Artificial Intelligence systems. 
The present position paper represents Nokia’s initial feedback to the Commission’s public 
consultation on the proposed package and touches upon a limited number of issues which we 
consider need urgent clarification. 
2 
Remarks on the Commission’s approach 
Nokia considers that the proposal for a "Regulation laying down harmonized rules on Artificial 
Intelligence" (the "Regulation") is a reasonable first attempt to tackle this topic given the 
enormous complexity of the technology. Nokia particularly welcomes the explicit 
acknowledgment that Artificial Intelligence represents a source of good for citizens, businesses 
and public interests. This is an approach that demonstrates the trust that European legislators 
have in the potential of this technology to help humanity solve significant societal and individual 
challenges and may prove useful in tackling skepticism regarding AI. 
Nokia also acknowledges the Commission’s inventiveness in employing original regulatory 
processes and techniques to future-proof the regulation. 
This approach will hopefully result in relatively quick adaptations and updates of the regulation 
as the technology evolves, particularly as we are of the opinion that the text will require several 
alterations not only before it can be implemented into practice, but also post-ante, as its 
shortcomings become obvious through practice. 
3 
The scope of the proposed regulation 
We take note that a definition of Artificial Intelligence per se is not included in the text of the 
proposal (rather, the explanatory memorandum is referring to it as “a family of technologies”). 
Nokia considers this a thoughtful approach, given the lack of consensus in the scientific 
community on the exact meaning of such a complex technology and its evolving nature. 
However, we also point out that the mere absence, at the time of the proposal, of a clear 
definition of what exactly constitutes the object of the regulation raises questions as to whether 
Artificial Intelligence should be regulated specifically at this point in time. 

4 / 10 
The fact that the Commission opted to define AI systems in a manner aligned with the OECD is 
commendable as an attempt to ensure consensus, but may not help clarify what exactly needs 
to be regulated (that is not already regulated). 
Nokia considers the definition given to AI systems in Annex I of the draft Regulation to be 
complete in that, by taking this approach, the Commission acknowledges the evolutive nature of 
AI and declares the aim of the Regulation to cover all currently known techniques and 
approaches to develop them. However, the definition itself is overly broad. It attempts to 
include both approaches which have been around for decades (i.e. the statistical approach and a 
good part of the machine learning approach), as well as an approach that has been used with 
relative success only in the very recent past. That particular approach represents a very small 
part of what the Regulation is referring to as “AI system”, namely deep neural networks (“DNNs”) 
and it brings about the most concerning aspects of the technology from an EU human rights and 
values perspective, given the capability of DNNs to mimic certain key human cognitive functions. 
From this perspective, Nokia is of the opinion that the draft Regulation is casting too wide a net, 
capturing too much subject matter and, as a result, becomes difficult - if not impossible - to 
implement in practice. To demonstrate why this generality is unenforceable, we ask the 
Commission to consider a hypothetical legislative proposal which aims to deal with "any 
computational technique that is harmful to humans and society". While the legislator’s intention 
might be good, as it stands, the proposal will undoubtedly be too broad to be useful in practice. 
In such circumstances, a less ambitious legislative approach with the intention of enabling 
enforceability is preferable to an approach that is much too general and thus ineffective. 
4 
Assessing Applicability 
Achieving trustworthiness 
The draft Regulation introduces a set of rules, following a risk-based approach, to establish the 
conditions for “an ecosystem of trust”. The rules are referring in particular to the placing on the 
market, putting into service and use of AI systems in the EU. 
While Nokia considers that “trust” is an extremely important element in a modern technology 
context such as the one created by AI, given the impact AI is expected to have on society, we 
also are of the option that individual trust represents an impractical, if not unreachable target as 
a legal concept. 
Nokia sincerely commends the Commission’s effort to move away from the purely ethical 
aspects of AI and trust, towards the legal aspects of risk, safety and human rights. In this regard, 
we noted that the Commission took the approach to regulate high-risk applications and uses of 
AI in particular, rather than the technology itself – which would have been premature, given the 
consensus on a definition, as described above. 
Under this assumption, the key question that needs urgent answering before submitting an AI 
system to any further regulatory requirements is: what represents “high risk”? Nokia considers 
that, in the light of the broad definition assigned to AI systems in the Regulation, the 
Commission's definition of what constitutes “high risk” needs to be further elaborated upon as 
Article 6 is currently ambiguous. 

5 / 10 
Providing a clear and explicit list of criteria that serves as a useful instrument for assessing 
whether an application or system qualifies for the processes described in the draft Regulation is 
imperative. A great portion of this draft Regulation refers to high-risk AI systems, yet the most 
critical element – that referring to clarity of eligibility and assessment criteria is missing. This will 
not only result in uncertainty for manufacturers and producers, but also in unclarity for users, 
regulators and judicial actors. Simply providing a limitative list of high-risk applications (as in 
Annex III), even if such a list can be appended with relative legislative ease, is simply not 
sufficient, given the complex and rapidly evolving nature of AI systems. 
As a provider of communications equipment and technologies, including AI-based solutions, 
Nokia wishes to particularly highlight the ex-ante uncertainty caused by these gaps of the 
proposal. Hence the urgent need for the Commission to clarify this aspect. 
Transparency 
4.2.1 
Data and Data Governance 
The level of algorithmic transparency required in the draft Regulation seems reasonable and 
plausible at first sight. However, Nokia is of the opinion that these requirements – as simple as 
they may seem – are effectively impossible to meet with present-day technologies, including AI 
itself and thus lacks merit if required on a wide scale. One example of the level of complexity is 
afforded by a database with tens of millions of images of thousands of categories of items in a 
data set provided through crowdsourcing, with thousands of samples for each category. The 
items include images of cats, dogs, doors, windows, trees, pots, pans, etc. These images include 
no highly specialized items such as electronic circuit boards. The demands on time and 
resources to check whether these images are representative of the categories they are 
supposed to represent are immense. Moreover, in the future there will be numerous and larger 
datasets for specialized tasks, such as collections of images of wounds for medical diagnosis, 
examples of paragraphs for writing contracts and legal documents, etc. As some AI systems 
require millions of data points, massive resources will be required to check the suitability or 
unbiasedness of the data (as required by Article 10.2 points e and f) and companies will be 
required based on Article 10.2.g to guarantee that there are no gaps or shortcomings in those 
datasets. Irrespective of whether these tasks are to be performed by humans or AI itself, the 
costs are significant. 
Nokia maintains that as of today there are no reliable classification methods that work on 
encrypted data without using source data. In spite of attempts having been made at this, and 
some are more promising than others, no classification methods that can meet such legal 
requirements exist at the moment. Among the best attempts, please refer to InstaHide, that 
was awarded the Bell Labs Award in 2020 and shortly afterwards was shown to have information 
leaks for small data sets. It is thus our opinion that it is highly unrealistic to expect even the 
most well-funded regulators to be able to identify potential non-compliance instances and to 
demand the system developers to do this prior to placing systems on the market. 

6 / 10 
4.2.2 
Source Code Disclosure 
Closely related to the issue of data disclosure is the requirement to allow access to the source 
code. It is a known fact that, with only a few exceptions, the review of any source code is 
complex, and AI systems are on the more complex end of the spectrum of systems. The 
estimate number of lines of code used in AI systems currently is in the millions, and regulators 
would require massive resources (financial and others) to achieve even rudimentary 
understanding. 
Moreover, a company’s source code is usually highly guarded, and disclosed generally only on an 
as-needed basis. It contains sensitive and often trade secret information, which if not properly 
protected may result in competitive damage to the company. Putting in place appropriate 
security measures (physical and electronic) is a significant responsibility for any undertaking. 
Breaches in that security (detected or undetected) may render deployed code vulnerable to 
attack or to further breaches. This requirement alone will have the potential to reduce the 
companies’ incentive to invest in developing AI systems. Nokia urges the Commission to reexamine this requirement. 
Nokia acknowledges that AI systems that have the potential to cause harm to individuals and 
their fundamental rights should be subject to an appropriate level of scrutiny. Such scrutiny 
should be based on controls at the level of the AI system operator, to ensure that the systems 
act as intended, to identify and potentially rectify unwanted outcomes that have the potential 
to cause harm. In many cases, such accountability frameworks are already in place and are 
functioning well, without particular requirements regarding the disclosure of the source code or 
of the ways software that is being used works. 
Nokia cautions against the use of overly simple disclosure and transparency requirements which 
will likely be ineffective in preventing harm, in addition to having the potential to disincentivize 
investments in further innovation in AI in Europe. 
Human Oversight Requirements 
Nokia considers that the European Commission’s proposals regarding human oversight as 
described in Article 14 of the proposed AI Regulation reflect an ideal view of humanity’s capacity 
to control acts of intelligent machines. Implementing human oversight is a risk mitigation 
measure that may prove, at least theoretically, successful, from the perspective of avoiding 
harm and fundamental rights infringements linked to the use of AI. However, Nokia believes that 
for purposes of enabling further development of AI technology, it is imperative to understand 
that these requirements, in their present form, are unfeasible and their transposition into law 
provides a false and unrealistic sense of safety and may actually legitimize . 
The whole point of AI is to automate fairly simple cognitive tasks that humans perform with 
relative ease and for which automation has not existed a decade ago. The idea is that AI will 
then be able to perform these tasks at scale. For example, whereas a human can label an image 
as a cat, a dog or a frying pan in 1 second, AI will do this in 1 microsecond and thus label 10as 
many images in the time a human does it. It is thus unclear at this point how can humans 
maintain oversight over a system that is that much faster than themselves. 

7 / 10 
The efficiency of AI systems come to the fore when replicating tasks that previously required 
human cognitive abilities at scale. At present, this can be done in an exceptionally small number 
of cases but maintaining humans in the loop defeats the purpose of automation. 
The current requirements, as formulated, imply a binary choice between implementing AI and 
assuming the risk that undesirable outcomes may occur, or not implementing AI due to 
awareness of the possibility that such tendencies of AI systems cannot be previously checked as 
required by, for example, article 14.4. point b) of the present draft AI Regulation. This choice 
should not, however, need to be made and should definitely be re-examined and rephrased in a 
way as to avoid conflicts of priorities or a false sense of legitimacy. 
Similarly, the requirements contained in article 14.4 points c) and e) are practicable only if the 
output of the AI system is sufficiently small for human experts to have the time to interpret 
each of the recommendations of an AI system before their being implemented – which in certain 
situations may prove either inefficient in terms of volumes of output, although conducted in 
accordance with existing practice, as required by existing legal provisions (e.g. the GDPR), or 
unrealistic in terms of implementation due to technical or time limitations. 
Moreover, some of the requirements foreseen in Articles 14 and 15 are already part of normal 
procedures in many companies; however their accuracy depends on the parameters defined for 
those processes, such as for the so-called training-validation-test (“TVT”) cycle, and on the 
feasibility of the requirements for the training data. However, any particular situation could be 
right or wrong only with the probabilities derived from the TVT cycle. Moreover, it is currently 
unclear how new data (as per paragraph 3 of article 15) are labeled for new learning under these 
conditions, given the lack of efficiency caused by the involvement of a human in the cycle. And 
otherwise, if AI is used for this purpose, then errors can be easily propagated, and the system 
can be made even less transparent and understandable. 
Overall, Nokia feels compelled to caution the European Commission that while some 
requirements may seem theoretically appropriate, in practice, they may prove either 
meaningless due to their generality, or impossible to achieve or implement in practice, if 
efficiency is the goal of the use of an AI system. 
5 
Measures Supporting Innovation 
Nokia welcomes the proposed measures for supporting innovation. We are particularly pleased 
with the introduction of regulatory sandbox schemes as an instrument that can be established 
by national regulators, as the AI regulation contains the possibility of the use of regulatory 
sandboxes at member state level. Inclusion of regulatory sandboxes is clearly done with the aim 
to create future proof instruments which enable the implementation of innovation-friendly 
measures, and to increase resilience. 
Nokia recognizes these instruments as enablers of innovation, which explains why this is one of 
the key areas of our interest, given the need for the present legislative act to accommodate 
future developments of a very complex technology. However, the idea of regulatory sandboxes 
needs to be implemented with great care. While in principle regulatory sandboxes can be great 
innovation enablers, their success depends on several factors. Typically, regulatory sandboxes 
open the way to advancing new regulatory measures while making sure that innovators have the 
opportunity to experiment with their ideas, testing them in a real-world environment, observing 

8 / 10 
effects and impact in a safe area. As the proposal currently stands, Title V of the AI Regulation 
only introduces general measures, which Nokia is concerned that member states will supplement 
with detailed measures which in turn will give rise to fragmentation of the European approach. 
From this perspective, Nokia sees as imperative the creation of a European-level, coordinated 
approach, following consultation with all stakeholders. Therefore, Nokia recommends that clear 
eligibility criteria for participation in a regulatory sandbox, including the modalities and the 
conditions applicable to experiments taking place in regulatory sandboxes are introduced in the 
final version of the act, allowing both for safe innovation, as well as for guidance in the 
implementation of the AI Regulation itself. 
Nokia also welcomes the proposed process for assessing product and market conformity and 
the use of harmonized standards for self-assessment for AI systems that are embedded in 
already regulated products. However, Nokia considers that there still is a stringent need for 
harmonization of conformity assessment processes, to avoid the need for recurrent or multiple 
reporting in front of several regulatory authorities. 
We welcome the new Coordinated Plan on AI outlining the necessary policy changes and 
investment at Member State level to strengthen the EU’s leading position in trustworthy AI. 
We are equally keenly awaiting the Commission’s proposals on the other legislative acts that are 
linked to the current draft regulation, as those could be a determining factor in the success of 
this proposal. Given the broad impact of AI in the digitization of society at large, Nokia is of the 
opinion that the current proposal needs to be seen in context and cannot be finalized separately 
from the new legislative framework, lest the high risk of discrepancy between the various legal 
instruments. 
6 
Standardization efforts 
The importance of standardization for the practical implementation of the AI Regulation is 
clearly expressed in the proposal and Nokia agrees with the European Commission about the key 
role it plays from technical, scientific, research, ethical, governance and policy perspectives. 
Given the expected impact of AI on society, the involvement of all stakeholders in 
standardization activities is necessary for governmental actors, along with the private sector 
and academia, to address societal and ethical issues, governance, and privacy policies and 
principles. These AI standards-related efforts include: 
Supporting and conducting AI research and development; 
Actively engaging in AI standards development; 
Procuring and deploying standards-based products and services; and, 
Developing and implementing supportive policies, including regulatory policies where 
needed. 
Nokia is involved in standards creation at all these levels and ready to contribute its expertise by 
working with the Commission in its efforts to adopt common specifications if standards for 
publication are not available, deemed insufficient or if there is a need to address specific safety 
or fundamental rights concerns as provided by Article 41. 

9 / 10 
While the AI community has agreed that the issues mentioned above must factor into AI 
standards, many decisions still need to be made about whether there is yet enough scientific 
and technical basis to develop those standards provisions. From this perspective, Nokia believes 
that in formulating common specifications, the European Commission should involve experts 
from both member states as well as industry stakeholders, to ensure viewpoints of different 
sectors and stakeholders are taken into account. Good examples of such approach exist in 
current legislation and implementation thereof, such as for example the ecodesign 
requirements on material efficiency aspects of energy-related products. 
Industry stakeholders that are involved in collaborative research and innovation play a crucial 
role in standards setting for the development and implementation of new technologies. By 
involving them, the European Commission will ensure that the EU maintains a leading role in the 
development of international, globally recognized, common standards into the Digital Decade. 
7 
Competitiveness of European Union 
Innovators 
Nokia applauds the Commission’s ambition to establish a European model for the development 
and use of AI systems which ensures an EU market for AI systems that balances related benefits 
and risks based on European fundamental rights and values. 
However, caution is recommended given the effects this type of approach could have on 
innovation and the setback that European companies could suffer when competing with US or 
Chinese companies. Most jurisdictions considering regulatory intervention on AI are adopting a 
light posture, by opting for the development of national AI strategies and action plans and most 
of these jurisdictions regard AI as a positive development. 
As highlighted under section 4 above, the unfeasible requirements related to human oversight 
and transparency could also discourage investment in the development of AI systems which 
could end up becoming prohibitively expensive to deploy. 
Furthermore, looking simply at the magnitude of the sanctions proposed in the draft AI 
Regulation, one could be tempted to simply hold back on any type of innovation that could 
potentially fall under the broad definition given to AI systems in this regulation proposal, for fear 
of being fined if processes are not followed to the letter – which, as explained above, would turn 
out to be an impossible task. 
Nokia believes that the current proposal could diminish any company’s appetite towards R&D in 
the AI field, thereby hurting EU competitiveness in the long term, certainly by comparison to the 
US and Chinese markets and actors. 
Nokia is prepared to engage in debate with all stakeholders and the European Commission in 
supporting the creation of a feasible risk assessment process for AI systems and appropriate 
mechanisms to assess compliance, avoiding an obstructive effect on European technological 
innovation and progress. 

10 / 10 
8 
Enforcement 
We note that the draft AI Regulation foresees the delegation of most enforcement powers to 
Member States, who are to designate competent EU Member State authorities and determine 
the penalties applicable to infringements of the AI Regulation. Given the complexity of AI as a 
technology, caution should be applied in selecting the competent authority, bearing in mind that 
certain areas tackled by the regulation will need specialized knowledge in order to assess 
compliance levels. Equally, in order to ensure competitiveness and an innovation-friendly 
environment, duplicative processes should be eliminated and avoided, communication between 
authorities involved in connected areas should be increased and coordination with specialized 
bodies prioritized. The extensive powers granted member states in enforcement of the 
regulation is a risky approach which could also result in fragmentation of the application of the 
AI Regulation, which is to be avoided. 
9 
Closing remarks 
Nokia thanks the European Commission for the opportunity to participate in this consultation. 
We are available for further discussions and would be honored to contribute our expertise for 
purposes of clarifying the issues highlighted above. 