28 June 2021 
Inquiries: 
Jussi Mäkinen, Head of Digital Regulation, jussi.makinen@techind.fi, +358 40 900 3066 
Alexander Törnroth, Head of AI Accelerator, alexander.tornroth@techind.fi, +358 40 187 7353 
AI Act – Focus on the Process and Predictability 
The Commission has come along with an ambitious proposal to regulate AI. Getting the balance 
right in ensuring that obligations drive policy outcomes, while allowing AI innovators sufficient 
flexibility in meeting those obligations, is going to be critical. Especially the ethical requirements 
will drive forward trust and sustainable use of AI solutions. 
AI one of the key technologies for reforming the European industry as AI-driven analysis and 
optimization tools can easily be implemented to any process of which data is available. AI plays a 
major role in making energy-consuming processes green. Use cases for AI can be numerous and it is 
essential to concentrate on regulation on truly horizontal issues, that are good software development 
practices. AI is software but the proposed definition covers not only AI, but basically all software. 
The proposal sets horizontal AI regime on top of harmonised NLF EU law. This structure brings along 
risk to cohesion of EU requirements. At least, this is an issue that needs close coordination from the 
Commission and close cooperation with the industries. Scope is set so that societally important use 
cases (Annex III) and AI-driven safety components and stand-alone AI products meant in the NLF 
framework are regarded being high-risk use cases. 
General requirements of the Chapter II are quite well oriented with the process of development of AI 
systems. However, the requirements on data – complete and free form errors - veer away from 
realism. As a rule, requirements should follow good AI development practice, e.g. MLOps. Set of 
general and role-based requirements are not essentially well-suited for in-house or specifically 
developed AI systems. As the Act is so detailed, it will place a heavy administrative burden, that is 
most heavily felt on SME companies. 
As a new field of technology, there are no existing standards or technical requirements for many usecases of AI. Commission cannot fix this by setting common specifications on its own, without any 
interaction with the industries. Here, the proposed regulatory sandboxes should be put into use. 
Commission has extensive powers to adopt delegated acts to adjust the definition of AI, use cases and 
set common specifications for AI. These major powers not only to fine-tune but to essentially adjust 
major elements of the Act bring along concern of legal predictability. 
Our suggestions 
Put more emphasis on due process and lineate requirements with good industry practices, such 
as MLOps. 
Remove excessive, casuistic, and highly detailed requirements. 
Concentrate on ethical issues and take good care of cohesion of regulatory requirements. 
Put regulatory sandboxes into proper use when developing common specifications for AI. 
Introduce proper limits for Commission powers to adopt delegated acts. 
Ensure there is a predictable lot for low-risk AI needed to optimise promises in many areas of 
society by limiting the scope, definition and introducing strict criteria for adjustment of highrisk use cases. 
To fuel innovation, build clarity on how privacy-preserving technologies can be used to facilitate 
processing of personal data. Ensure full lineation with the GDPR to have high-quality learning 
data for AI systems.  