Ref: EU Commission consultation on Artificial Intelligence (AI)- Ethical and Legal requirements 
Link to consultation: https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificialintelligence-ethical-and-legal-requirements_en 
BETTER FINANCE’s feedback on the EU Commission proposal on 
Regulation laying down harmonised rules on artificial intelligence 
(artificial intelligence act) and amending certain union legislative acts 
About BETTER FINANCE 
BETTER FINANCE, the European Federation of Investors and Financial Services Users, is the public 
interest non-governmental organisation advocating and defending the interests of European 
citizens as financial services users at the European level to lawmakers and the public in order to 
promote research, information and training on investments, savings and personal finances. It is the 
one and only European-level organisation solely dedicated to the representation of individual 
investors, savers and other financial services users. 
BETTER FINANCE acts as an independent financial expertise and advocacy centre to the direct 
benefit of European financial services users. Since the BETTER FINANCE constituency includes 
individual and small shareholders, fund and retail investors, savers, pension fund participants, life 
insurance policy holders, borrowers, and other stakeholders who are independent from the financial 
industry, it has the best interests of all European citizens at heart. As such its activities are supported 
by the European Union since 2012. 
Introduction 
The European Commission has proposed a Regulation laying down harmonised rules on artificial 
intelligence (artificial intelligence act) and amending certain union legislative acts. The purpose of 
this regulation is to provide a uniformed legal framework for the internal market regarding the 
marketing and the use of Artificial intelligence (AI). 
Artificial intelligence has been deployed in several sectors and economic activities, in particular 
services and products for consumers. Therefore, it is crucial to provide rules for the application 
of artificial intelligence in order to ensure safety and compliance with fundamental rights. The 
intent of the regulation is to provide a technology neutral definition of artificial intelligence 
systems that can provide legal certainty and at the same time is future-proof, gives enough 
flexibility in regard to future technological developments. 
The proposal establishes requirements for the use of AI in several activities and sectors. 
Regarding financial services, the proposal tackles the use of AI on the assessment of 
creditworthiness and credit scores. Individuals should be informed that they are interacting with 
an AI. These transparency requirements also include chatbots. ​https://www.pinsentmasons.com/out-law/analysis/what-eu-ai-act-means-financial-services ​  
The credit institution will need also to observe a series of requirements based on “high risk” 
criteria and to complement AI deployment with human oversight. ​Ibid. ​  

However, the requirements for the deployment of AI address only in part financial services and 
do not cover the use of AI in the entire financial sector. The proposal only encourages financial 
firms to establish (voluntarily) and apply a code of conducts on the use of AI in other financial 
services. ​Ibid. ​  
In terms of supervision the Commission proposal defines a new entity named Artificial 
Intelligence Board in order to enhance coordination among national authorities. AI deployed in 
financial services could also be subject to market supervision. The proposal gives the following 
indication: “[…] the authorities responsible for the supervision and enforcement of the financial 
services legislation, including where applicable the European Central Bank, should be designated as 
competent authorities for the purpose of supervising the implementation of this Regulation, 
including for market surveillance activities, as regards AI systems provided or used by regulated and 
supervised financial institutions.”​https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligenceethical-and-legal-requirements_en ​  Also in terms of financial supervision the EU Commission refers 
to the application of AI in the context of credit firms and their internal governance. 
BETTER FINANCE Feedback 
BETTER FINANCE strongly supports the proposal for an AI framework that allows to provide 
legal and ethical clarity on the use of Artificial Intelligence. We have raised on several occasions 
in our policy recommendations and research on Robo advisors that in order to regain the trust of 
consumers it is necessary propose a legislative framework for Artificial Intelligence and to ensure 
that the use of algorithm is fair, transparent and accountable to consumers and does not harm EU 
citizens’ fundamental rights. In addition, we have for long advised to undertake an in-depth 
fitness check of all relevant EU legislations in the insurance and financial sector in order to 
propose legislative updates where necessary. 
However, we regret that the requirements on the use of AI do not cover entirely the EU financial 
services. The provision on the voluntary creation and application of codes on the use of AI in other 
financial services (other than credit directive and credit institutions) will not be enough to 
address potential risks and consumer detriment caused by the use of AI in the retail financial 
market. Our research on Robo-advisors​https://betterfinance.eu/wp-content/uploads/Robo-Advice-Report-2020-25012021.pdf ​  shows that there are persistent issues in terms of 
reliability of the algorithms when used to propose investments to financial services users. 
Consumers very often complain about the high fees charged for the investment product, higher 
than those explained during the advice process. New fintech platforms as Robo-advisors, 
operate as an alternative to more traditional financial advisors, with comparatively lower fees 
and offering access to simpler and cheaper products such as ETFs. However, the use of algorithm 
and Automated Decision Making (ADM) may cause risks to consumers concerning e.g. the level of 
suitability of the investment advice: 
several platforms provide investment advice that seems inconsistent with the 
investor and risk profile of the mystery shoppers. 

strong discrepancy in terms of investment gains and high dispersion of asset 
allocation for the same investor profile. 
Summary box: BETTER FINANCE’ research on Robo-advice 
Robo-advice online platforms: Following four consecutive years of research on Robo-advice by BETTER FINANCE 
(link to the report), four main areas of concern stand out: (i) investor protection awareness (ii) investment 
advice (iii) disclosure and (iv) sustainable investing. 
I. 
Investor protection awareness: Our research suggests that the propensity of “retail” investors to seek 
advice and take financial action (invest) is determined by the level of financial literacy and trust in capital 
markets. These two factors act more as complements and can reduce the vulnerable position of “retail” 
savers and their perceived lack of protection. 
II. 
Investment advice: For the third time in a row, the findings our Robo-Advice report show that: 
several platforms provide investment advice that seems inconsistent with the investor and 
risk profile of the mystery shoppers. 
strong discrepancy in terms of investment gains and high dispersion of asset allocation for 
the same investor profile. This may stem from how the investor questionnaires are designed 
or how the background information of the mystery shoppers is analysed. 
▪ the recommended equity exposure ranges from 9% to 95% for exactly the same 
investor profile. 
▪ Annual returns vary from + 1.80% to + 12.8% for the “Millennial” profile, and 
from +1.60% to +7.40% for the “Baby Boomer”. 
III. 
Disclosure: the responsibility to provide clear and non-misleading information falls squarely on the 
suppliers of financial services. However, we have observed that the information provided to individual 
investors is somehow scattered across the website or even missing in certain cases: 
14 out of 17 platforms include best- and worst-case scenarios but only 10 platforms 
include past performance scenario in their investment advice. 
only 5 platforms (28%) specify that the past/future performance scenario are not 
reliable indicators of the actual performance. 
Only 33% of the platforms clearly provide a warning stating that the investment may 
lose value. 
67% of platforms clearly disclose the risk level of the portfolio in question, though 
the underlying details of what the risk level contains in practise varies greatly and 
leaves much to be desired. 
IV. 
Sustainability: Only 6 of the 18 platforms analysed in this year’s research also propose sustainable 
investing options to their clients. However, it is quite disappointing to note that none of the platforms 
ask about the sustainability preferences of their clients during the questionnaire.  
Only a few platforms ask whether the client wants to invest sustainably at the beginning 
of the questionnaire, but most of the 6 platforms in scope allow for tweaking their 
portfolio from “traditional” to “sustainable” once the investment advice is provided. 
Full research report available here 
Also, the EIOPA expert group on digital ethics published in June 2021 the report on Artificial 
Intelligence Governance Principles: Towards Ethical and Trustworthy Artificial Intelligence in the 

European Sector. ​https://www.eiopa.europa.eu/content/eiopa-publishes-report-artificial-intelligence-governanceprinciples_en ​  In the context of Robo advisors the report also underlines the need for 
consumers “to be provided with meaningful and timely information about the system’s capabilities 
and limitations, and to the extent possible, consumers should be allowed to request the intervention 
of an employee at some point of the process.” In addition, financial consumers should receive 
necessary information in order to gain a basic understanding of the algorithm that is behind the 
investment recommendations provided by the Robo advice such as the level of risk appetite, 
green preferences, and type of assets. Also, a human advice should be always recommended by 
these platforms. ​https://www.eiopa.europa.eu/content/eiopa-publishes-report-artificial-intelligence-governanceprinciples_en ​  Therefore, additional pieces of legislations on financial services should be 
included in order to provide requirements on AI in a systematic manner. In order to avoid any 
legislative incongruences, the EU Commission proposal should cover additional EU legislations 
such as Mifid II and Solvency II. The proposal should cover transparency and explainability issues 
derived by the deployment of AI in the insurance sectors and AI-automated financial advice. 
Complementary governance aspects are essential in these financial services when it comes to 
ensure good outcomes for consumers. 
The AI High Level Expert Group (HELG) has also recognised that explainability of the algorithms 
and their transparency are the most important aspects that should be required to provide trust 
and accountability of AI systems deployed in financial services. ​Ibid. ​  ​https://digital-strategy.ec.europa.eu/en/policies/expert-group-ai ​  
Better finance ​​ is a contributor of the Human-Centric Digital Manifesto for Europe, How the 
digital transformation can serve the public interest (September 2019)​https://www.beuc.eu/publications/beuc-x-2019-053-a-human-centric-digital-manifesto-for-europe.pdf ​  It is fundamental to 
ensure the human centric and fair application of Artificial Intelligence and the creation of an 
appropriate institutional framework on AI governance. Ethical codes should be developed and 
implemented for the development and the application of Algorithm and Artificial Intelligence. 
Ethical codes and principles should be at the basis for fair, non-discriminatory and non-harmful 
use of AI. Specific rules should be also developed to address the pricing problem in the insurance 
sector. The use of algorithm may generate substantial risks to consumer as discrimination or 
unfair practices. Some group of customers may be directly excluded by the algorithm being 
determined as too risky (too costly). Application of a segmentation of customers could result in 
strong differences of pricing for group of customers thus going against the fundamental rights of 
citizens that should be treated equally. Therefore, a code of conduct and AI governance 
framework should prevent unfair and discriminatory practices. 