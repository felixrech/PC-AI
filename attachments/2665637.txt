GENERAL RECOMMENDATIONS 
Artificial intelligence (AI) and machine learning (ML) enable innovation and opportunities in the creative sector 
and will have a lasting impact on the development of the visual content industries. We believe that in establishing 
a legal framework for AI and ML, it is essential to show respect for IP and privacy issues and to foster an 
ecosystem that is ethical and transparent. An ecosystem that does so can compensate human creators when 
their work in used in AI/ML systems and promote new and innovative ideas. 
Key Ask – Consider “Editorial” & “Creative” Content Differently 
Getty Images welcomes the proposed EU Artificial Intelligence Act. We believe that ensuring the authenticity of “Editorial 
Content” and empowering consumers to verify trustworthiness should be a key part of the proposal. It is important 
that not all images and videos be treated the same under the law. Only “Editorial Content” should 
be subject to Transparency obligations under Article 52(3). 
(See About Getty Images section below for explanation of Editorial Content) 
KEY CLAUSES IN EU AI ACT AND RECOMMENDATIONS 
1. Record keeping and quality management requirements for high-risk AI (Articles 12, 17, 20): Collectively 
these three Articles propose key record keeping requirements that Providers of high-risk AI systems must 
comply with.  Per Article 12, “logging capabilities shall conform to recognised standards or common specifications”, 
“ensure a level of traceability of the AI system’s functioning throughout its lifecycle…”, “enable the monitoring of the 
operation of the high-risk AI system…”, and “facilitate the post-market monitoring…”. 
Recommendation 1 – Even for AI uses that might not be classed as “high-risk” under the AI Act, 
Getty Images encourages transparent record-keeping that clearly tracks what copyrighted 
content is used in ML and AI development and any resulting synthetically produced creative 
content. Open industry standards and tools that can be used to identify and verify “authentic” 
editorial content, should be promoted. Getty Images is a member of the Content Authenticity 
Initiative (CAI) which is working to develop such standards and we encourage legislation that 
would promote and incentivize adoption of transparent record-keeping. 
1 CAI is building systems to provide provenance for digital media, giving creators tools to express objective reality 
and empowering consumers to evaluate whether what they are seeing is trustworthy. It is a state-of-the-art 
industry-led initiative which seeks to address content authenticity at scale. CAI is focused on cross-industry 
participation, collaborating with a wide set of representatives from software, publishing, and social media 
companies, human rights organizations, and academic researchers. See https://contentauthenticity.org/ 

2. Record Transparency obligations for certain AI systems (Article 52): The obligations proposed in Article 52 
are well intentioned and are an important tool to promote ethical behaviour and protect against 
disinformation. Per the proposed text, “Providers shall ensure that AI systems intended to interact with natural 
persons must ensure that the systems are designed and developed in such a way that natural persons are informed 
that they are interacting with an AI system...” [Article 52(1)], “Users of an emotion recognition system or a biometric 
categorisation system shall inform of the operation of the system…”[Article 52(2)] and “Users of an AI system that 
generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, persons, 
objects, places or other entities or events and would falsely appear to a person to be authentic or truthful (‘deep fake’), 
shall disclose that the content has been artificially generated or manipulated.” [Article 52(3)] 
Recommendation 2 – Although Getty Images fully supports transparency requirements intended 
to reduce the risk associated with “deep fakes”, we are concerned that the proposed language 
in Article 52(3) may be overly broad and poses a risk of unnecessarily chilling innovative 
creative applications of AI technologies. The proposal should include a narrower approach to 
consumer disclosures which is confined to modification or emulation of Editorial Content, 
focused on intent to deceive and situations which may lead to particularised harm to natural 
persons. The current wording is vague and may inadvertently include – or at minimum increase 
the risk of litigation to – legitimate creative synthetic content which creates no risk of harm or 
injury to natural persons. 
Recommendation 3 – Clarify that disclosure requirements under Article 52(3) can be achieved 
by adhering to metadata standards. For example, the Content Authenticity Initiative (CAI) 
could be one key tool to help facilitate and realise mandatory disclosures for Editorial Content. 
3. Codes of conduct (Article 69): Codes of conduct intended to foster the voluntary applications to AI systems other 
than high-risk AI will be encouraged. 
Recommendation 4 – Getty Images supports this provision and the creation of codes of conduct 
by individual providers and industry associations. This will help to ensure that requirements 
for non-high-risk AI applications are informed by a wide range of stakeholders and can be 
systematically updated. We would like to see the above mentioned principles of record keeping 
and transparency be reflected in codes of content relevant to AI that creates or modifies visual 
content or uses visual content as input data. 
4. High-risk uses (Annex III): High-risk AU systems referred to in Article 6(2) 
Recommendation 5 – Getty Images supports classifying AI systems that significantly encroach 
on any of the fundamental rights enshrined under the Charter of Fundamental Rights of the EU 
as high-risk. In connection with the right to enjoyments of one’s property described in Art 17 
of the Charter of Fundamental Rights, AI systems that, without authorization, use copyrighted 
work as training data and enable the creation of synthetic work that is capable of being used a 
market substitute for the underlying data, should be viewed as a significant encroachment on 
fundamental rights and be considered high-risk. 
Recommendation 6 – Although Getty Images supports including “biometric identification and 
categorisation of natural persons” in Annex III, the proposed language is overly broad and may 
result in imposing unnecessary regulation on AI systems that use biometric identification for 
non high-risk activities such as organizing libraries of non-private stock content. If the 
appropriate consent to use biometric data of a natural person has been obtained prior to use is 
an AI system, that system should not be considered high-risk. In addition, any AI system that 
uses of anonymized biometric data that cannot be used to personally identify a natural person 
should not be considered high-risk. 

ABOUT GETTY IMAGES 
Getty Images is a leading source for visual content across the world. We have a long history of managing high 
quality content, and our business model encourages the creation of artistic work by providing a system for lawful 
licensing and the monetization of copyright protected content. Our vast and unmatched database includes two 
main categories of content: “creative” and “editorial” content. The “creative” category includes model and 
property released content that can be used for a wide variety of commercial uses; whereas our “editorial” 
category includes “news/editorial” coverage that meets high standards of editorial integrity and is prohibited 
from being altered in a compromising way. Please see the Getty Images Editorial Standards policy for further 
details. ​https://www.gettyimages.co.uk/company/editorial-policy ​  As technologies like AI and ML enable both the “creative” and “editorial” disciplines to evolve, we are 
committed to protecting the interests of our community of over 320,000 contributors through copyright 
licensing, as well as respecting the privacy and intellectual property rights of third parties. 
If you have any questions or if we can provide further information, please do not hesitate to contact Jonathan 
Lockwood, Vice President, Corporate Counsel, Getty Images at jonathan.lockwood@gettyimages.com. 