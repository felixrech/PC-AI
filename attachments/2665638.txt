A Proportional Regulation for AI Innovation & Application 
WEC-Europe’s response to the proposed EU Artificial Intelligence Act 
In this paper World Employment Confederation – Europe (WEC-Europe), the European trade association for Private 
Employment Services, provides its input on the Proposal for a regulation laying down harmonised rules on Artificial 
Intelligence (hereafter: the AI Act). 
Labour market efficiency, inclusiveness, and support in times of economic disruption 
Members of WEC-Europe provide private employment services including recruitment, temporary agency work and career 
guidance. Through these services, they contribute to (1.) efficient matching of labour market demand and supply, (2.) 
labour market inclusivity and (3.) a stepping-stone to quality and sustainable employment. In this time of increased 
economic uncertainty and the subsequent labour market dynamic, private employment services are a crucial part of the 
European ecosystem for labour market support for business and workers. Of course, like any industry, the services are 
evermore enhanced and improved by new (digital) technologies, including Artificial Intelligence (hereafter: AI). 
Private Employment Services get workers ready for an AI enhanced workplace 
Annually, private employment services touch the lives of 11,5 million workers as they transition on(to) the labour market. In 
this they play a key role to prepare and re-/upskill workers and job seekers for new workplaces that require new skills, 
competences, and ways of working. This is exactly the difference half a million labour markets consultants and recruiters in 
Main points: 
- WEC-Europe welcomes the creation of a regulatory framework of AI that will improve predictability and 
a level playing field for the application of AI. 
- Following its Code of Conduct, WEC-Europe is dedicated to improving labour market inclusiveness and 
fighting (un)conscious human bias from the recruitment process, irrespective of the software used in its 
services. 
- WEC-Europe emphasizes that AI is a tool that can be programmed to identify these (un)conscious 
human biases and minimize them in recruitment procedures. As such, it welcomes the opportunities in 
the proposal to do so. It highlights that in contrast to this ambition, ‘users’ are unable to do so in the 
proposal. This prevents users ability to countercheck providers and/or enhance de-biasing 
methodologies. Moreover, this shapes market dependencies that will not drive innovation and 
diversity. 
- WEC-Europe warns that the current definitions in the proposal of high-risk AI as well as recruitment is 
so broad it covers all software used in recruitment (and employment), including those that do not 
involve any automated decision-making or machine-learning that impact the risk the proposal seeks to 
mitigate. As such, the proposal’s definitions diminish the overall high-risk approach. 
- WEC-Europe brings forward that this broad definition and the administrative requirements of the 
proposal will benefit large providers that are able to meet these. Thereby raising issues of AI market 
concentration, competition, innovation, and adoption. 
- WEC-Europe welcomes the decentral oversight mechanisms but emphasizes the need for clarity for 
business on the competent authority. 

Europe seek to make. As such, the industry is deeply vested and committed to ensure European workers and employers 
have access to the skills needed to succeed in a workplace and labour market that is induced with applications of AI. 
WEC-Europe’s dedication to fight labour market discrimination 
WEC-Europe is dedicated to ensuring the provision of private employment services – irrespective of the (digital) tools 
deployed – contributes to diverse and inclusive labour markets in Europe and beyond. The industry’s track record and Code 
of Conduct tell this story: 
1. 
Through private employment services a vast and diverse workforce is recruited and employed. Women, youth, and 
people with a background of long-term unemployment, disability and/or migration are heavily represented in the 
group of workers private employment services engage with, especially in comparison to other sectors. 
2. 
On the European and national level, as complement to governmental initiatives, industry bodies have put in place a 
vast array of standards, audits, staff training and remedies to fight labour market discrimination through private 
employment services. 
3. 
Finally, the industry has a vast track record of partnering with public employment services in the EU Member States to 
support the employment and labour market participation of the various underrepresented groups that are identified 
for specific labour market support on the European, national, regional, and local level. 
To continue to play and improve these roles, WEC-Europe brings forward the following inputs for the legislative process for 
the adoption of an AI Act in Europe: 
WEC-Europe welcomes a clear framework for the application of AI 
Having legal certainty on the regulatory framework for the application of AI in recruitment is an important element. It 
holds the potential to provide predictability and level playing field that is needed for the development and application 
of quality and responsible applications on AI in Europe. It is from that perspective WEC-Europe welcomes the proposal 
for such a framework.  
WEC-Europe deems the proposed definition of high-risk AI in recruitment vastly too broad 
The definition of AI the Commission proposed is too broad, creates legal ambiguity and does not align with the riskbased approach. It incorporates all pieces of software and not the technical functioning that the proposal seeks to 
regulate. Neither does the definition clearly add a dimension to what is already covered in the GDPR, thus further 
increasing legal uncertainty. 
Alternatively, we propose to specifically target those dimensions of AI functioning that could actually lead to the risks 
identified. This should exclude ‘traditional’ software that do not have any risky automated machine learning or 
decision-making in them. 
To this purpose we put forward the following suggestions: 
Art 3 sub 1: 
‘artificial intelligence system’ (AI system) means software whose primary purpose and function is driven by the use of 
that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of 
human-defined objectives, generate outputs such as content, predictions, recommendations, or decisions influencing 
the environments they interact with .’ 
Annex III pt 4. 
We suggest distinguishing to different forms of AI applications in recruitment: 
Low risk: 
Applications that support marketing/outreach for job openings; 

The creation of job descriptions and vacancies to improve their accessibility to more jobseekers; 
Applications that check on hard and objective criteria (such as availability, legal age, work permits, willingness to 
commute etc.) 
Systems that support the scheduling of job interviews 
Systems that do not generate outputs such as content, predictions, recommendations, or decisions within 
recruitment, selection, promotion, or termination outcomes without human involvement or oversight.  
Applications used to parse unstructured CV's into structured data. 
High risk 
Systems that process biometric data 
Systems that include autonomous decision-making on (receiving) job opportunities, promotions, interviews or 
otherwise beneficial opportunities based on sensitive personal data 
AI systems that monitor performance and behaviour that include sensitive personal data 
WEC-Europe emphasizes that AI is a tool that can both minimise and amplify conscious and unconscious 
human biases in recruitment and employment. 
In this respect, WEC-Europe finds that the current administrative requirements are disproportionately balanced 
towards the latter, thus preventing the easy application of AI that minimizes human biases. Further administrative 
intervention, requirements and audits will tip the balance further in the wrong direction for labour market 
inclusiveness. In this respect we strongly emphasize to maintain the self-assessment for high-risk AI applications in 
recruitment and employment. 
WEC-Europe welcomes the high-risk approach of the proposed AI Act 
WEC-Europe concurs that specific AI applications in recruitment hold risks for labour market inclusivity and 
participation and recognizes that human oversight, security, transparency, record-keeping, and data-governance are 
key elements when private and public employment services apply them. 
WEC-Europe welcomes the diversified approach to oversight, integrating existing public mechanisms, 
third-party certification, and self-regulatory mechanisms such as self-assessment and codes of conduct. 
The application and impact of AI differs from sector to sector. As such, social partners, governmental auditors, and 
policy makers in these respective sectors need to be fully involved in the specific sectoral applications. This prevents 
implementation that is insufficiently coordinated with sectoral public and private practitioners, to the detriment of 
sectoral functioning, existing oversight, or social dialogue. 
The legislative process for a European AI Act is not the right policy platform or tool for regulating 
employment relations. In this context, WEC-Europe notes that Annex III pt. 4 significantly bypasses the 
legal realities on differences between (the creation, assessment, and termination of) a commercial (B2B 
or B2C) contract and an employment contract. 
To prevent significant legal inconsistencies and uncertainty, we advise to separate the two types of contracts 
(employment contracts and business contracts with self-employed service providers) and assess risks and regulatory 
intervention separately. In this respect WEC-Europe strongly emphasizes that the application (and enforcement) of an 
appropriate and clear worker classification regime is the most important gateway to employee protections, including 
against automated decision-making on their employment contract (including those protections provided in the GDPR). 
Worker status classification would especially be relevant to those gigs in location-based platforms providing delivery or 
personal mobility services. 
WEC-Europe welcomes the technical opportunities for AI developers to identify, minimise and fight 
conscious and unconscious human (labour market) biases and discrimination. 

The opportunities for AI sandboxing are welcomed and Article 10 sub 5 of the proposal is adequately worded to serve 
this purpose. We advise to maintain this language. 
Still, this section is limited to ‘Providers’ only. While ‘Users’ need an independent opportunity to countercheck, 
scrutinize and enhance the de-biasing methodology and/or data sets of the provider. Not having this opportunity 
creates a unhealthy dependency in an already centralised market. As such, ‘Users’ need to be able to access and build 
their own debiasing dataset. Indeed, the data-set Providers use (for example from other users of its service) potentially 
insufficiently align with the population of another user. For the sake of better de-biasing and prevent the further 
centralisation of market players, we call on the expansion of Article 10 sub 5 to ‘Users’. This will allow and incentivize 
‘Users’ to innovate in the development of unbiased datasets by themselves. 
WEC-Europe notes that the administrative requirements involved identifying compliance to articles 8 to 
16 will be a significant hurdle to innovation in AI. 
They raise questions on proportionality vis-à-vis the efficiency and inclusiveness gains of AI applications. In this 
respect, we anticipate this to be a significant threshold for the development and adoption of AI in Europe. As such, we 
advise EU legislators a less prescriptive approach that allows for flexibility for companies to implement the 
requirements addressed in the aforementioned articles. 
Moreover, the extent of these requirements further raises the competitive advantage of large technology providers. 
Potentially raising issues on competition, market entry and innovation. 
Decentral oversight should not lead to regulatory uncertainty or diverse audit practices 
The final AI Act would need to ensure market operators gain unambiguous clarity on the national authority competent 
on the application of the AI Act. 
Business involvement in governance needs to be secured and mandatory at all levels. 
The proposal envisages an extensive infrastructure of exchanges and collaboration amongst (new?) national and 
(new?) European bodies. WEC-Europe emphasizes the importance of business involvement in all these bodies on all 
levels. Those bodies, collaborations and infrastructures that oversee and engage on the use of AI in recruitment should 
structurally incorporate the voice of private employment services. As such, we advise the inclusion of appropriate 
business consultation is mandatory for the policymaking of the various institutions involved in the governance, 
coordination, and enforcement of oversight of AI in the EU, including the ‘European AI Board’ and revising the list of 
high-risk applications. This explicitly should include a platform for sectoral involvement in these consultations when 
the respective sector is discussed. Finally, in addition to this, the proposal would require a flanking policy framework 
on how the EU will ensure oversight bodies can be properly staffed AI auditors. 