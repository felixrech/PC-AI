6 August 2021
The Hague, NL

Foreword
On 21 April 2021, the European Commission published a proposal for “Regulation of the European
Parliament and of the Council laying down harmonised rules on Artificial Intelligence (Artificial
Intelligence Act) and amending certain Union legislative acts” and a "Coordinated Plan on Artificial
Intelligence 2021 Review". This document is CLAIRE's official response to the two closely related
documents, which form the core of the European AI strategy. (The choice of a unified response to both
documents was deliberate and is explained in more detail in the introduction.) It was written by a group
of AI experts from CLAIRE, assembled based on their expertise and a set of diversity criteria, including
geographic diversity and diversity across key areas of AI. This group was comprised of Thomas Bäck
(Universiteit Leiden, NL and divis intelligent solutions GmbH, DE), Ricardo Chavarriaga (ZHAW, CH),
Emanuela Girardi (Pop AI, IT), Fredrik Heintz (Linköping University, SE), Holger Hoos (Universiteit Leiden,
NL), Jeroen van den Hoven (TU Delft, NL), Morten Irgens (Oslo Metropolitan University and Kristiania
University College, NO), Ana Paiva (University of Lisbon, PT), Philipp Slusallek (DFKI and Saarland
University, DE), Marlies Thönnissen (DFKI, DE and Universiteit Leiden, NL), and Josef Urban (Czech
Technical University, CZ).
As part of its mission, CLAIRE supports the European Commission in consulting broadly and in depth on
all elements of the European AI strategy, ensuring that the AI research and innovation community,
which plays a key role in ensuring the success of "AI made in Europe", is included prominently in these
consultations. It is of crucial importance to take the time that is needed to revise and refine the
proposed regulation such that it benefits European society, while simultaneously proceeding swiftly
with the investments into European AI research and innovation capabilities that are required to
maintain global competitiveness in AI-related technologies and applications. CLAIRE welcomes the
opportunity to provide feedback to the Commission’s proposals.
The views and recommendations expressed in this document are based on the CLAIRE vision (see
https://claire-ai.org/wp-content/uploads/2019/10/CLAIRE-vision.pdf) that is supported by the 413
groups and organisations with over 22 000 employees, that form the CLAIRE Research Network, the
3780 individual supporters of the CLAIRE vision, and the governments of nine European Member States
that have officially confirmed their support for the CLAIRE vision (Belgium, Czech Republic, Finland,
Greece, Italy, Luxembourg, Netherlands, Slovak Republic, and Spain).
This response also reflects the results of a comprehensive survey conducted by CLAIRE among its
members, supporters and within the European AI community at large, between May and July 2021 (a
complete summary of the results of this survey is provided in the Appendix), as well as discussions
during a number of meetings and public events organised by CLAIRE and its member organisations.
In light of the complexity of the material and of the European AI ecosystem, this document is an initial
response to the European Commission's latest plans. It complements CLAIRE’s earlier response to the
European Commission's 2020 white paper on AI. While many of the ten key recommendations made
there have been (at least partially) addressed, those recommendations remain highly relevant.
2

Summary of concerns and recommendations
Concern 1: The proposed regulation "proposes a single future-proof definition of AI" (Section 1.1);
however, this definition is deeply flawed.
Concern 2: The uncertainty resulting from problematic definitions is likely to have detrimental
consequences for the development, uptake and use of AI by European companies - especially by SMEs
and startups.
Concern 3: The notion of quality of data (and data sets) remains unclear. The proposed regulation puts
forward general requirements for quality of data, but does not establish suitable criteria for assessing
data quality. Without such criteria, the requirements for data quality remain ineffective.
Concern 4: There is a lack of focus on the proper intended behaviour of AI systems. The responsibility
and accountability for ensuring proper intended behaviour - including the use of suitable input data in
design, experimentation, testing and operation - is not clearly defined.
Concern 5: The proposed regulation is vague on citizens' rights and has important exceptions that
negatively impact these rights.
Concern 6: The proposed regulation will erode European competitiveness in the area of AI.
Concern 7: Even if European regulation succeeds in setting global standards, most development and
research may end up taking place - or be directed from - elsewhere, and generate benefits (especially
economic benefits) mostly outside of Europe. This will erode European sovereignty in the area of AI
technology.
Concern 8: Funding for AI research and innovation through Horizon Europe and the Digital Europe
Programme is insufficient and distributed in ways that leave out important parts of the AI community. It
thus fails to mobilise and leverage key European expertise in AI and risks further increasing the
fragmentation of the European AI ecosystem.
Concern 9: In the absence of effective mechanisms and incentives, the cooperation required for
success at the European (rather than merely the member state) level will not be achieved.
Concern 10: Europe is losing the competition for AI talent with the US and China. Europe critically
needs to stop the AI brain drain at all levels by rapidly introducing competitive conditions for attracting
and retaining AI talent.
Concern 11: A distributed version of the European lighthouse for AI will be ineffective and
inconsequential, and the fact that the current plans are vague and confused about the concept has
already started to erode what could be a major success story for European AI, a powerful symbol and
nexus for the ambition of "AI made in Europe", and a global attractor of talent.
Concern 12: The actions foreseen under the plan are scattered. None of them appears to be likely to
substantially move the needle on AI research or innovation in the global context or to lead to
game-changing AI capabilities. There is serious risk of increasing fragmentation and, as a result,
diminished global impact of the European AI ecosystem under this plan.
3

Recommendation 1: Any definition of AI used by the European Commission should be accepted by a
broad majority of the international AI community.
Recommendation 2: Rather than relying on a definition of AI technologies, regulatory restrictions should
be defined based on the classes of use cases enabled by AI, and by functional characteristics of the
systems used in these cases. To the largest possible extent, AI regulation should be technology-neutral.
Recommendation 3: The proposed regulation needs to be aligned with existing regulations, notably with
the GDPR, in terms of the requirements for use of high-quality data.
Recommendation 4: The proposed regulation and coordinated plan should focus on ensuring the
proper intended behaviour of AI systems in high-risk applications and thus embrace the notion of trusted
AI.
Recommendation 5: Make sure that, a priori, government uses of AI technologies fall under the same
restrictions as all other uses, and allow only minimal exemptions with suitable oversight.
Recommendation 6: Focus on investment that can offset the burden created by any AI regulation.
Improve the proposed regulation by clarifying definitions and removing uncertainties. Make certification
easy and cost-effective.
Recommendation 7: To achieve global impact, the investment into the European AI research and
innovation ecosystem needs to be much more substantial, has to be made in a way that leverages
broader parts of the European AI research ecosystem, and cannot be solely targeted to a set of weakly
coordinated research networks.
Recommendation 8: Create suitable mechanisms for coordination at the EU level. This includes
coordination of the networks of centres of excellence in AI, of the EDIHs, of at least a sizable part of RRF
spending on AI and of other key components of the plan. The coordinated plan on AI needs to become
more coordinated.
Recommendation 9: Implement key parts of the coordinated plan through longer-term,
mission-oriented investments, including 7- and 10-year funding for research networks.
Recommendation 10: Create and rapidly deploy effective, light-weight, EU-wide mechanisms for
attracting and retaining talent, such as an ERC programme in AI.
Recommendation 11: Complement the research funding programmes by establishing a large
computational infrastructure for AI in the EU. Mandate that companies that use EU data must store such
data in the EU, train their AI models in the EU, and run a substantial share of their AI research and
development in the EU.
Recommendation 12: The European Commission, together with the Member States, should establish a
small number of large-scale research centres in different geographical regions of Europe, dedicated to
specific application areas of AI, following broadly the challenges laid out in Chapters 11-17 of the
coordinated plan, and funded at an appropriate level, jointly by the European Commission, the Member
States and, in some cases, possibly industry.
Recommendation 13: Establish a central, physical European lighthouse centre for AI, in order to bring
together the AI ecosystem and to create global momentum that can help Europe reach the ambitions
stated in the coordinated plan.
Recommendation 14: Simpler is better. The coordinated plan should be revised, involving the highest
level of the European Commission, to focus on a small number of impactful initiatives, each backed by
resources that allow the European AI community to achieve global impact and leadership in key areas of
AI research, innovation and applications.
4

Table of Contents
Foreword
2
1 Introduction
6
2 Proposed Regulation
8
3 Coordinated Plan on AI
18
4 Conclusions and Outlook
31
Appendix: Survey results
33
5

1 Introduction
Europe is one of the world's three economic super regions and is at the forefront of many areas of
science and engineering. Some of the world’s best companies and universities are located in Europe.
However, Europe's ability to turn this position into societal or commercial value trails other important
global regions, notably North America and Southeast Asia. Europe lags behind its main rivals in the
global, modern, digital economy.
Information technologies in general and AI technologies specifically are rapidly emerging as key
drivers for all economic sectors, as well as for future progress in science and engineering. Failure
to develop and maintain world-class capabilities in AI research and innovation will lead to a loss
of European technological sovereignty and resulting negative impact on the economy, as well as
loss of opportunities for use of AI for the benefit of society. The European Commission’s focus on
strengthening Europe's digital capabilities is therefore important and necessary. The Commission
correctly frames this as a question of European sovereignty.
It is said that America innovates, China implements and Europe regulates. There is some truth in this,
and we see clearly a difference in philosophy between those three regions, specifically with respect to
AI research, innovation and applications. This is evident, for example, in last year’s guidance for the
regulation of AI applications from the US White House , which established a framework for future
1
legislation based on a hands-off approach.
The Commission’s approach towards increased European innovation, research and competitiveness is
broad, along several axes. These include increased funding to European research and innovation in AI,
a new Coordinated Plan with the Member States, new rules on Machinery, a comprehensive data
strategy, GDPR, and a regulatory framework on AI. The Coordinated Plan outlines the necessary policy
changes and investment in the Member States, and the rules on machinery intend to increase the
safety of and trust in new and more versatile products, and the legal framework sets out an EU-level
framework for regulating AI that both protects the public and promotes industry innovation—not to
trade off one against the other.
CLAIRE supports the European Commission's drive towards a balance between regulation and
innovation,
where
citizens’ rights are well protected while facilitating investment and
innovation.
However, we find that the sum of the initiatives, as they are currently planned,
does not achieve this balance.
1 https://www.whitehouse.gov/wp-content/uploads/2020/11/M-21-06.pdf
6

There are five major issues:
1.
The coordinated plan is lacking key mechanisms for ensuring global relevance and leadership
of "AI made in Europe". It encompasses a vast array of instruments and mechanisms, each of
which is rather modestly funded in relation to the ambitious goals of the plan. The plan lacks
coordination between these mechanisms. It also lacks large-scale signature initiatives that
can address key challenges within the fragmented European AI ecosystem.
2.
The proposed regulation is too broad and vague to effectively boost the impactful
development and use of "AI made in Europe", and to strengthen, rather than weaken, the
global competitiveness of the EU economy.
3.
The proposed regulation does not achieve a reasonable balance between cost, investments
and effects for companies, governments and society. It places a regulatory burden on the
European economy that is particularly challenging for SMEs, startups and micro-enterprises,
while other elements of the coordinate plans do not provide effective instruments to offset
this burden.
4.
The proposed regulation is vague on implications to citizens' rights and provides exceptions
in government uses of AI that are likely to negatively impact citizens.
5.
The proposed regulation shows a problematic focus on a particular (and still flawed) notion
of AI technologies. We believe that regulation of technology is important, but that the focus
should be on the uses and applications of technology, rather than on a specific set of
technologies that are being used. AI technology evolves, and even experts disagree which
technologies fall within the scope of AI. Regulation aimed at ensuring the responsible use of
AI should therefore be as technology-neutral as possible.
Overall, CLAIRE believes the intention underlying the proposed regulation is good, but that it does not
achieve the intended upsides, while creating downsides of serious concern. Likewise, the coordinated
plan, of which the proposed regulation forms an integral part, is pursuing worthwhile and achievable
goals, but the level of funding and the array of mechanisms currently foreseen is insufficient for
realising the ambition of European leadership in key areas and applications of AI and carries major
risks of Europe falling further behind the fast-moving global leaders.
In the remainder of this document, we first comment on key aspects of the proposed regulation
(Section 2), then discuss the revised version of the coordinated action plan (Section 3), and finally
provide some high-level conclusions and a brief outlook on CLAIRE's future engagement with the
European AI strategy (Section 4). We deliberately address the proposed regulation as well as the
coordinated plan, since the former is a key element of the latter (see Chapter 9 of the coordinated
plan), and regulation related to AI interacts with other elements of the European AI strategy as outlined
in the coordinated plan.
7

2 Proposed Regulation
Unrestricted, "all-out" uses of AI can achieve levels of automation, delegation and autonomy that bring
large short-term economic benefits. Some of these benefits will be lessened by regulation of AI. Still,
CLAIRE agrees with the European Commission that regulation of the use of AI, especially in
high-risk applications, is worthwhile, if the regulation achieves reasonable calibration between
short-term economic cost and long-term benefits to society, based on a broad notion of social
welfare that reflects core European values shared with many societies around the world.
The proposed regulation pursues several objectives, including driving innovation and mitigating risks,
promoting the ethical application of AI, instilling European values, improving transparency, fostering
collaboration, creating a level playing field between EU Member States, and protecting the rights of EU
citizens. Overall, CLAIRE agrees with these high-level objectives.
In our survey, we found strong support for the risk-based approach underlying the proposed regulation
(see Appendix, Question 1) and for the regulation overall. However, further analysis and discussions
revealed a number of serious concerns, which we explain in the following, along with
recommendations for addressing these concerns. In this, we focus on the most obvious, high-level
concerns.
The definition of AI remains problematic
By definition, AI systems are modelled on human capabilities (e.g., in learning, reasoning, decision
making or problem solving), and often reflect human weaknesses and strengths. Holding AI systems to
an absolute standard, where an equivalent human process is viewed under a reasonableness standard
may lead to legal inconsistencies. Of course, as is the case with other technology, AI systems may in
some cases surpass human capabilities, and part of their value is derived from that fact.
This becomes important when contrasting current AI technology with notions of AI that achieve
broad-spectrum human-level intelligence, which are often referred to as artificial general intelligence
(AGI). Many experts doubt that AGI can be achieved in the foreseeable future, and many have serious
concerns about the consequences of creating AGI. The proposed regulation is not explicit on the fact
that it addresses systems using AI technologies rather than artificial intelligence in the sense of AGI.
Especially in combination with the 'AI hype' that citizens, companies and other organisations have been
exposed to recently, this will likely cause confusion. It is important to state explicitly that the
8

proposed regulation applies to AI technologies rather than broad-spectrum human-level
intelligence. It is of crucial importance for everyone involved in scrutinising, revising and
enacting the proposed regulation to be keenly aware of the strengths and limitations of AI
systems available now and in the near future. A clearly separated debate about AGI might be
warranted at some point. In this document, we use the term 'AI' solely to refer to AI technologies
available now and in the near future.
There is no generally accepted definition of which technologies, capabilities and problems fall
within the scope of AI. It is natural that the European AI strategy, including the coordinated plan and
the proposed regulation, should define what falls under the label of 'AI' and 'AI technologies'. The field
of AI is evolving quickly, and AI techniques are difficult to separate from other advanced
computing techniques to the point where experts disagree about what should and should not be
labelled as AI. Of course, a legal structure can attempt to circumvent this issue by including a
definition.
Concern 1:
The proposed regulation "proposes a single future-proof definition of AI" (Section 1.1); however,
this definition is deeply flawed.
The definition given in Annex I of the proposed regulation is neither broad enough to capture standard
definitions used elsewhere, nor sufficiently narrow to avoid capturing digital technologies clearly
outside the scope of AI.
For example, Annex I (c) of the proposed regulation includes "statistical approaches, Bayesian
estimation, search and optimization methods", which are indeed used widely in AI systems but, in their
full breadth, are generally not considered AI techniques (a simple example for this is linear regression;
further examples include widely used operations research methods used in logistics and supply chain
optimisation). Likewise, Annex I (b) includes logic-based approaches; in their full breadth, these include
logic gates and circuits, which form the basis of standard computer hardware, as well as programming
constructs based on logic, which form the basis of standard computer software; therefore, the
definition can be easily read as including all standard computer hard- and software, which is misaligned
with all definitions of AI used by AI experts and organisations.
At the same time, Annex II misses a broad range of techniques widely used in important areas of AI
such as multi-agent systems. Furthermore, Article 3 (1) only mentions software, with the consequence
that the regulation would exempt hardware-based systems with the same functionality; this issue is
complicated by the fact that the boundary between hard- and software in modern computer systems is
rather imprecise (see, e.g., field-programmable gate arrays (FPGAs)).
In Key Recommendation 3 of its response to the 2020 white paper on AI, CLAIRE has called on the
European Commission to "adopt a definition of AI that captures what distinguishes AI approaches
from other kinds of advanced computation: they exhibit key aspects of behaviour considered as
intelligent in humans. With a non-standard definition of AI, there is a risk that support as well as
regulation are misaligned with what is commonly understood to constitute AI technology." While
the original definition that prompted this recommendation was even more problematic, the definition
9

now embraced by the European Commission is still seriously flawed and urgently requires revision.
This is not just important for the proposed regulation, but also for the scoping and targeting of
investments into the European AI ecosystem. Based on a flawed notion of what AI is, it is
impossible to effectively promote and support its safe and effective use for the benefit of
European citizens.
Unfortunately, not only the details of the definition adopted in the proposed regulation, but the
overall construction of the definition is flawed. As per paragraph 6 and Article 3 (1), the definition is
based on a list of functional characteristics of AI systems and a list of technologies that realise these
characteristics. Both lists are, and will likely remain, incomplete and overreaching, contested and
inconsistent. There is something inherently risky in building a legal structure on top of an unclear,
inconsistent, incomplete, foreign or unaccepted (or all of the above) understanding of what it sets out
to regulate.
Recommendation 1:
Any definition of AI used by the European Commission should be accepted by a broad majority
of the international AI community.
One such definition can be found on p. 6 of CLAIRE's white paper response:
What distinguishes AI approaches from other kinds of computation is that they exhibit key aspects
of behaviour considered as intelligent in humans, and thus enable fundamentally new levels of
automation and delegation. AI thus encompasses algorithms and systems that can replicate,
support or surpass human perceptual, linguistic and reasoning processes; learn, draw conclusions
and make predictions based on large or small quantities of data; replicate or enhance human
perception; support humans in diagnosis, planning, scheduling, resource allocation and decision
making; and cooperate physically and intellectually with humans and other AI systems.
The issues surrounding the definition of AI and the reliance of the proposed regulation on the
definition will create unwanted effects. For example, the focus on an explicitly defined set of
technologies means that the regulation can be circumvented by avoiding a technical solution that is
classified as AI. This could easily lead to a situation where the AI research community, especially as it
operates within or in collaboration with companies, seeks to have newly developed methods not
labelled AI, in order to avoid it from becoming subjected to the legislation.
Definitions are one of the main sources of uncertainty in the proposal, either due to their
vagueness or their absence (e.g., for terms such as 'bias'). The vagueness of several provisions in the
proposed regulation, and the use of definitions that are misaligned with common uses of terms (or
definitions likely to be used in other jurisdictions), will give rise to different interpretations by
authorities and market operators and, therefore, create legal uncertainty and hinder compliance with
the regulation.
10

Concern 2:
The uncertainty resulting from problematic definitions is likely to have detrimental
consequences for the development, uptake and use of AI by European companies - especially by
SMEs and startups.
CLAIRE believes that AI is best regulated based on the concrete use of technology rather than
based on specific techniques being used. One of the strengths of the proposed regulation is its
adoption of a risk-based approach. However, this approach is weakened by the focus on specific
technologies rather than their use. For example, it is unclear why the uses prohibited under Article 5
should depend in any way on the specific technologies being used.
Recommendation 2:
Rather than relying on a definition of AI technologies, regulatory restrictions should be defined
based on the classes of use cases enabled by AI, and by functional characteristics of the systems
used in these cases. To the largest possible extent, AI regulation should be technology-neutral.
By shifting the focus from the use of certain technologies in specific application areas to use
cases enabled by progress in AI (and other technologies), the proposed regulation can become
clearer, more effective and less contested. However, some legacy systems that are currently not
considered AI and do not fall under the current definition of AI according to Article 3 would then fall
within the scope of the regulation and may have to be certified and monitored; such systems are used,
e.g., in the financial and manufacturing sectors.
Another advantage of taking a more technology-neutral approach would arise in connection
with academic freedom. Paragraph 16 (p. 22) states: "Research for legitimate purposes in relation to
such AI systems should not be stifled by the prohibition, if such research does not amount to use of the
AI system in human-machine relations that exposes natural persons to harm and such research is
carried out in accordance with recognized ethical standards for scientific research." It would seem
simpler and clearer to refer only to accepted ethical standards in the context of research on high-risk or
prohibited AI applications.
The data regulation is confusing
CLAIRE welcomes the focus in the proposed regulation on high-quality data for AI (see, e.g., paragraph
44), as well as the reference to the coming Data Governance Act. However, the notion of data quality
used throughout the text is unclear. Furthermore, there appears to be a misunderstanding that data
quality matters mostly for training (statistical) models using machine learning techniques, where in
reality, not all machine learning approaches train models, and the operation of many types of AI
systems that do not use models are also affected by the quality of the data encountered before and
after deployment. Furthermore, it is insufficient to only focus on the input data (see discussion below
on system behaviour).
11

Concern 3:
The notion of quality of data (and data sets) remains unclear. The proposed regulation puts
forward general requirements for quality of data, but does not establish suitable criteria for
assessing data quality. Without such criteria, the requirements for data quality remain
ineffective.
The proposed regulation also includes impossible requirements regarding data quality. Specifically,
Article 10 (3) states that data should be "free of errors and complete". At face value, this is possible
only in highly specific and largely theoretical cases and next to impossible to achieve in practice.
Regarding the requirement of data being error-free, it is often not clear what is correct and what is an
error, and what was correct at one point in time can be considered incorrect later (examples abound in
medical diagnosis). Instead, the requirement should be a “best effort” requirement, taking into account
the state of the art and industry practices.
Unfortunately, even with a best effort requirement, it remains unclear how the proposed regulation
and the GDPR can be reconciled: the proposed regulation requires the use of data of the highest
possible quality (Paragraph 44) , while the GDPR advocates to use data that may be of low
quality.
The proposed regulation also requires that a system does not discriminate. In many cases, this is
difficult to verify, unless sensitive information about the users has been collected, based on which
outcomes can be compared. This is difficult to achieve under the GDPR, as it makes it hard to collect
suitable personal data of the required high quality. Thus, in many cases, companies will need to use
lower-quality data. That also means the "right to be forgotten" under the GDPR implies that data quality
can deteriorate over time. Since under the GDPR, a person can demand that their data be deleted, or
by not giving consent, the data will by definition be incomplete or biased in many circumstances, as
that right might be used by specific groups of people, thus causing bias.
Another example arises in the context of Article 12 (4d), which requires logging information about
natural persons whose data is processed, while the GDPR restricts this kind of data collection. This
conflict needs to be addressed in some way, and guidelines on how to resolve them need to be
provided.
Overall, the GDPR and the proposed regulation appear to be partially in conflict. This creates new risks
of legal uncertainty that will particularly affect SMEs and startups that wish to develop or make use of
AI techniques.
Recommendation 3:
The proposed regulation needs to be aligned with existing regulations, notably with the GDPR, in
terms of the requirements for use of high-quality data.
12

There should be a focus on AI system behaviour
Only regulating the input data for an AI system - as is the current focus of the proposed
regulation - is insufficient for purely technical reasons. There are AI techniques that even with
“perfect” input data will not be able to provide the correct outcome under all circumstances (e.g., via
adversarial attacks on DNNs). While good input data is an important aspect for any data-driven
technique, the regulation must instead focus on ensuring the proper intended behaviour of the
AI system within the proposed application context (see SOTIF, https://de.wikipedia.org/wiki/SOTIF).
Concern 4:
There is a lack of focus on the proper intended behaviour of AI systems. The responsibility and
accountability for ensuring proper intended behaviour - including the use of suitable input data
in design, experimentation, testing and operation - is not clearly defined.
We see this focus on ensuring the proper functioning of an AI-System not only merely as a challenge for
AI, but as an opportunity for Europe to take the lead in trusted AI. Europe is well positioned to carry out
the necessary research and innovation, considering existing research strength in relevant areas of AI
(such as AI-based testing and verification techniques and neuro-symbolic AI), the focus on quality
products throughout European industry, but also given the historic, cultural, and political focus on safe
and trusted technology.
Recommendation 4:
The proposed regulation and coordinated plan should focus on ensuring the proper intended
behaviour of AI systems in high-risk applications and thus embrace the notion of trusted AI.
This aligns well with Recommendation 2 and implies that AI regulation should focus on the behaviour
of AI systems rather than the underlying AI techniques, recognising that in some cases, techniques
come with theoretical or empirical assurances regarding their behaviour (although such theoretical
guarantees are not always relevant in practice, since their underlying assumptions may not hold in
real-world use cases).
Another challenge arises in the context of AI systems that make use of components, such as
pre-trained machine learning algorithms obtained from another company. AI regulation needs to
target the behaviour of the entire system in the context of the concrete use case. Otherwise,
because of the generality of many AI algorithms, an embedded AI module that itself has low risk could
be used in a context where its results are used in a high-risk context without falling under the
regulation. Similar to product liability, it should be the final product that matters, irrespectively of how
it has been created.
13

There are concerns regarding citizens’ rights
CLAIRE welcomes the fact that the proposed regulation addresses fundamental rights - this is a step in
the right direction. Prohibitions of AI systems for social scoring and some police uses of biometric
recognition reflect the insight that some uses of AI are simply too harmful to be allowed.
However, the proposal is vague regarding certain citizen's rights. Among the proposed high-risk
applications are “those … that manipulate human behaviour, opinions or decisions… causing a person
to behave, form an opinion or take a decision to their detriment.” Unfortunately, it remains unclear
what constitutes manipulation of human behaviour to one’s detriment, and how this can be
measured.
Furthermore, the prohibition of mass surveillance is narrow, and the exceptions raise concerns.
Specifically, there are biometric mass surveillance practices that are not covered, and there are
potentially troubling exceptions. This leaves room for the use of biometric technologies for surveillance
and monitoring of individuals. It gives substantial support to the prohibition on law enforcement
agencies using real-time remote biometric identification systems (like facial recognition) in public
spaces. Overall, the proposed regulation does not prohibit the full extent of unacceptable uses of
AI, and in particular all forms of biometric mass surveillance.
In combination with the overly wide scope for self-regulation, this leaves a possibility for the use of
surveillance technologies and discriminatory technologies by governments and companies. In addition,
the responsibility for assessing the compliance of AI systems is assigned to the providers of
these systems, rather than on those who commission and operate them.
It is easy to find application domains that should have been defined as high-risk, considering their
implications for individual citizens and society as a whole. Examples include:
AI systems intended to be used for the purpose of diagnosing or classifying the mental health of
natural persons, or for identifying or approximating the psychological profile or character traits of
natural persons from proprietary or public data sources or a combination thereof, regardless of
the intention of such AI systems (e.g., medical diagnostics, target marketing, influencing voting
behaviour).
AI systems intended to be used for the purpose of assisting natural persons by providing them
actively with information, including images, videos, audio, and textual information, and by
selecting, filtering, generating, modifying or adapting or any combination thereof, this
information before providing this information to natural persons.
AI systems intended to be used for the purpose of scoring, permanently behaviorally monitoring,
or otherwise assessing natural persons regarding their access to or amount of fees paid for
obtaining important insurances, such as health insurance, insurance for disability or other
inabilities to work (including caused by psychological, mental, burn-out and similar reasons), or
14

transportation operations insurances (including occasional or permanent observation of
behaviour, surveillance and analysis).
Concern 5:
The proposed regulation is vague on citizens' rights and has important exceptions that
negatively impact these rights.
The proposed legislation allows for exemptions from restrictions on problematic uses of AI for
governments and government agencies. The reasons for these exceptions are unclear, as the use of
these by government agencies is not necessarily less harmful than use by private actors. This can
significantly compromise the rights of European citizens, and as a consequence, the proposed
regulation may not effectively preclude harmful uses of AI. It may also allow questionable uses of AI
technologies in the public sector. Examples of uses include attempts at detecting when migrants lie
during the visa process, inferring the age of unaccompanied minors requesting refugee status, or
reducing crime through advanced profiling (e.g., directing more policing to minority neighbourhoods).
Recommendation 5:
Make sure that, a priori, government uses of AI technologies fall under the same restrictions as
all other uses, and allow only minimal exemptions with suitable oversight.
To fulfil European ambitions for an ecosystem of trust in AI, exemptions for government use foreseen
in the current text should be revisited. Exemptions should be placed under stronger controls through
well-defined democratic processes and mechanisms. Participatory processes should be encouraged
that strongly involve all relevant stakeholders, including experts and groups in consumer rights, citizen
rights, technical experts and domain experts in further work on these aspects of the proposed
regulation.
Innovation and economic growth will be impacted
Europe lags in innovation. Its entrepreneurial capability and volume of risk investment are
considerably lower than those of its immediate competitors. Europe needs to find ways to make it
easier and less expensive to start technology-driven global companies.
In principle, regulation has the potential to stimulate innovation, and this is also an important ambition
of the proposed regulation. CLAIRE supports the European Commission's drive towards a balance
between regulation and innovation where citizens’ rights and societal interests are well
protected while facilitating investment and innovation. However, we find that the proposed
regulation in combination with the revised version of the coordinated action plan (discussed in more
detail in Section 3) does not achieve a reasonable balance, and we see substantial risk that the net
effect of the proposed regulation will be negative.
Delegating major responsibilities to the Member States will create more fragmentation and
friction with the internal market. For instance, while we are in favour of Article 53 on "regulatory
15

sandboxes", we believe the European Commission should not delegate all decisions on the
implementation of sandboxes to the Member States and associated contries. This delegation is likely to
create fragmentation of regulatory regimes and possible regulatory competition to attract innovators
and investors. As an example, while Norway already has introduced regulatory sandboxes in their legal
code, Sweden prohibits them.
As explained earlier in this section, ambiguous key terms and problematic definitions result in
legal uncertainty, which will drive up cost, reduce investment and ultimately hamper
innovation. The proposed regulation lays out a certification scheme that will apply to sectors not used
to regulatory processes and to an economy that is driven by the transformational power to existing
sectors by new technologies like AI. The cost, time, infrastructure and knowledge needed for
certification will be burdensome. Adhering to the extensive and complex regulation will likely prove
costly for companies and organisations. Small companies and research organisations might not be
able to easily follow the regulatory developments or ensure compliance and might thus be
affected negatively.
In addition, the implications of certification requirements remain unclear, along with the positioning of
certification within the already existing, complex landscape of certification and legal requirements
(including, e.g., GDPR, ISO 9001 and ISI 27001/TISAX). The connections and dependencies between
existing standards, the proposed new certification, the CE certification requirements remain
unclear, and the transitivity implications of these unknown dependencies create further
uncertainty.
The challenges of the certification schemes will be exacerbated if the conformity assessments will be
based on formal standards. There is a reason that SMEs, startups and entrepreneurs are
under-represented in standardisation organisations – they do not have the resources (in terms of
money, time, network or competence) to participate. The result, as we see across Europe, is that the
standards are mainly written by large companies, a few research organisations, and hired legal &
ethical experts, usually with little knowledge of the needs and tribulations of the entrepreneurial sector.
As a result, a standards-based certification scheme is likely to further disadvantage SMEs and
startups.
The proposed regulation includes requirements for high-risk AI systems and allocates those to a set of
actors, with the main burden resting on “providers” of AI systems. That model is overly simplistic. The
typical AI innovation ecosystem has many actors, and is fundamentally non-linear. The way AI
systems are initially developed, then revised, shared, and integrated by different actors in
practice leads to many different scenarios that are not captured by the proposed regulation.
We see the risk that placing the burden of certification on the providers of AI systems in
combination with the threat of steep fines, an unclear legal text and the impossibility of
knowing exactly how and for what some products will be used, will drive companies towards
classifying their applications as high risk to be on the safe side.
Software in general and AI tools or systems specifically have many applications, and it is not always
obvious who will use them for what. It is thus difficult for the provider of an AI tool or system to know
16

how to classify it. An example is found in paragraph 40 on page 28: "it is appropriate to qualify as
high-risk AI systems intended to assist judicial authorities in researching and interpreting facts and the
law and in applying the law to a concrete set of facts”. Would this imply that the use of an AI-powered
translation programme or a search engine in this context could be considered a high-risk application?
The expected tendency to classify AI systems as high-risk just to avoid later legal issues due to a
misclassification has several consequences. In particular, contrary to the intention of the proposed
legislation, many applications will be classified as high risk. This will drive up the cost of
developing the product and bringing it to market, which will, in turn, affect its position in the
market.
Article 29 (1) states that users must use AI systems "in accordance with instructions to use". But many
AI systems are complex and difficult to use. This causes risk and places a potentially excessive legal
burden on the user, who not only needs to understand the system but also how the regulations relate
to its application, in order to use the system in a correct way.
The sum of these considerations calls into question whether the proposed regulation will benefit
Europe economically.
Concern 6:
The proposed regulation will erode European competitiveness in the area of AI.
To address this concern, key aspects of the proposed regulation need to be revised, as explained
earlier in this section. In addition, it is of the utmost importance that the burden necessarily imposed
by regulation is offset effectively by carefully targeted investment and opportunities for innovation. In
this context, other components of the European AI strategy are of crucial importance. The revised
version of the coordinated plan recognises this fact, but - as we will discuss in the following section does not provide the instruments required to ensure European competitiveness in AI.
Recommendation 6:
Focus on investment that can offset the burden created by any AI regulation. Improve the
proposed regulation by clarifying definitions and removing uncertainties. Make certification
easy and cost-effective.
17

3 Coordinated Plan on AI
The key goal of the European Commission's Coordinated Plan on AI is to secure a global leadership
position of the EU in human-centric AI, through a joint commitment of the European Commission and
the Member States. The 2021 review of the plan, to which the following discussion responds, outlines
the goals of the plan, gives an overview of the actions taken, and provides an outlook on actions to be
taken in the near future. As with the proposed regulation, rather than attempting to comment on all
details of the plan, we focus on a small number of key aspects and also give brief responses to selected
details.
Overall, CLAIRE strongly agrees with the need to "accelerate, act and align AI policy priorities
and investments". In addition to the valid and compelling reasons stated in the introduction to the
plan (p. 2), the need to act swiftly and with determination is also prompted by the ongoing
developments in the area of AI outside of Europe - notably, in the US and China. Since 2018, when the
first version of the coordinated plan was released, Europe has fallen further behind in terms of
AI research and innovation, despite a multitude of well-intentioned and, in many cases, carefully
constructed and executed initiatives carried out by the European Commission and the Member States.
CLAIRE is unconvinced that the measures provided in the outlook chapters of the 2021 plan will
fundamentally change this situation, which raises serious concerns regarding European AI
capabilities, notably talent, going forward.
The main obstacles to overcome are
the complex and highly fragmented nature of the AI ecosystem and the measures put into place to
strengthen it;
a lack of effective funding instruments for stimulating research and innovation;
a lack of strategic EU-level activities that attract global attention or generate global impact;
a lack of coordination between different activities in order to reach larger goals.
The situation is exacerbated by the degree to which the attention of the European Commission, and as
a result, the general public as well as increasing parts of the AI ecosystem, are focussed on AI
regulation, rather than the investment needed to ensure European excellence in terms of AI research
and innovation. This can easily lead to a situation where Europe becomes largely dependent on AI
18

technology developed elsewhere, even if that technology meets regulatory standards pioneered by and
enacted throughout Europe. This scenario gives rise to a serious concern:
Concern 7:
Even if European regulation succeeds in setting global standards, most development and
research may end up taking place - or be directed from - elsewhere, and generate benefits
(especially economic benefits) mostly outside of Europe. This will erode European sovereignty in
the area of AI technology.
The results of our survey clearly reflect this concern. Over 90% of respondents agree that investment
into AI research and innovation is at least as important for the success of "AI made in Europe" as
regulation (see Appendix, Question 20), and over two thirds of these feel strongly about this point.
Furthermore, while ca. 75% of respondents agree that the coordinated plan presented by the European
Commission "maximises Europe’s potential to compete globally", over 40% of respondents state that
the coordinated plan does not sufficiently address the need for AI research and innovation (see
Appendix, Question 21).
Substantial and effective public investments are needed
As stated in the introduction of the plan, the European Commission intends to "accelerate private and
public investments leveraging EU funding available, for example, through Digital Europe (DEP), Horizon
Europe (HE) programmes and the Recovery and Resilience Facility (RRF)". It makes sense to use
existing instruments to broadly support the development and deployment of AI techniques and
systems throughout the EU. However, especially as DEP and HE are concerned, CLAIRE believes
that this will prove insufficient for securing European leadership in human-centric AI, since in a
nutshell, on their own, these investments are too small and too broadly distributed.
As stated in Chapter 5, "Through Horizon 2020, the Commission invested EUR 50 million over 4 years to
create a research community of closely networked AI excellence centres" (p.19). CLAIRE member
groups and organisations are heavily involved in all four networks that have been created, with
leadership roles in three of the networks and in the CSA. While establishing these networks was an
important first step, it is important to realise that creating multiple networks has further increased the
fragmentation of the European AI ecosystem; the funding period is limited and has not been
coordinated between the four networks; the budget is thinly spread across large groups of partners
and associated partners; and the overall funding is certainly far too limited to realistically reach any of
the major and consequential goals these networks are pursuing. In addition, the ICT-48-2020 call in
question failed to fund two areas of European strength in AI that are of key importance to many
applications discussed in Chapters 11-17 of the plan: Natural language processing and robotics,
creating a serious threat to European excellence in these areas.
In recognition of this, the outlook of Chapter 5 of the plan foresees to "fund under Horizon Europe, in
2021 and 2022, additional networks of AI excellence centres addressing complementary research areas
that are not yet covered by the existing networks of AI excellence centres and reinforcing research
19

efforts that address critical AI research topics. This will drive forward the development of safer, more
secure and more trustworthy AI, support foundational and application-oriented research on
next-generation AI, aiming to keep Europe at the cutting edge in AI" (p. 20). However, the funding
allocated in the recently published Horizon Europe calls is insufficient, and the way the funding
is distributed risks, once again, leaving out important parts of the AI community (e.g., in
robotics), since the fierce competition for modest amounts of budget is likely to lead to a situation
where the community fractures into multiple networks of which only one will be funded. This risks
further increasing fragmentation of the European AI ecosystem.
Concern 8:
Funding for AI research and innovation through Horizon Europe and the Digital Europe
Programme is insufficient and distributed in ways that leave out important parts of the AI
community. It thus fails to mobilise and leverage key European expertise in AI and risks further
increasing the fragmentation of the European AI ecosystem.
The plan intends to "starting in 2021, advance the state of the art in various areas of AI research,
including, research towards the next level of intelligence and autonomy of AI-based systems,
transparency in AI, greener AI, AI for complex systems, advances in edge AI networks, unbiased AI
systems, empowering humans with advanced AI support" (p. 20). Existing and newly created networks
of centres of excellence in AI will doubtlessly achieve advancements in the state of the art across
various areas of AI, but CLAIRE has serious doubts that the funding instruments used under
Horizon 2020 and Horizon Europe will achieve advancements significant enough to secure global
leadership.
Recommendation 7:
To achieve global impact, the investment into the European AI research and innovation
ecosystem needs to be much more substantial, has to be made in a way that leverages broader
parts of the European AI research ecosystem, and cannot be solely targeted to a set of weakly
coordinated research networks.
More coordination is needed
The introduction of the plan (p.3) states that "RRF provides an unprecedented opportunity to
modernise and invest in AI to lead globally in the development and uptake of human-centric,
trustworthy, secure and sustainable AI technologies". In principle, CLAIRE agrees that the RRF
provides unique opportunities in the context of ensuring European excellence and leadership in
AI, especially, since there is a sizable 'digital expenditure target' of 134 billion Euros. Unfortunately, it
appears that the RRF funding is allocated to the Member States without major incentives or
requirements for coordinated investment, which makes it likely that in the area of AI, most or all of it
will be spent in a fully distributed fashion on national or regional projects.
20

According to Chapter 1 of the plan, "Member States are strongly encouraged to develop and promote
instruments that allow regular monitoring, coordination, evaluation and exchange of experience and
best practice across a broad spectrum of stakeholders" and to "reinforce support for and investment in
joint actions identified in the Coordinated Plan" (p. 7). While this is certainly desirable, the plan does
not provide any concrete mechanisms or incentives for this much-needed kind of cooperation
between the Member States.
Concern 9:
In the absence of effective mechanisms and incentives, the cooperation required for success at
the European (rather than merely the member state) level will not be achieved.
Likewise, the outlook of Chapter 1 encourages Member States to "facilitate discussions on setting up
national coalitions and facilitate best practice exchange among Member States and stakeholders on
existing national AI coalitions by bringing together public- and private-sector stakeholders, e.g. in joint
workshops on thematic areas of common interest. In cooperation with the co-programmed partnership
on AI, Data and Robotics, this action will assist cross-border cooperation and draw in more
stakeholders" (p. 11). Again, this is highly desirable, but CLAIRE is concerned that little of this will
happen, unless clear incentives and coordination mechanisms are created at the EU level.
This concern arises throughout key components of the plan, including the mechanisms outlined in
Chapter 6 for stimulating take-up of AI technologies by SMEs and public administrations - a topic
CLAIRE agrees has high importance and potential for major impact in terms of benefits to citizens and
the economy of the EU. Chapter 6 states (p. 22) that the "EU and the Member States will invest EUR 1.5
billion to set up a network of around 200 hubs [EDHIs] across European regions'', and that the "network
of EDIHs will share best practices and effectively collaborate with each other (using the
recommendations coming out of the AI DIH Network) to offer the best support to SMEs and public
sector organisations everywhere in Europe" to boost the dissemination of resources and to enable
experimentation with AI. While this certainly brings benefits to the regions, the collaboration and
sharing of best practices requires sustained and much stronger coordination than currently
foreseen in the plan. Especially in a broad and fast-moving field such as AI, cohesion and
coordination within a diverse network of facilities requires careful design and implementation
of suitable mechanisms at the EU level.
For the European AI ecosystem to achieve global success, and even to ensure regional success
across the Member States and regions within Europe, highly distributed and largely
uncoordinated funding is not enough.
Recommendation 8:
Create suitable mechanisms for coordination at the EU level. This includes coordination of the
networks of centres of excellence in AI, of the EDIHs, of at least a sizable part of RRF spending on
AI and of other key components of the plan. The coordinated plan on AI needs to become more
coordinated.
21

The proposed coordinated plan relies to a significant extent on the new public private partnership,
Adra, and the AI-on-demand platform to achieve much-needed coordination. Considering the current
state of the AI-on-demand platform, CLAIRE finds it unlikely that it can play a major enabling role in the
near future, but remains committed to help ensure its usefulness for the European AI ecosystem in the
long term. Adra has been established only recently; in close concert with its well-established founding
organisations it can, in principle, make major contributions to the European AI ecosystem but,
considering its mandate and structure, is unlikely to coordinate effectively the activities of the networks
of centres of excellence, EDHIs and other major stakeholders.
Success in AI applications critically depends on excellence
in AI research and innovation
In CLAIRE's official response to the European Commission's 2020 white paper on AI, a clear
recommendation was made to focus "AI made in Europe" on "AI for Good" and "AI for All" (Key
Recommendation 4). We are pleased to see that key parts of the coordinated plan are well aligned with
this focus, notably Chapter 11 ("Bring AI into play for climate and environment"), Chapter 12 ("Use the
next generation of AI to improve health") and Chapter 17 ("Support AI for sustainable agriculture") in
relation to AI for Good, as well as Chapter 14 ("Make the public sector a trailblazer for using AI") in
relation to "AI for All". These application areas of AI are of key importance to citizens and societies
across the EU and far beyond, and we remain convinced that Europe can play an important leadership
role in all of them. However, success in these areas (within and beyond the EU, e.g., in terms of
economic benefits derived from global leadership in these areas) critically depends on AI
capabilities resulting from excellence in research and innovation.
Europe cannot lead in AI applications without being a leader in AI research and innovation. In
our response to the 2020 white paper, we called on the European Commission to aim for "global
leadership, together with like-minded partners, in supporting publically funded, large-scale AI research
and innovation that can compete at the level of large US and Chinese companies, while focusing on
areas specifically relevant for societies". The revised version of the coordinated plan certainly embraces
this ambition, but does not allocate sufficient resources to have a realistic chance of securing global
leadership in any of the areas discussed in Chapters 11-17 of the plan. The area in which the gap
between the level of ambition and the level of funding is the smallest is perhaps that of AI for climate
and the environment, through the Destination Earth (DestinE) programme, but even in this case,
serious concerns remain regarding the funding aimed at the crucial AI research and development
components that form the basis for any meaningful realisation of a "digital twin of Earth".
Likewise, the level of funding allocated for creating a network of AI centres in robotics is grossly
insufficient to maintain European leadership in research on AI-based robotics, and as a result
calls into question the very foundation of the ambition expressed in Chapter 13 of the document
("Maintain Europe’s lead: Strategy for Robotics in the world of AI"). Furthermore, dedicated,
large-scale funding for natural language processing - in light of European language diversity,
another area of crucial importance, also for public administration and industry - appears to be
22

missing from the coordinated plan, which threatens to erode the existing European leadership
in this area.
Long-term investments are needed
Key components of the coordinated plan as implemented up to this date have consisted of funding for
short periods of time. For example, three of the four networks of centres of excellence in AI mentioned
in Chapter 5 (p. 19) have a duration of three years, and one a duration of four years. Of course, such
funding instruments are common, also at the member state level and outside of Europe, but especially in cases of support for cutting-edge research in AI at top European universities with 4-year
PhD programmes - any funding programmes for less than three years is inherently problematic.
Furthermore, the research agendas of these networks, in close alignment with the respective call texts
and with the level of excellence and ambition of European AI researchers, are unlikely to be realised
within a 3- or 4-year period. Similar considerations apply to many of the calls under Horizon Europe
that are intended to realise key parts of the coordinated plan, especially as little coordination exists
between the individual projects. CLAIRE urges the European Commission to ensure rectification of this
shortcoming of the coordinated plan.
Recommendation 9:
Implement key parts of the coordinated plan through longer-term, mission-oriented
investments, including 7- and 10-year funding for research networks.
Examples for such programmes exist, for example in the Netherlands, which provides 10-year funding
for nation-wide, large scale research programmes. It is important to not leave such longer-term efforts
to the Member States alone, since much of the basis of the Commission's plans for European
leadership in AI hinges on large-scale, coordinated action involving stakeholders across Europe. A new
Joint Undertaking in AI could be an interesting element of this strategy, in the form of a physical, central
lighthouse centre for AI (see also Recommendation 13), bringing together the coordinated actions
between Member States and the European Commission.
Naturally, long-term programmes should be funded at appropriate levels and involve
intermediate evaluation to ensure effective and responsible use of resources. They should be
strongly anchored in the leadership and participation of institutions with a track record of
sustained impact in AI and related areas, but also include mechanisms for including less
established partners and for serving the large talent pools found in areas of Europe that have
not yet developed world-leading activities in AI. Longer-term funding programmes can increase the
efficiency of budget use, can increase chances for globally impactful progress in AI, and can help
stabilise the European AI ecosystem. They can also help address current, serious challenges in retaining
and attracting talent.
23

Attracting and retaining talent at all levels is of crucial
importance
Chapter 1 of the coordinated plan rightfully emphasises enabling conditions for the success of "AI
made in Europe" including computation infrastructure, data, as well as governance and coordination
(and especially coordination with the Member States). What is critically missing, however, is an
emphasis on talent, which is discussed only far later in the plan (Chapter 8), and in an overly limited
fashion, tying the notion of talent only to junior levels expertise (such as students, PhDs and postdocs)
and missing critical aspects of attracting and retaining talent at all levels.
For several years, Europe has experienced a dangerous outflow of top AI talent to North American
companies and universities. Top young European AI researchers often leave for the US and Canada
directly after completing their PhD or Master degrees, attracted by highly paid internships and
aggressive hiring policies of US-based multinational companies such as Google and Facebook, as well
as large AI research centres established at universities such as CMU, University of Toronto (Vector
Institute) and Université de Montréal (Mila). A number of excellent senior European AI researchers have
left, or are working remotely, for companies and research centres in North America and China as well,
including leaders of European AI organisations. Europe’s AI organisations, in particular CLAIRE and
ELLIS, have been warning against this dangerous trend since 2018. Europe critically needs to stop the
AI brain drain at all levels by rapidly introducing competitive conditions for attracting and
retaining AI talent.
Concern 10:
Europe is losing the competition for AI talent with the US and China. Europe critically needs to
stop the AI brain drain at all levels by rapidly introducing competitive conditions for attracting
and retaining AI talent.
Simply appealing to the introduction of best practices will not be sufficient. Europe needs to very
quickly introduce effective funding programmes comparable with the generous offers available
through schemes such as Canada's AI CIFAR Chairs, which - together with large investments into
large-scale AI institutes - have made a country like Canada into an AI superpower.
Chapter 8 of the coordinated plan states that the European Commission will, "under the Horizon
Europe programme, support Networks of AI excellence centres (as part of the AI lighthouse). Among
other tasks, the centres would explore options to retain talent through closer collaboration with
industry and public authorities" (p. 29). CLAIRE believes that relying on networks of AI excellence
centres alone will prove insufficient to stem the brain drain.
The Commission further plans to "fund doctoral networks, postdoctoral fellowships and collaborative
staff-exchange projects in AI under the Marie Skłodowska-Curie actions" (Chapter 8, p. 29). CLAIRE
agrees that funding for doctoral and postdoctoral researchers in AI is urgently needed, and that
deploying it through an existing, well-established mechanism, such as the Marie
Skłodowska-Curie actions, is a good approach. However, this addresses the problem only at the
24

most junior level of AI talent, and if these researchers, after having been thus funded, leave the
European AI ecosystem, little has been achieved.
Europe is uniquely positioned to build on its world-leading expertise in selecting and funding excellent
research via its ERC system. Substantial low-administrative funding can be efficiently distributed into
top-level AI research by establishing further ERC AI panels that will use well-established and widely
accepted ERC mechanisms to select and fund excellent AI teams across Europe. In light of this, we
recommend to launch in 2022 a new joint ERC-AI programme with its own substantial funding on
top of the current ERC budget.
Recommendation 10:
Create and rapidly deploy effective, light-weight, EU-wide mechanisms for attracting and
retaining talent, such as an ERC programme in AI.
Competitive ERC/CIFAR-style research funding is, however, only a part of the necessary measures. AI
researchers are today leaving Europe also because of much better access to computational and
experimental infrastructure, the possibility to work with much larger datasets, much larger pre-trained
AI models, and much larger applications. Europe needs to take inspiration from recent large
national infrastructure projects, such as the French Jean Zay AI cluster, and build up
computational resources competitive with the US and China, thus democratising access to such
resources beyond today’s limited number of AI-company researchers. As the recently launched
BigScience project documents, there is a very real danger of European researchers being left behind as
2
second-class citizens who will not be able to train and run state-of-the-art AI models, leaving them to
cloud access to models pre-trained in non-transparent commercial environments created outside
Europe. An effective measure in this direction is to mandate that companies that make
substantial use of the data of EU users have to build their data centres in the EU, conform to the
EU laws when training their AI models, and run a corresponding share of their AI research and
development in the EU. Another key step towards addressing this issue is the establishment of
large-scale AI centres and of a suitably equipped European lighthouse centre for AI, as explained
in the following.
Recommendation 11:
Complement the research funding programmes by establishing large computational
infrastructure for AI in the EU. Mandate that companies that use EU data must store such data
in the EU, train their AI models in the EU, and run a substantial share of their AI research and
development in the EU.
2 https://venturebeat.com/2021/07/14/nlp-needs-to-be-open-500-researchers-are-trying-to-make-it-happen/
25

Investment into networks and distributed infrastructure must be
complemented by large-scale infrastructure and facilities
The coordinated plan includes the creation of larger, regional and national research centres in AI. As
per Chapter 5 of the plan, the Member States are encouraged to "set up regional and national research
excellence centres around AI, for example by using national funding instruments and RRF funds, and
create a research and technology transfer structure able to attract and retain talent while at the same
time aiming to become a national reference point for AI research and development. The centres would
ensure regional outreach and exchange, collaborate at the European level and, together with the
EU-funded networks, build the distributed European AI lighthouse" (p. 20).
CLAIRE believes that regional and national centres are important, and we welcome the fact that
some Member States are now setting up such centres. However, these centres are unlikely to
reach scales that enable world-class, mission-driven AI research and development in the areas
covered in Chapters 11-17 of the coordinated plan.
In August 2020, the US government announced the creation of 12 centres for AI and quantum
computing research, funded jointly at 1 billion US dollars. Later in 2020, 7 AI research centres have
been established, and another 11 have been announced, in some cases co-funded by industry, in July
2020. CLAIRE predicts that, based on network funding and a large number of smaller-scale
centres set up by the Member States, Europe will be unable to compete with the US. To achieve
the ambitious goals of the plans, these smaller centres must be complemented by large-scale
infrastructure and facilities.
Recommendation 12:
The European Commission, together with the Member States, should establish a small number
of large-scale research centres in different geographical regions of Europe, dedicated to specific
application areas of AI, following broadly the challenges laid out in Chapters 11-17 of the
coordinated plan, and funded at an appropriate level, jointly by the European Commission, the
Member States and, in some cases, possibly industry.
These larger-scale centres should be focussed on broad application areas of AI rather than on
specific AI technologies or techniques, since the application areas in which Europe aims to lead
require the combination of techniques from different areas of AI as well as close collaboration with
domain experts and, in some cases, dedicated infrastructure.
The lighthouse centre for AI cannot be distributed
In its 2020 white paper on AI, the European Commission prominently included the concept of a
lighthouse centre for AI. This idea follows that of a European AI hub that forms, together with a small
26

number of regional hubs and a large network of organisations engaged in AI research and innovation, a
key component of the CLAIRE vision for European excellence in AI, first presented in 2018.
CLAIRE's 2020 response to the white paper explicitly reinforced this idea; in Key Recommendation 10,
CLAIRE calls on the European Commission to "create the proposed lighthouse centre in a way that
effectively achieves critical mass, synergy, and cohesion across the European AI ecosystem without
permanently dislocating talent from where it is needed most".
We are pleased to see that the lighthouse centre is now a key component of the coordinated plan, and
that there appears to be a commitment to start setting it up in the very near future. Chapter 5 of the
coordinated plan states that the Commission will "set up, starting in 2021, and in close dialogue with
the Member States and the wider AI community, an AI lighthouse for Europe, as announced in the
White Paper" (p. 19).
The coordinated then elaborates (pp. 19-20): "The AI lighthouse will build on the existing and future
Networks of AI excellence centres, with the aim to build an alliance of strong European research
organisations that will share a common roadmap to support excellence in basic and applied research,
to align national AI efforts, to foster innovation and investments, to attract and retain AI talent in
Europe, and to create synergies and economies of scale. This initiative will bring together leading
players from research, universities and industry in Europe to work on commonly agreed ambitious
challenges, with the overarching aim of becoming a world reference of excellence in AI. As a result,
Europe’s diversity will stimulate healthy competition, rather than the fragmentation of the AI
community."
CLAIRE agrees that an AI lighthouse has the potential of becoming a global reference in AI, and
also a global attractor for talent. It is, in addition to the proposed regulation of AI, perhaps the
one element of the plan that has the highest potential for creating global impact. However, this
will only work if the lighthouse is implemented in a suitable fashion.
The idea of a publicly funded, large-scale centre for AI, a "CERN for AI", has intrigued AI researchers and
other stakeholders in Europe and far beyond since 2017, when it started to be discussed. The interest
in and support for this idea has intensified greatly since the concept has officially become a key part of
the CLAIRE vision.
The way in which the lighthouse is referred to in recently published Horizon Europe calls, as well as in
Chapter 5 of the coordinated plan (see, e.g., p. 20) raises major concerns that the original, powerful
concept has been watered down to refer to a loosely organised collection of research networks
supported by short-term funding, not unlike the four networks of centres of excellence established in
Horizon 2020. Such a "virtual lighthouse" is superficially attractive, because it sidesteps the difficult
question of location and permits the broad spreading of modest resources, but it has serious
drawbacks.
27

Concern 11:
A distributed version of the European lighthouse for AI will be ineffective and inconsequential,
and the fact that the current plans are vague and confused about the concept has already
started to erode what could be a major success story for European AI, a powerful symbol and
nexus for the ambition of "AI made in Europe", and a global attractor of talent.
As explained earlier in this document, the European AI strategy as laid out in the revised coordinated
plan suffers from a lack of coordinating mechanisms, of elements that bring together the fragmented
European AI ecosystem. Strong support for broad networks is an important ingredient for the success
of "AI made in Europe", but by relying primarily on investments into networks, European ambitions in
AI cannot be realised.
As explained in CLAIRE's response to the Commission's 2020 white paper (p. 8), the lighthouse centre
"should be ' the place to be ' when it comes to AI research and innovation in Europe . A place where
people can meet for a period of time to work with other leading researchers and experts from all over
the world on the most exciting and important topics, technologies and applications of AI." To achieve
this, a central, physical realisation of the lighthouse concept is required.
Recommendation 13:
Establish a central, physical European lighthouse centre for AI, in order to bring together the AI
ecosystem and to create global momentum that can help Europe reach the ambitions stated in
the coordinated plan.
We note that in our survey, there was also clear and strong support for the concept of a centralised
implementation of the European lighthouse centre (see Appendix, Question 22): over 80% of
respondents agreed with this concept, and more than half of these indicated strong support for a
centralised, physical facility.
The concept of "place" matters. This is why EU institutions, while spread out across Europe, are
concentrated in Brussels, why the European Central Bank has prominent headquarters in Frankfurt,
why Apple created an iconic and immense building for their headquarters in California, and why every
single European member state has a capital city, in which ministries and other public institutions, along
with the embassies of other countries, are concentrated. Critical mass and momentum require
concentration.
The effects of this can be seen, for example, when comparing the visibility of two European success
stories: CERN and EMBL. CERN, established in 1954, is primarily based on a central location. EMBL,
established in 1974, is distributed over 6 sites. Both are world-leading in their respective fields of
research, particle physics and molecular biology. However, a historic web search comparison of “CERN”
3
and “EMBL” shows more than ten times higher visibility of CERN (38 vs 3 aggregated points), and the
number of followers on their principal Twitter accounts is 2.5 million for CERN and 0.0491 million for
3 https://trends.google.com/trends/explore?date=today%205-y&q=CERN,EMBL
28

EMBL. It seems unlikely that this would reflect in any way a difference in inherent interest in particle
physics vs molecular biology.
CLAIRE is well aware of the challenges of deciding the location of a central facility. As explained in our
response to the Commission's 2020 white paper, there are ways to address these challenges (p. 8):
"Through sabbaticals and other temporary scientific positions, the Hub will not drain talent from labs
around Europe. Rather, it will act as the beating heart of European AI , a place where knowledge is
exchanged, fused and amplified by the visiting researchers and then spread out again to the labs in the
network by the returning researchers, thereby strengthening the development of excellent AI research
across all of Europe." As per Key Recommendation 10 from that document, the site selection process
should be grounded and transparently managed on the basis of politically neutral, externally validated
criteria. Furthermore, the central lighthouse should be complemented by a small number of
large-scale centres in different geographical regions of Europe dedicated to specific application
areas of AI, following broadly the challenges laid out in Chapters 11-17 of the coordinated plan.
Simpler is better
CLAIRE agrees with the level of ambition for European AI that is evident in the coordinated plan.
With an organisation as large and complex as the European Union, it is natural that there will be a
broad spectrum of thoughts and opinions on how to achieve this ambition, and this is also evident in
the coordinated plan.
Concern 12:
The actions foreseen under the plan are scattered. None of them appears to be likely to
substantially move the needle on AI research or innovation in the global context or to lead to
game-changing AI capabilities. There is a serious risk of increasing fragmentation and, as a
result, diminished global impact of the European AI ecosystem under this plan.
CLAIRE agrees with the European Commission's statement in the conclusion of the coordinated plan (p.
56): "The next steps should focus on the implementation of the joint actions and the removal of
fragmentation between funding programmes, initiatives and actions taken at EU and Member State
level." CLAIRE has serious doubts that this can be achieved by the plethora of actions planned as per
the outlook provided by the coordinated plan.
As stated in the plan, there is much "further potential for action to foster closer cooperation and
coordinating common priorities and initiatives within AI", and realising that potential is key to achieving
the Commission's ambition for "AI made in Europe", and that of the European AI community and its
stakeholders. CLAIRE strongly agrees with this point.
What's missing from the revised version of the coordinated plan, as presented in April 2021, are
key mechanisms or initiatives that clearly have the potential to create global impact, attract
talent and advance European capabilities in AI in obvious, major ways. None of the proposed
29

mechanisms, except regulation and perhaps the lighthouse (depending on implementation), is
likely to make international headlines.
Recommendation 14:
Simpler is better. The coordinated plan should be revised, involving the highest level of the
European Commission, to focus on a small number of impactful initiatives, each backed by
resources that allow the European AI community to achieve global impact and leadership in key
areas of AI research, innovation and applications.
These initiatives should include:
an AI infrastructure sovereignty programme designed to produce European alternatives to
US-dominated critical infrastructure and services that play a critical role for enabling
development and adoption of AI technologies;
an "innovation booster" programme for spin-offs, start-ups, scale-ups
excellence grants in AI, modelled after ERC Grants and similar mechanisms (German von
Humboldt chairs, Canadian CIFAR chairs etc.).
A small number of large-scale regional AI excellence hubs distributed throughout Europe and
focussed on key application areas of AI;
a European Lighthouse Centre for AI developed along the lines of a “CERN for AI”
In addition, longer-term and larger-scale funding instruments that bring together the European AI
community, rather than fragmenting it further, need to be developed and deployed to complement
short-term, modestly sized funding that is distributed broadly via the Horizon Europe and Digital
Europe programmes.
30

4 Conclusions and Outlook
Just as the 2021 revision of the coordinated action plan and the proposed regulation follow and build
on the European Commission's 2020 white paper on AI, CLAIRE's response given here builds on
CLAIRE’s earlier response to the white paper. While many of the recommendations made in this earlier
document are included in the newest proposals, careful analysis in light of the new documents shows
that it remains highly relevant.
Overall, the European Commission has set itself an extremely challenging task. AI is challenging, and
there is some disagreement even within the global AI community as to which problems and
approaches fall within the scope of AI, and which are most relevant for rapidly emerging applications.
Coordinating AI policy and investment across a vast, culturally diverse organisation such as the
European Union is even harder. It is therefore not surprising that iteration, consultation and discussion
is required to "get it right".
The proposed regulatory framework interacts strongly with other elements of the coordinated plan on
AI, especially those related to investment into European capabilities in AI. It is therefore important to
approach them in a holistic way. Commenting on one while not considering the other is
counterproductive and risks producing solutions to some of the major concerns that do not align
effectively towards the overall goal of European leadership in human-centric, trustworthy AI.
It would be particularly problematic to consider the coordinated plan as "locked in", and to focus
consultation and discussion solely or mostly on the proposed legislation. Considering the weaknesses
of the proposed legislation discussed in Section 2 of this document, this would incur the risk of
seriously eroding European sovereignty with respect to AI technology and its applications. The
proposed regulation will require a substantial amount of additional consultation - it is important to take
the time needed for this process. Other elements of the coordinated plan, however, need to be revised
and pursued swiftly, to ensure that Europe's position in terms of AI capabilities and talent does not get
further compromised compared to the fast moving global leaders.
CLAIRE applauds the level of ambition evident from the European Commission's latest documents on
AI. Achieving these ambitions would indeed position "AI made in Europe" for global success and bring
enormous benefits to citizens across Europe.
On the other hand, serious concerns arise regarding some of the general approaches outlined in these
latest documents as well as regarding specific details, as spelled out in Sections 2 and 3: These include
issues with the definition of AI (Concern 1) and detrimental effects of problematic definitions (Concern
2); negative impact on citizens' rights (Concern 5); erosion of European competitiveness and
31

sovereignty (Concerns 6 and 7); insufficient funding for AI research and innovation and a lack of
mechanisms for cooperation (Concerns 8 and 9); a wasteful and ineffective implementation of a
"distributed lighthouse" (Concern 11); and a risk of further fragmentation of the European AI ecosystem
(Concern 12).
Building on these concerns, as well as on the key recommendations from our 2020 white paper
response, CLAIRE has made a series of recommendations for improvements to the recently presented
regulation and coordinated plan on AI. These prominently include adopting a suitable definition of AI
throughout both documents (Recommendation 1); defining regulatory restrictions based on a class of
use cases enabled by AI rather than based on a list of technologies (Recommendation 2); placing, a
priori, government uses of AI technologies under the same restrictions as all other uses
(Recommendation 5); ensuring investments that can offset the burden created by any AI regulation
(Recommendation 6); increasing funding for AI research and innovation to levels that can truly achieve
global impact, and creating suitable mechanisms for coordination at the EU level (Recommendations 7
and 8); creating effective, light-weight, EU-wide mechanisms for attracting and retaining talent, such as
an ERC programme in AI (Recommendation 10); establishing a small number of large-scale research
centres in different geographical regions of Europe, dedicated to specific application areas of AI,
following broadly the challenges laid out in Chapters 11-17 of the coordinated plan (Recommendation
12); and focussing on focus on a small number of impactful initiatives, each backed by resources that
allow the European AI community to achieve global impact and leadership in key areas of AI research,
innovation and applications - including a central, physical European lighthouse centre for AI
(Recommendations 13 and 14).
As a large and diverse organisation, spanning all of Europe and all areas of AI, CLAIRE will be happy to
work with the European Commission and other stakeholders towards ensuring the success of "AI made
in Europe". Some opportunities for doing so arise through CLAIRE's leading role in the recently
established networks of centres of excellence; another one is closely connected to CLAIRE's role as a
co-founder and facilitator of Adra. Finally, CLAIRE, which represents academia, research institutes and
industry networks, would be happy to contribute as a member of the European AI Board (EAIB). CLAIRE
will continue to work with the European Commission, the governments of Member States, other AI
organisations, and within its own extensive network spanning a major part of the European AI research
and innovation landscape, through community building, consultation, events, volunteer work and
funded programmes, towards the success of human-centric, trustworthy "AI made in Europe".
32

Appendix: Survey results
In this section, we summarise results from a detailed survey prepared by CLAIRE and run from
11.05.2021 to 04.07.2021 via EU Survey. The survey was designed to elicit in-depth assessments and
insights, rather than to generate a maximum number of responses. In total, 25 questions were asked
on the following topics: personal (3), high-level goals and strategy (7), categories of risk and enforcement (5),
perceived benefits and disadvantages (7) and coordinated plan for AI / investment into research and
innovation (3). The survey was inter alia distributed among the ICT-48 AI networks of excellence, CLAIRE,
European Language Equality (ELE), European Language Grid (ELG).
Overall, of the 85 respondents, 66 identified as affiliated with CLAIRE (41 supporters, 33 Research
Network members, 3 Innovation Network members), 14 as working in industry, 61 as working in
academia, 4 NGO or similar, 17 Research and Technology Organisations (RTOs), 9 private citizens. The
survey was one of several mechanisms for providing input into CLAIRE's response to the two
documents released by the European Commission on 21 April 2021, and further mechanisms for
consultation with the CLAIRE (AI) community and beyond are planned for the near future.
High-level goals and strategy
Question 1: The EC has decided to pursue a proportionate risk-based approach (to regulate AI) that
also introduces codes of conduct for non-high risk AI systems (so-called ‘option 3+’). Do you agree with
this choice of strategy?
Answers: 84.8% agree/strongly agree, 13.0% disagree/strongly disagree
33

Question 2: The Coordinated Plan on Artificial Intelligence 2021 Review (CPAI) maximises Europe’s
potential to compete globally.
Answers: 74.1% agree/strongly agree, 20.0% disagree/strongly disagree
Question 3: Do you agree with the proposed regulation of AI? (Please elaborate your
arguments/concerns)
Answers: 74.1% agree/strongly agree, 21.2% disagree/strongly disagree
34

Question 4: Do you agree that the new regulation and CPAI will ensure that AI is sustainable and
trustworthy in the EU?
Answers: 63.5% agree/strongly agree, 34.1% disagree/strongly disagree
35

Question 5: For AI to be humane and ethical it needs to be transparent.
Answers: 85.8% agree/strongly agree, 11.8% disagree/strongly disagree
Question 6: Do you agree that this regulation sufficiently ensures transparency across all AI
technologies?
Answers: 56.5% agree/strongly agree, 38.8% disagree/strongly disagree
36

Question 7: The European Vision for AI should extend beyond the borders of Europe to other regions
of the world.
Answers: 87.0% agree/strongly agree, 10.6% disagree/strongly disagree
Categories of risk and enforcement
Question 8: Do you agree with the categories of risk (Minimal, Limited, High, Unacceptable)?
Answers: 87.1% agree/strongly agree, 7.1% disagree/strongly disagree
37

Question 9: Do you agree that the package of rules that is now released by the Commission will be
sufficient to protect EU citizens from the potential abuse of AI systems (i.e., mass surveillance, social
scoring, manipulating human behaviour, opinions or decisions)?
Answers: 44.7% agree/strongly agree, 47.1% disagree/strongly disagree
38

Question 10: Do you agree that this regulation sufficiently addresses the issue of real time remote
biometric identification?
Answers: 52.9% agree/strongly agree, 29.5% disagree/strongly disagree
Question 11: The success of any regulation depends in part on the degree to which it is enforceable.
Do you agree that the EU and its Member States will be able to sufficiently enforce this regulation of AI?
Answers: 35.3% agree/strongly agree, 56.5% disagree/strongly disagree
39

Question 12: As per the Commission's proposal, national authorities should be responsible for
assessing whether AI systems comply with the regulation.
Answers: 62.4% agree/strongly agree, 31.7% disagree/strongly disagree
40

Perceived benefits or disadvantages
Question 13: The proposed regulation strikes a reasonable balance between the interests of academia,
industry and society at large. (Please elaborate on required changes to the proposed regulations)
Answers: 64.7% agree/strongly agree, 29.4% disagree/strongly disagree
Question 14: Do you agree that the proposed regulation and plans sufficiently addresses the concerns
of the stakeholders in Industry? (Please elaborate any concerns or suggestions you have)
Answers: 61.2% agree/strongly agree, 25.9% disagree/strongly disagree
41

Question 15: Do you agree that the proposed regulation and plans sufficiently addresses the concerns
of the stakeholders in Academia? (Please elaborate any concerns or suggestions you have)
Answers: 58.8% agree/strongly agree, 34.1% disagree/strongly disagree
Question 16: Do you agree that the proposed regulation and plans sufficiently addresses the concerns
of the stakeholders in NGOs? (Please elaborate any concerns or suggestions you have)
Answers: 63.6% agree/strongly agree, 20.0% disagree/strongly disagree
42

Question 17: Do you agree that the proposed regulation and plans sufficiently addresses the concerns
of private citizens? (Please elaborate any concerns or suggestions you have)
Answers: 60.0% agree/strongly agree, 30.6% disagree/strongly disagree
43

Question 18: Do you agree that CPAI and the proposed regulation will attract new global AI talent to
the EU?
Answers: 48.3% agree/strongly agree, 42.3% disagree/strongly disagree
Question 19: This regulation may limit AI innovation too much, putting the EU in a disadvantaged
position globally.
Answers: 40.0% agree/strongly agree, 51.8% disagree/strongly disagree
44

Coordinated plan for AI / investment into research and innovation
Question 20: Investment into AI research and innovation is at least as important for the success of "AI
made in Europe" as regulation.
Answers: 93.0% agree/strongly agree, 5.9% disagree/strongly disagree
Question 21: The coordinated plan sufficiently addresses the need for AI research and innovation.
Answers: 51.8% agree/strongly agree, 42.3% disagree/strongly disagree
45

Question 22: The outlook provided in the CPAI prominently includes a lighthouse centre for AI. I
believe this should be implemented as an ambitiously scoped, physical facility with world-class
infrastructure and support staff (in addition to regional centres and investment into the broader
ecosystem), rather than solely in a virtual, distributed fashion.
Answers: 82.4% agree/strongly agree, 15.3% disagree/strongly disagree
46